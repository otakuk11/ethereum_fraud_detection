{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "939bfb8a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "error",
     "timestamp": 1667209390500,
     "user": {
      "displayName": "Alvin Leung",
      "userId": "04515226660203115454"
     },
     "user_tz": -480
    },
    "id": "939bfb8a",
    "outputId": "f0ab42c0-f591-4af8-9b07-47e4d7c90fed"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, PolynomialFeatures\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, recall_score, accuracy_score, classification_report, r2_score as r2\n",
    "from sklearn.model_selection import KFold, RepeatedKFold, GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import torch\n",
    "import keras\n",
    "from keras.constraints import max_norm as MaxNorm\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.ensemble import StackingClassifier, StackingRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "matplotlib.rcParams['figure.figsize'] = (11.0, 8.0)\n",
    "\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a95cd3b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "executionInfo": {
     "elapsed": 374,
     "status": "error",
     "timestamp": 1667209406117,
     "user": {
      "displayName": "Alvin Leung",
      "userId": "04515226660203115454"
     },
     "user_tz": -480
    },
    "id": "a95cd3b8",
    "outputId": "04c2636b-fbb1-4eb2-8f61-b596147f865e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing Data\n",
    "df = pd.read_csv('../Data/address_data_combined.csv')\n",
    "X = df.drop(columns=['Address', 'FLAG'])\n",
    "y = df['FLAG']\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "columns = ['Avg min between sent tnx', 'Avg min between received tnx',\n",
    "       'Time Diff between first and last (Mins)',\n",
    "       'Unique Received From Addresses', 'min value received',\n",
    "       'max value received ', 'avg val received', 'min val sent',\n",
    "       'avg val sent', 'total transactions (including tnx to create contract',\n",
    "       'total ether received', 'total ether balance']\n",
    "    \n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Log for Skewed Data\n",
    "for c in columns:\n",
    "    X_train_full[c] = X_train_full[c].apply(lambda x: np.log(x) if x > 0 else 0)\n",
    "    X_test[c] = X_test[c].apply(lambda x: np.log(x) if x > 0 else 0)\n",
    "\n",
    "# Scaling\n",
    "X_train_full = scaler.fit_transform(X_train_full)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "np.isnan(X_train_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2c286bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8677, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg min between sent tnx</th>\n",
       "      <th>Avg min between received tnx</th>\n",
       "      <th>Time Diff between first and last (Mins)</th>\n",
       "      <th>Unique Received From Addresses</th>\n",
       "      <th>min value received</th>\n",
       "      <th>max value received</th>\n",
       "      <th>avg val received</th>\n",
       "      <th>min val sent</th>\n",
       "      <th>avg val sent</th>\n",
       "      <th>total transactions (including tnx to create contract</th>\n",
       "      <th>total ether received</th>\n",
       "      <th>total ether balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2613</th>\n",
       "      <td>628.48</td>\n",
       "      <td>672.28</td>\n",
       "      <td>4486.98</td>\n",
       "      <td>2</td>\n",
       "      <td>0.740937</td>\n",
       "      <td>6.126160</td>\n",
       "      <td>3.433549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.372346</td>\n",
       "      <td>7</td>\n",
       "      <td>6.867097</td>\n",
       "      <td>0.005369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9439</th>\n",
       "      <td>5.95</td>\n",
       "      <td>16359.54</td>\n",
       "      <td>540043.22</td>\n",
       "      <td>10</td>\n",
       "      <td>0.011089</td>\n",
       "      <td>99.703158</td>\n",
       "      <td>18.683700</td>\n",
       "      <td>0.534594</td>\n",
       "      <td>20.551363</td>\n",
       "      <td>63</td>\n",
       "      <td>616.562105</td>\n",
       "      <td>0.021228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3982</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.23</td>\n",
       "      <td>1</td>\n",
       "      <td>59.995000</td>\n",
       "      <td>59.995000</td>\n",
       "      <td>59.995000</td>\n",
       "      <td>59.994528</td>\n",
       "      <td>59.994528</td>\n",
       "      <td>2</td>\n",
       "      <td>59.995000</td>\n",
       "      <td>0.000472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>1112.15</td>\n",
       "      <td>1644.37</td>\n",
       "      <td>717228.55</td>\n",
       "      <td>3</td>\n",
       "      <td>0.105162</td>\n",
       "      <td>31.953425</td>\n",
       "      <td>0.328026</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0.330100</td>\n",
       "      <td>520</td>\n",
       "      <td>85.614673</td>\n",
       "      <td>0.118807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Avg min between sent tnx  Avg min between received tnx  \\\n",
       "2613                    628.48                        672.28   \n",
       "9439                      5.95                      16359.54   \n",
       "2121                      0.00                          0.00   \n",
       "3982                      0.00                          0.00   \n",
       "9985                   1112.15                       1644.37   \n",
       "\n",
       "      Time Diff between first and last (Mins)  Unique Received From Addresses  \\\n",
       "2613                                  4486.98                               2   \n",
       "9439                                540043.22                              10   \n",
       "2121                                     0.00                               0   \n",
       "3982                                     2.23                               1   \n",
       "9985                                717228.55                               3   \n",
       "\n",
       "      min value received  max value received   avg val received  min val sent  \\\n",
       "2613            0.740937             6.126160          3.433549      0.000000   \n",
       "9439            0.011089            99.703158         18.683700      0.534594   \n",
       "2121            0.000000             0.000000          0.000000      0.000000   \n",
       "3982           59.995000            59.995000         59.995000     59.994528   \n",
       "9985            0.105162            31.953425          0.328026      0.000546   \n",
       "\n",
       "      avg val sent  total transactions (including tnx to create contract  \\\n",
       "2613      1.372346                                                  7      \n",
       "9439     20.551363                                                 63      \n",
       "2121      0.000000                                                  0      \n",
       "3982     59.994528                                                  2      \n",
       "9985      0.330100                                                520      \n",
       "\n",
       "      total ether received  total ether balance  \n",
       "2613              6.867097             0.005369  \n",
       "9439            616.562105             0.021228  \n",
       "2121              0.000000             0.000000  \n",
       "3982             59.995000             0.000472  \n",
       "9985             85.614673             0.118807  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "print(X_train_full.shape)\n",
    "X_train_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8d93a698",
   "metadata": {
    "id": "8d93a698"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Engineering\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "columns = ['Avg min between sent tnx', 'Avg min between received tnx',\n",
    "       'Time Diff between first and last (Mins)',\n",
    "       'Unique Received From Addresses', 'min value received',\n",
    "       'max value received ', 'avg val received', 'min val sent',\n",
    "       'avg val sent', 'total transactions (including tnx to create contract',\n",
    "       'total ether received', 'total ether balance']\n",
    "    \n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Log for Skewed Data\n",
    "# log on both train and test data\n",
    "for c in columns:\n",
    "    X_train_full[c] = X_train_full[c].apply(lambda x: np.log(x) if x > 0 else 0)\n",
    "    X_test[c] = X_test[c].apply(lambda x: np.log(x) if x > 0 else 0)\n",
    "\n",
    "# Scaling\n",
    "# only use training data to fit, to avoid data leakage\n",
    "X_train_full = scaler.fit_transform(X_train_full)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "np.isnan(X_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3bb509ec",
   "metadata": {
    "id": "3bb509ec"
   },
   "outputs": [],
   "source": [
    "#Optimal Parameters for each model from hyperparameter tuning\n",
    "tabnet_params = {'gamma': 1.0, \n",
    "                 'lambda_sparse': 0, \n",
    "                 'momentum': 0.4, \n",
    "                 'n_steps': 8, \n",
    "                 'optimizer_params': {'lr': 0.025}, \n",
    "                 'verbose': 0}\n",
    "\n",
    "xgb_params = {'learning_rate': 0.05, \n",
    "              'max_depth': 8, \n",
    "              'n_estimators': 1000}\n",
    "\n",
    "\n",
    "mlp_params = {'input_dim': X_train_full.shape[1],\n",
    "              'H': 60,\n",
    "              'activation': 'relu',\n",
    "              'dropout_probability': 0.2,\n",
    "              'num_epochs': 75,\n",
    "              'num_layers': 10}\n",
    "\n",
    "svm_params = {'C': 1000, \n",
    "              'gamma': 1}\n",
    "\n",
    "rf_params = {'max_depth': 20, \n",
    "               'min_samples_leaf': 5,\n",
    "               'n_jobs': -1}\n",
    "\n",
    "lightgbm_params = {\"bagging_fraction\": 0.95, \n",
    "                   \"bagging_freq\": 1,\n",
    "                   \"feature_fraction\": 0.95,\n",
    "                   \"learning_rate\": 0.2,\n",
    "                   \"max_bin\": 300, \n",
    "                   \"max_depth\": 6,\n",
    "                   \"min_gain_to_split\": 0,\n",
    "                   \"num_leaves\": 20}\n",
    "\n",
    "\n",
    "def compile_mlp(input_dim, H, num_epochs, num_layers, activation, dropout_probability):\n",
    "    # Creating Sequential MLP\n",
    "    model_n = Sequential()\n",
    "    model_n.add(layers.Dense(H, input_shape=(input_dim, ), activation= activation))\n",
    "\n",
    "    for _ in range(num_layers - 1):\n",
    "        model_n.add(layers.Dense(H, activation= activation, kernel_constraint=MaxNorm(3)))\n",
    "        model_n.add(layers.Dropout(dropout_probability))\n",
    "\n",
    "    model_n.add(layers.Dense(1, activation='sigmoid'))\n",
    "    # configure the model\n",
    "    model_n.compile(loss='binary_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.AUC(from_logits=True)])\n",
    "    return model_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9c034817",
   "metadata": {
    "id": "9c034817",
    "outputId": "68793b80-bd69-4c82-9aa0-26c4579c3df0"
   },
   "outputs": [],
   "source": [
    "# get a list of models to evaluate\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    mlp = KerasClassifier(model = compile_mlp, **mlp_params)\n",
    "    tabnet = TabNetClassifier(**tabnet_params)\n",
    "    models['tabnet'] = tabnet\n",
    "    models['svm'] = svm.SVC(**svm_params)\n",
    "    models['xgboost'] = XGBClassifier(**xgb_params)\n",
    "    models['mlp'] = mlp\n",
    "    models['lightGBM'] = lgb.LGBMClassifier(**lightgbm_params)\n",
    "    models['randomforest'] = RandomForestClassifier(**rf_params)\n",
    "    return models\n",
    " \n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedKFold(n_splits=5, n_repeats=1, random_state=42)\n",
    "    scores = cross_val_score(model, X, y, scoring='f1', cv=cv, n_jobs=-1)#, error_score='raise')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "805bf398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">tabnet 0.905 (0.011)\n",
      ">svm 0.914 (0.006)\n",
      ">xgboost 0.925 (0.005)\n",
      ">mlp 0.822 (0.024)\n",
      ">lightGBM 0.923 (0.003)\n",
      ">randomforest 0.908 (0.006)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 792x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define dataset\n",
    "X, y = X_train_full, y_train_full\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, X, y)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, np.mean(scores), np.std(scores)))\n",
    "# plot model performance for comparison\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b017856f",
   "metadata": {
    "id": "b017856f",
    "outputId": "12322ef9-efc2-49ab-d6cd-b84e8d4e160f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272/272 [==============================] - 2s 2ms/step - loss: 0.5037 - auc_32: 0.8287\n",
      "117/117 [==============================] - 0s 569us/step\n",
      "117/117 [==============================] - 0s 724us/step\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "\n",
    "#Creating Stacking model - Initialized using logistic regression model\n",
    "def get_stacking():\n",
    "    # define the base models\n",
    "    level0 = list()\n",
    "    for key,value in get_models().items():\n",
    "        try:\n",
    "            value._estimator_type = 'classifier'\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        finally:\n",
    "            level0.append([key,value])\n",
    "    # define meta learner model\n",
    "    level1 = LogisticRegression()\n",
    "    # define the stacking ensemble\n",
    "    model = StackingClassifier(estimators=level0, final_estimator=level1, cv= 5, n_jobs = -1)\n",
    "    return model\n",
    "\n",
    "#Pipeline to get all models\n",
    "def get_models2():\n",
    "    models = dict()\n",
    "    models['tabnet'] = TabNetClassifier(**tabnet_params)\n",
    "    models['svm'] = svm.SVC(**svm_params)\n",
    "    models['xgboost'] = XGBClassifier(**xgb_params)\n",
    "    models['mlp'] = KerasClassifier(model = compile_mlp, **mlp_params)\n",
    "    models['lightGBM'] = lgb.LGBMClassifier()\n",
    "    models['stacking'] = get_stacking()\n",
    "    return models\n",
    "\n",
    "#Getting predictions from all models to evaluate performance on test set\n",
    "predictions, names2, timing_list = list(), list(), list()\n",
    "for name, model in get_models2().items():\n",
    "    current_time = time.time()\n",
    "    model.fit(X, y)\n",
    "    predictions.append(model.predict(X_test))\n",
    "    names2.append(name)\n",
    "    final_time = time.time()\n",
    "    timing_list.append(final_time - current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e090999a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Time taken</th>\n",
       "      <th>Optimal Parameters</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lightGBM</td>\n",
       "      <td>0.106529</td>\n",
       "      <td>{'bagging_fraction': 0.95, 'bagging_freq': 1, ...</td>\n",
       "      <td>0.953226</td>\n",
       "      <td>0.956108</td>\n",
       "      <td>0.919775</td>\n",
       "      <td>0.937590</td>\n",
       "      <td>0.946838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>stacking</td>\n",
       "      <td>198.347178</td>\n",
       "      <td>None</td>\n",
       "      <td>0.952688</td>\n",
       "      <td>0.952070</td>\n",
       "      <td>0.922590</td>\n",
       "      <td>0.937098</td>\n",
       "      <td>0.946941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>2.903730</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 8, 'n_est...</td>\n",
       "      <td>0.951882</td>\n",
       "      <td>0.954612</td>\n",
       "      <td>0.917664</td>\n",
       "      <td>0.935773</td>\n",
       "      <td>0.945348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svm</td>\n",
       "      <td>3.334639</td>\n",
       "      <td>{'C': 1000, 'gamma': 1}</td>\n",
       "      <td>0.942742</td>\n",
       "      <td>0.933908</td>\n",
       "      <td>0.914849</td>\n",
       "      <td>0.924280</td>\n",
       "      <td>0.937416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tabnet</td>\n",
       "      <td>58.456848</td>\n",
       "      <td>{'gamma': 1.0, 'lambda_sparse': 0, 'momentum':...</td>\n",
       "      <td>0.936559</td>\n",
       "      <td>0.940520</td>\n",
       "      <td>0.890218</td>\n",
       "      <td>0.914678</td>\n",
       "      <td>0.927710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mlp</td>\n",
       "      <td>1.909598</td>\n",
       "      <td>{'input_dim': 12, 'H': 60, 'activation': 'relu...</td>\n",
       "      <td>0.887903</td>\n",
       "      <td>0.866959</td>\n",
       "      <td>0.834624</td>\n",
       "      <td>0.850484</td>\n",
       "      <td>0.877729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Time taken                                 Optimal Parameters  \\\n",
       "4  lightGBM    0.106529  {'bagging_fraction': 0.95, 'bagging_freq': 1, ...   \n",
       "5  stacking  198.347178                                               None   \n",
       "2   xgboost    2.903730  {'learning_rate': 0.05, 'max_depth': 8, 'n_est...   \n",
       "1       svm    3.334639                            {'C': 1000, 'gamma': 1}   \n",
       "0    tabnet   58.456848  {'gamma': 1.0, 'lambda_sparse': 0, 'momentum':...   \n",
       "3       mlp    1.909598  {'input_dim': 12, 'H': 60, 'activation': 'relu...   \n",
       "\n",
       "   Accuracy  Precision    Recall        F1   ROC-AUC  \n",
       "4  0.953226   0.956108  0.919775  0.937590  0.946838  \n",
       "5  0.952688   0.952070  0.922590  0.937098  0.946941  \n",
       "2  0.951882   0.954612  0.917664  0.935773  0.945348  \n",
       "1  0.942742   0.933908  0.914849  0.924280  0.937416  \n",
       "0  0.936559   0.940520  0.890218  0.914678  0.927710  \n",
       "3  0.887903   0.866959  0.834624  0.850484  0.877729  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, recall_score, accuracy_score, precision_score\n",
    "results_df = pd.DataFrame()\n",
    "results_df['Model'] = names2\n",
    "results_df['Time taken'] = timing_list\n",
    "results_df['Optimal Parameters'] = [tabnet_params,\n",
    "                                    svm_params,\n",
    "                                    xgb_params,\n",
    "                                    mlp_params,\n",
    "                                    lightgbm_params,\n",
    "                                    None]\n",
    "metrics_dict = {'Accuracy': accuracy_score, \n",
    "                'Precision': precision_score, \n",
    "                'Recall': recall_score, \n",
    "                'F1': f1_score, \n",
    "                'ROC-AUC': roc_auc_score}\n",
    "for metric, func in metrics_dict.items():\n",
    "    storage = []\n",
    "    for prediction in predictions:\n",
    "        storage.append(func(y_test, prediction))\n",
    "    results_df[metric] = storage\n",
    "\n",
    "results_df.sort_values(['Accuracy', 'ROC-AUC'], ascending = [False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "68b72a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('../Data/results_with_mlp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec68df3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
