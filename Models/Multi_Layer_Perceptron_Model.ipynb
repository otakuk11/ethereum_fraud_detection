{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2695,
     "status": "ok",
     "timestamp": 1668339019174,
     "user": {
      "displayName": "Darrell Lai",
      "userId": "03944376215088217788"
     },
     "user_tz": -480
    },
    "id": "eHwMiarH2aJY"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score as r2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "matplotlib.rcParams['figure.figsize'] = (13.0, 6.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1668339151866,
     "user": {
      "displayName": "Darrell Lai",
      "userId": "03944376215088217788"
     },
     "user_tz": -480
    },
    "id": "25aQ5wmiyLHA"
   },
   "outputs": [],
   "source": [
    "import scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1668339153194,
     "user": {
      "displayName": "Darrell Lai",
      "userId": "03944376215088217788"
     },
     "user_tz": -480
    },
    "id": "8_gIGsYxzCgf"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 807,
     "status": "ok",
     "timestamp": 1668339063341,
     "user": {
      "displayName": "Darrell Lai",
      "userId": "03944376215088217788"
     },
     "user_tz": -480
    },
    "id": "XGdXgHApf2Ah"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../Data/address_data_combined.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tkK6CQBZLiz"
   },
   "source": [
    "# Do Grid Search on K-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1668339154679,
     "user": {
      "displayName": "Darrell Lai",
      "userId": "03944376215088217788"
     },
     "user_tz": -480
    },
    "id": "vehkmxe-zfZP",
    "outputId": "29c940e8-2d7b-4b22-d0c1-9098b9834fd7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-cf3e69c6-9ada-455e-bec2-7bc3d4868b56\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address</th>\n",
       "      <th>FLAG</th>\n",
       "      <th>Avg min between sent tnx</th>\n",
       "      <th>Avg min between received tnx</th>\n",
       "      <th>Time Diff between first and last (Mins)</th>\n",
       "      <th>Unique Received From Addresses</th>\n",
       "      <th>min value received</th>\n",
       "      <th>max value received</th>\n",
       "      <th>avg val received</th>\n",
       "      <th>min val sent</th>\n",
       "      <th>avg val sent</th>\n",
       "      <th>total transactions (including tnx to create contract</th>\n",
       "      <th>total ether received</th>\n",
       "      <th>total ether balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x87d884aaa6ff9e9b6014631b0abae80b53953fb8</td>\n",
       "      <td>1</td>\n",
       "      <td>5151.68</td>\n",
       "      <td>15159.08</td>\n",
       "      <td>71235.62</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.013367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.040100</td>\n",
       "      <td>0.040100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0xd42393df90d582bd8a5493171f0173e3a017d391</td>\n",
       "      <td>1</td>\n",
       "      <td>1179.02</td>\n",
       "      <td>1124.89</td>\n",
       "      <td>25126.45</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.176667</td>\n",
       "      <td>0.145000</td>\n",
       "      <td>0.419270</td>\n",
       "      <td>22</td>\n",
       "      <td>2.650000</td>\n",
       "      <td>-0.284889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x3025c36d8a9620d3df89e9e9b1acbdfd639a6f37</td>\n",
       "      <td>1</td>\n",
       "      <td>361.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>723.47</td>\n",
       "      <td>1</td>\n",
       "      <td>4.999916</td>\n",
       "      <td>4.999916</td>\n",
       "      <td>4.999916</td>\n",
       "      <td>2.490000</td>\n",
       "      <td>2.499538</td>\n",
       "      <td>3</td>\n",
       "      <td>4.999916</td>\n",
       "      <td>0.000840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x6309f709faad518fc158af4c14edfa7b06424770</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x3d020954e30c3d40b7f0c533cf198bc10dd45a49</td>\n",
       "      <td>1</td>\n",
       "      <td>14280.60</td>\n",
       "      <td>1479.86</td>\n",
       "      <td>45357.57</td>\n",
       "      <td>21</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.099286</td>\n",
       "      <td>2.084658</td>\n",
       "      <td>2.084658</td>\n",
       "      <td>22</td>\n",
       "      <td>2.085000</td>\n",
       "      <td>0.000342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf3e69c6-9ada-455e-bec2-7bc3d4868b56')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-cf3e69c6-9ada-455e-bec2-7bc3d4868b56 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-cf3e69c6-9ada-455e-bec2-7bc3d4868b56');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                      Address  FLAG  Avg min between sent tnx  \\\n",
       "0  0x87d884aaa6ff9e9b6014631b0abae80b53953fb8     1                   5151.68   \n",
       "1  0xd42393df90d582bd8a5493171f0173e3a017d391     1                   1179.02   \n",
       "2  0x3025c36d8a9620d3df89e9e9b1acbdfd639a6f37     1                    361.73   \n",
       "3  0x6309f709faad518fc158af4c14edfa7b06424770     1                      0.00   \n",
       "4  0x3d020954e30c3d40b7f0c533cf198bc10dd45a49     1                  14280.60   \n",
       "\n",
       "   Avg min between received tnx  Time Diff between first and last (Mins)  \\\n",
       "0                      15159.08                                 71235.62   \n",
       "1                       1124.89                                 25126.45   \n",
       "2                          0.00                                   723.47   \n",
       "3                          0.00                                     0.00   \n",
       "4                       1479.86                                 45357.57   \n",
       "\n",
       "   Unique Received From Addresses  min value received  max value received   \\\n",
       "0                               1            0.010000             0.020000   \n",
       "1                              13            0.000000             0.750000   \n",
       "2                               1            4.999916             4.999916   \n",
       "3                               0            0.000000             0.000000   \n",
       "4                              21            0.035000             0.200000   \n",
       "\n",
       "   avg val received  min val sent  avg val sent  \\\n",
       "0          0.013367      0.000000      0.000000   \n",
       "1          0.176667      0.145000      0.419270   \n",
       "2          4.999916      2.490000      2.499538   \n",
       "3          0.000000      0.000000      0.000000   \n",
       "4          0.099286      2.084658      2.084658   \n",
       "\n",
       "   total transactions (including tnx to create contract  total ether received  \\\n",
       "0                                                  8                 0.040100   \n",
       "1                                                 22                 2.650000   \n",
       "2                                                  3                 4.999916   \n",
       "3                                                  0                 0.000000   \n",
       "4                                                 22                 2.085000   \n",
       "\n",
       "   total ether balance  \n",
       "0             0.040100  \n",
       "1            -0.284889  \n",
       "2             0.000840  \n",
       "3             0.000000  \n",
       "4             0.000342  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 409,
     "status": "ok",
     "timestamp": 1668341806895,
     "user": {
      "displayName": "Darrell Lai",
      "userId": "03944376215088217788"
     },
     "user_tz": -480
    },
    "id": "1_8aeu8kzioi"
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Address', 'FLAG'])\n",
    "y = df['FLAG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "executionInfo": {
     "elapsed": 417,
     "status": "ok",
     "timestamp": 1668341810382,
     "user": {
      "displayName": "Darrell Lai",
      "userId": "03944376215088217788"
     },
     "user_tz": -480
    },
    "id": "clI0vtAAzo7y",
    "outputId": "81c69ee0-aace-4cad-da2a-36b976d7da76"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-87fe61e5-7c39-4854-9762-b590ddb17c74\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg min between sent tnx</th>\n",
       "      <th>Avg min between received tnx</th>\n",
       "      <th>Time Diff between first and last (Mins)</th>\n",
       "      <th>Unique Received From Addresses</th>\n",
       "      <th>min value received</th>\n",
       "      <th>max value received</th>\n",
       "      <th>avg val received</th>\n",
       "      <th>min val sent</th>\n",
       "      <th>avg val sent</th>\n",
       "      <th>total transactions (including tnx to create contract</th>\n",
       "      <th>total ether received</th>\n",
       "      <th>total ether balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5151.68</td>\n",
       "      <td>15159.08</td>\n",
       "      <td>71235.62</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.013367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.040100</td>\n",
       "      <td>0.040100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1179.02</td>\n",
       "      <td>1124.89</td>\n",
       "      <td>25126.45</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.176667</td>\n",
       "      <td>0.145000</td>\n",
       "      <td>0.419270</td>\n",
       "      <td>22</td>\n",
       "      <td>2.650000</td>\n",
       "      <td>-0.284889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>361.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>723.47</td>\n",
       "      <td>1</td>\n",
       "      <td>4.999916</td>\n",
       "      <td>4.999916</td>\n",
       "      <td>4.999916</td>\n",
       "      <td>2.490000</td>\n",
       "      <td>2.499538</td>\n",
       "      <td>3</td>\n",
       "      <td>4.999916</td>\n",
       "      <td>0.000840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14280.60</td>\n",
       "      <td>1479.86</td>\n",
       "      <td>45357.57</td>\n",
       "      <td>21</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.099286</td>\n",
       "      <td>2.084658</td>\n",
       "      <td>2.084658</td>\n",
       "      <td>22</td>\n",
       "      <td>2.085000</td>\n",
       "      <td>0.000342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87fe61e5-7c39-4854-9762-b590ddb17c74')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-87fe61e5-7c39-4854-9762-b590ddb17c74 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-87fe61e5-7c39-4854-9762-b590ddb17c74');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   Avg min between sent tnx  Avg min between received tnx  \\\n",
       "0                   5151.68                      15159.08   \n",
       "1                   1179.02                       1124.89   \n",
       "2                    361.73                          0.00   \n",
       "3                      0.00                          0.00   \n",
       "4                  14280.60                       1479.86   \n",
       "\n",
       "   Time Diff between first and last (Mins)  Unique Received From Addresses  \\\n",
       "0                                 71235.62                               1   \n",
       "1                                 25126.45                              13   \n",
       "2                                   723.47                               1   \n",
       "3                                     0.00                               0   \n",
       "4                                 45357.57                              21   \n",
       "\n",
       "   min value received  max value received   avg val received  min val sent  \\\n",
       "0            0.010000             0.020000          0.013367      0.000000   \n",
       "1            0.000000             0.750000          0.176667      0.145000   \n",
       "2            4.999916             4.999916          4.999916      2.490000   \n",
       "3            0.000000             0.000000          0.000000      0.000000   \n",
       "4            0.035000             0.200000          0.099286      2.084658   \n",
       "\n",
       "   avg val sent  total transactions (including tnx to create contract  \\\n",
       "0      0.000000                                                  8      \n",
       "1      0.419270                                                 22      \n",
       "2      2.499538                                                  3      \n",
       "3      0.000000                                                  0      \n",
       "4      2.084658                                                 22      \n",
       "\n",
       "   total ether received  total ether balance  \n",
       "0              0.040100             0.040100  \n",
       "1              2.650000            -0.284889  \n",
       "2              4.999916             0.000840  \n",
       "3              0.000000             0.000000  \n",
       "4              2.085000             0.000342  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9JOmlHh0FyAC"
   },
   "source": [
    "train-test split -- split 30% for test data and the remaining 70% for a kfolds cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "executionInfo": {
     "elapsed": 333,
     "status": "ok",
     "timestamp": 1668341934197,
     "user": {
      "displayName": "Darrell Lai",
      "userId": "03944376215088217788"
     },
     "user_tz": -480
    },
    "id": "X8KJbdVeztGB",
    "outputId": "533a27a1-c737-4724-ec6b-30e6f923f347"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9908, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-61357270-d81a-4ff8-a066-e827ff9f44ca\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg min between sent tnx</th>\n",
       "      <th>Avg min between received tnx</th>\n",
       "      <th>Time Diff between first and last (Mins)</th>\n",
       "      <th>Unique Received From Addresses</th>\n",
       "      <th>min value received</th>\n",
       "      <th>max value received</th>\n",
       "      <th>avg val received</th>\n",
       "      <th>min val sent</th>\n",
       "      <th>avg val sent</th>\n",
       "      <th>total transactions (including tnx to create contract</th>\n",
       "      <th>total ether received</th>\n",
       "      <th>total ether balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6709</th>\n",
       "      <td>17.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>51.17</td>\n",
       "      <td>1</td>\n",
       "      <td>101.0000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>10.804780</td>\n",
       "      <td>33.666149</td>\n",
       "      <td>4</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>0.001554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13808</th>\n",
       "      <td>2679.43</td>\n",
       "      <td>2841.02</td>\n",
       "      <td>275214.32</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.295850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.877316</td>\n",
       "      <td>100</td>\n",
       "      <td>103.313259</td>\n",
       "      <td>0.060902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8333</th>\n",
       "      <td>103299.49</td>\n",
       "      <td>37551.75</td>\n",
       "      <td>826452.87</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>52.532971</td>\n",
       "      <td>23.290155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.627500</td>\n",
       "      <td>15</td>\n",
       "      <td>163.031084</td>\n",
       "      <td>30.011085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6981</th>\n",
       "      <td>4756.98</td>\n",
       "      <td>11283.84</td>\n",
       "      <td>46352.60</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>9.975152</td>\n",
       "      <td>10.194942</td>\n",
       "      <td>7</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>-19.974711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61357270-d81a-4ff8-a066-e827ff9f44ca')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-61357270-d81a-4ff8-a066-e827ff9f44ca button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-61357270-d81a-4ff8-a066-e827ff9f44ca');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       Avg min between sent tnx  Avg min between received tnx  \\\n",
       "6709                      17.06                          0.00   \n",
       "13808                   2679.43                       2841.02   \n",
       "8333                  103299.49                      37551.75   \n",
       "6981                    4756.98                      11283.84   \n",
       "676                        0.00                          0.00   \n",
       "\n",
       "       Time Diff between first and last (Mins)  \\\n",
       "6709                                     51.17   \n",
       "13808                                275214.32   \n",
       "8333                                 826452.87   \n",
       "6981                                  46352.60   \n",
       "676                                       0.00   \n",
       "\n",
       "       Unique Received From Addresses  min value received  \\\n",
       "6709                                1            101.0000   \n",
       "13808                              21              0.0001   \n",
       "8333                                6              0.0000   \n",
       "6981                                1             11.0000   \n",
       "676                                 0              0.0000   \n",
       "\n",
       "       max value received   avg val received  min val sent  avg val sent  \\\n",
       "6709            101.000000        101.000000     10.804780     33.666149   \n",
       "13808            15.000000          2.295850      0.000000      1.877316   \n",
       "8333             52.532971         23.290155      0.000000     16.627500   \n",
       "6981             20.000000         15.500000      9.975152     10.194942   \n",
       "676               0.000000          0.000000      0.000000      0.000000   \n",
       "\n",
       "       total transactions (including tnx to create contract  \\\n",
       "6709                                                   4      \n",
       "13808                                                100      \n",
       "8333                                                  15      \n",
       "6981                                                   7      \n",
       "676                                                    0      \n",
       "\n",
       "       total ether received  total ether balance  \n",
       "6709             101.000000             0.001554  \n",
       "13808            103.313259             0.060902  \n",
       "8333             163.031084            30.011085  \n",
       "6981              31.000000           -19.974711  \n",
       "676                0.000000             0.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "print(X_train_full.shape)\n",
    "X_train_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JeShwDT9prH"
   },
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 416,
     "status": "ok",
     "timestamp": 1668341938170,
     "user": {
      "displayName": "Darrell Lai",
      "userId": "03944376215088217788"
     },
     "user_tz": -480
    },
    "id": "rZfAUdeC8Nwl",
    "outputId": "84508266-f49f-4c1b-b2e5-6b7fc50e13d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Engineering\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "columns = ['Avg min between sent tnx', 'Avg min between received tnx',\n",
    "       'Time Diff between first and last (Mins)',\n",
    "       'Unique Received From Addresses', 'min value received',\n",
    "       'max value received ', 'avg val received', 'min val sent',\n",
    "       'avg val sent', 'total transactions (including tnx to create contract',\n",
    "       'total ether received', 'total ether balance']\n",
    "    \n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Log for Skewed Data\n",
    "# log on both train and test data\n",
    "for c in columns:\n",
    "  X_train_full[c] = X_train_full[c].apply(lambda x: np.log(x) if x > 0 else 0)\n",
    "  X_test[c] = X_test[c].apply(lambda x: np.log(x) if x > 0 else 0)\n",
    "\n",
    "# Scaling\n",
    "# only use training data to fit, to avoid data leakage\n",
    "X_train_full = scaler.fit_transform(X_train_full)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "np.isnan(X_train_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EaO6STY8DOEi"
   },
   "source": [
    "make scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1668341951603,
     "user": {
      "displayName": "Darrell Lai",
      "userId": "03944376215088217788"
     },
     "user_tz": -480
    },
    "id": "aKQ7UItGC22o"
   },
   "outputs": [],
   "source": [
    "from keras.metrics import Recall, RecallAtPrecision\n",
    "# metrics to evaluate is the highest recall we can get for a precision above 0.75\n",
    "RecallAtPrecision_scorer = RecallAtPrecision(precision=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuSYG93WFSqE"
   },
   "source": [
    "define function that returns a compiled MLP. no training yet. the arguments can be tweaked to include the parameters you want to search over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 569,
     "status": "ok",
     "timestamp": 1668341962400,
     "user": {
      "displayName": "Darrell Lai",
      "userId": "03944376215088217788"
     },
     "user_tz": -480
    },
    "id": "RMtBoTV520Fy"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "def compile_mlp(input_dim, H, num_epochs, num_layers, activation, dropout_probability):\n",
    "\n",
    "  # Creating Sequential MLP\n",
    "  model_n = Sequential()\n",
    "\n",
    "  model_n.add(layers.Dense(H, input_shape=(input_dim, ), activation= activation))\n",
    "\n",
    "  for _ in range(num_layers - 1):\n",
    "      model_n.add(layers.Dense(H, activation= activation, kernel_constraint=MaxNorm(3)))\n",
    "      model_n.add(layers.Dropout(dropout_probability))\n",
    "\n",
    "  model_n.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "  # configure the model\n",
    "  # use F1 score beause it balances between preciison and recall\n",
    "  model_n.compile(loss='binary_crossentropy', optimizer='adam', metrics=[RecallAtPrecision_scorer])\n",
    "  # model_n.compile(loss='binary_crossentropy', optimizer='adam', metrics=[Recall])\n",
    "  return model_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ssuQDhiFFH-U"
   },
   "source": [
    "set initial parameters and compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wEunAT_lyRVQ"
   },
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "# def compile_mlp(input_dim, H, num_epochs, num_layers, activation_function):\n",
    "# number of hidden nodes\n",
    "H = 10\n",
    "# num of epochs\n",
    "num_epochs = 50\n",
    "# num_layers\n",
    "num_layers = 3\n",
    "# activation function\n",
    "activation_function = 'relu'\n",
    "#dropout probability\n",
    "dropout_probability = 0.2\n",
    "# input dim\n",
    "input_dim = X_train_full.shape[1]\n",
    "\n",
    "model = KerasClassifier(model=compile_mlp, input_dim=input_dim, H=H, num_epochs=num_epochs, num_layers=num_layers, activation=activation_function, dropout_probability=dropout_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JEhsvmqKFN9n"
   },
   "source": [
    "set search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ux7D07jtpkTR"
   },
   "outputs": [],
   "source": [
    "param_grid = {'activation':('relu', 'tanh', 'sigmoid'), \n",
    "              'H': [40, 50, 60, 70, 80],\n",
    "              'num_epochs': [75, 100],\n",
    "              'num_layers': [7, 8, 9, 10, 11, 12],\n",
    "              'dropout_probability': [0.2, 0.3]}\n",
    "# param_grid = {'H': [5, 10],\n",
    "#               'num_layers': [3, 4, 5]}\n",
    "\n",
    "# param_grid = dict(H=[5,10], num_layers=[3,4])\n",
    "seed = 42\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eg9LgmIgFPt6"
   },
   "source": [
    "do grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0V7a5bYppkV4"
   },
   "outputs": [],
   "source": [
    "grid = GridSearchCV(model, param_grid=param_grid, cv=5, verbose=2, scoring= 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 706585,
     "status": "ok",
     "timestamp": 1667478752079,
     "user": {
      "displayName": "Victor Wong",
      "userId": "11168613095769754614"
     },
     "user_tz": -480
    },
    "id": "oZGGI8HnpkYW",
    "outputId": "f598580e-4950-49a3-853e-575f11e40d10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.5632 - recall_at_precision: 0.3371\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   2.9s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.5424 - recall_at_precision: 0.3393\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   3.8s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.5523 - recall_at_precision: 0.3415\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   3.3s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.5477 - recall_at_precision: 0.3432\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   3.4s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.5473 - recall_at_precision: 0.3454\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   3.1s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.6158 - recall_at_precision: 0.3262\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   3.3s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.5807 - recall_at_precision: 0.3280\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   3.8s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.5754 - recall_at_precision: 0.3298\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   3.2s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.5593 - recall_at_precision: 0.3316\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   3.5s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.5656 - recall_at_precision: 0.3334\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   3.4s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.5494 - recall_at_precision: 0.3355\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   3.2s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5563 - recall_at_precision: 0.3374\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   3.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5661 - recall_at_precision: 0.3391\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   5.6s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5214 - recall_at_precision: 0.3413\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   3.7s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.5777 - recall_at_precision: 0.3431\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   3.4s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5709 - recall_at_precision: 0.3447\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   3.6s\n",
      "248/248 [==============================] - 2s 3ms/step - loss: 0.4993 - recall_at_precision: 0.3468\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   3.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5301 - recall_at_precision: 0.3487\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   5.0s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.5183 - recall_at_precision: 0.3506\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   3.6s\n",
      "248/248 [==============================] - 2s 3ms/step - loss: 0.5173 - recall_at_precision: 0.3527\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   2.9s\n",
      "248/248 [==============================] - 2s 3ms/step - loss: 0.5280 - recall_at_precision: 0.3545\n",
      "62/62 [==============================] - 0s 1ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   2.9s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.5321 - recall_at_precision: 0.3564\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   2.6s\n",
      "248/248 [==============================] - 3s 3ms/step - loss: 0.4898 - recall_at_precision: 0.3585\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   3.4s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.4860 - recall_at_precision: 0.3607\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   2.6s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.5334 - recall_at_precision: 0.3625\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   2.7s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.5124 - recall_at_precision: 0.3645\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   3.0s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.5197 - recall_at_precision: 0.3663\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   3.2s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.5387 - recall_at_precision: 0.3679\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   3.7s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.5314 - recall_at_precision: 0.3695\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   3.4s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.5214 - recall_at_precision: 0.3715\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   5.3s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.5264 - recall_at_precision: 0.3732\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   2.8s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.5045 - recall_at_precision: 0.3750\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   3.3s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.5531 - recall_at_precision: 0.3764\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   3.4s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.5413 - recall_at_precision: 0.3779\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   3.7s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.5168 - recall_at_precision: 0.3797\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   3.2s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.5532 - recall_at_precision: 0.3811\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   3.1s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5312 - recall_at_precision: 0.3826\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   3.4s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.5369 - recall_at_precision: 0.3841\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   3.8s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.5275 - recall_at_precision: 0.3857\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   3.6s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5561 - recall_at_precision: 0.3871\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   3.7s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5568 - recall_at_precision: 0.3736\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   3.4s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.6020 - recall_at_precision: 0.3743\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   3.6s\n",
      "248/248 [==============================] - 4s 5ms/step - loss: 0.5611 - recall_at_precision: 0.3754\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   4.3s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.6195 - recall_at_precision: 0.3760\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   3.5s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5507 - recall_at_precision: 0.3775\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   3.6s\n",
      "248/248 [==============================] - 5s 8ms/step - loss: 0.5743 - recall_at_precision: 0.3787\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.7s\n",
      "248/248 [==============================] - 2s 3ms/step - loss: 0.5519 - recall_at_precision: 0.3799\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   2.9s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.5938 - recall_at_precision: 0.3809\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   3.1s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.5618 - recall_at_precision: 0.3820\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   2.9s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.5465 - recall_at_precision: 0.3833\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   2.9s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.6295 - recall_at_precision: 0.3716\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   3.0s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.5945 - recall_at_precision: 0.3725\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   3.1s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.6058 - recall_at_precision: 0.3733\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   2.9s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.6444 - recall_at_precision: 0.3736\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   3.4s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.5636 - recall_at_precision: 0.3749\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   3.1s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.5847 - recall_at_precision: 0.3760\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   3.1s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.5899 - recall_at_precision: 0.3769\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   2.9s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.6254 - recall_at_precision: 0.3665\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   3.0s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.5959 - recall_at_precision: 0.3674\n",
      "62/62 [==============================] - 1s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   3.7s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.6166 - recall_at_precision: 0.3681\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   3.2s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.6417 - recall_at_precision: 0.3685\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   3.1s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.6649 - recall_at_precision: 0.3584\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   3.6s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.6475 - recall_at_precision: 0.3588\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   3.4s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6062 - recall_at_precision: 0.3597\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   4.9s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.6079 - recall_at_precision: 0.3606\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   3.8s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7043 - recall_at_precision: 0.3510\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   3.3s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.6610 - recall_at_precision: 0.3512\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   3.6s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.6857 - recall_at_precision: 0.3511\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   3.4s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.6595 - recall_at_precision: 0.3427\n",
      "62/62 [==============================] - 1s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   3.9s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.6378 - recall_at_precision: 0.3432\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   3.4s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.6339 - recall_at_precision: 0.3438\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7102 - recall_at_precision: 0.3434\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.1s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.6481 - recall_at_precision: 0.3355\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   3.6s\n",
      "248/248 [==============================] - 4s 5ms/step - loss: 0.7202 - recall_at_precision: 0.3351\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   4.2s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.6398 - recall_at_precision: 0.3354\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   3.5s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7016 - recall_at_precision: 0.3273\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   3.5s\n",
      "248/248 [==============================] - 2s 3ms/step - loss: 0.5262 - recall_at_precision: 0.3286\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   2.5s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.5806 - recall_at_precision: 0.3295\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   3.0s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.5782 - recall_at_precision: 0.3303\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   5.5s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.5424 - recall_at_precision: 0.3316\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   2.9s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.5628 - recall_at_precision: 0.3327\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   2.6s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.5839 - recall_at_precision: 0.3334\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   3.0s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.6100 - recall_at_precision: 0.3339\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   3.1s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.5780 - recall_at_precision: 0.3347\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   3.0s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.5613 - recall_at_precision: 0.3357\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   3.2s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.6069 - recall_at_precision: 0.3363\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   2.9s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.6529 - recall_at_precision: 0.3364\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   3.2s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.5755 - recall_at_precision: 0.3296\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   3.3s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.6174 - recall_at_precision: 0.3301\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   3.3s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.6287 - recall_at_precision: 0.3306\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   2.8s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.5977 - recall_at_precision: 0.3313\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   3.7s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.6973 - recall_at_precision: 0.3310\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   3.3s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.6441 - recall_at_precision: 0.3314\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   3.3s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.6864 - recall_at_precision: 0.3238\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   3.1s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.6061 - recall_at_precision: 0.3245\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   3.2s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5889 - recall_at_precision: 0.3255\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.1s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.7060 - recall_at_precision: 0.3249\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.5s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.6293 - recall_at_precision: 0.3255\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   3.4s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7091 - recall_at_precision: 0.3179\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   3.4s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7078 - recall_at_precision: 0.3174\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   3.4s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.6073 - recall_at_precision: 0.3181\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   3.9s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7100 - recall_at_precision: 0.3176\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   3.8s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7140 - recall_at_precision: 0.3103\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   3.6s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.6113 - recall_at_precision: 0.3110\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   3.6s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.6832 - recall_at_precision: 0.3110\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   4.0s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7077 - recall_at_precision: 0.3104\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   3.5s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.7025 - recall_at_precision: 0.3093\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   3.1s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.7164 - recall_at_precision: 0.3019\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   2.6s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.7097 - recall_at_precision: 0.3011\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   2.5s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.6987 - recall_at_precision: 0.3001\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   3.0s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.7068 - recall_at_precision: 0.2994\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   3.5s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.7073 - recall_at_precision: 0.2986\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   2.8s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7021 - recall_at_precision: 0.2976\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   4.9s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.6989 - recall_at_precision: 0.2967\n",
      "62/62 [==============================] - 0s 4ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   5.8s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.7004 - recall_at_precision: 0.2957\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   3.9s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.7023 - recall_at_precision: 0.2885\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   3.1s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.7009 - recall_at_precision: 0.2875\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   3.8s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7278 - recall_at_precision: 0.2871\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   3.4s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.7007 - recall_at_precision: 0.2864\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   3.3s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.7079 - recall_at_precision: 0.2857\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   3.0s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.7061 - recall_at_precision: 0.2849\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   3.2s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.7070 - recall_at_precision: 0.2841\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   3.7s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7043 - recall_at_precision: 0.2772\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   3.5s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.7004 - recall_at_precision: 0.2764\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   3.4s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.7080 - recall_at_precision: 0.2757\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   3.1s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7010 - recall_at_precision: 0.2748\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   3.2s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7041 - recall_at_precision: 0.2739\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   3.9s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7056 - recall_at_precision: 0.2732\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   3.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7053 - recall_at_precision: 0.2725\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   5.1s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7047 - recall_at_precision: 0.2717\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   3.9s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.6992 - recall_at_precision: 0.2708\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   3.5s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7036 - recall_at_precision: 0.2700\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   4.1s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7078 - recall_at_precision: 0.2694\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   3.5s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7018 - recall_at_precision: 0.2626\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   4.8s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7026 - recall_at_precision: 0.2618\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   3.5s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7053 - recall_at_precision: 0.2610\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   3.9s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.7069 - recall_at_precision: 0.2604\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   2.9s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.7086 - recall_at_precision: 0.2598\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   2.9s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.7117 - recall_at_precision: 0.2590\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   2.6s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.7059 - recall_at_precision: 0.2583\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   2.6s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.7071 - recall_at_precision: 0.2576\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   2.9s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.7020 - recall_at_precision: 0.2568\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   3.6s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.7061 - recall_at_precision: 0.2561\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   2.8s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.7032 - recall_at_precision: 0.2497\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   2.8s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.7013 - recall_at_precision: 0.2490\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   2.8s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.7045 - recall_at_precision: 0.2484\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   3.3s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.7065 - recall_at_precision: 0.2477\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.1s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.7000 - recall_at_precision: 0.2470\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   3.6s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.7061 - recall_at_precision: 0.2464\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   2.9s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7075 - recall_at_precision: 0.2457\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   3.3s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.7045 - recall_at_precision: 0.2450\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   3.4s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.6979 - recall_at_precision: 0.2442\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   3.2s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7025 - recall_at_precision: 0.2434\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   3.7s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7007 - recall_at_precision: 0.2426\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   3.2s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7060 - recall_at_precision: 0.2420\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   3.4s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.7027 - recall_at_precision: 0.2413\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   3.2s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.7039 - recall_at_precision: 0.2407\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   3.4s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7034 - recall_at_precision: 0.2400\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   4.1s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7063 - recall_at_precision: 0.2339\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   3.4s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7060 - recall_at_precision: 0.2333\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   3.3s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7038 - recall_at_precision: 0.2327\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   3.3s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7000 - recall_at_precision: 0.2320\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   3.5s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.7090 - recall_at_precision: 0.2315\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   6.4s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7036 - recall_at_precision: 0.2308\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   4.9s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7037 - recall_at_precision: 0.2302\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7021 - recall_at_precision: 0.2296\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   4.9s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.7073 - recall_at_precision: 0.2290\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   3.3s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.7162 - recall_at_precision: 0.2285\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   2.9s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.7093 - recall_at_precision: 0.2281\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   2.9s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.7114 - recall_at_precision: 0.2276\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   2.6s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.7080 - recall_at_precision: 0.2270\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   2.6s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.7130 - recall_at_precision: 0.2212\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   3.1s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.7132 - recall_at_precision: 0.2208\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   3.3s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.7130 - recall_at_precision: 0.2204\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   3.2s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.7161 - recall_at_precision: 0.2200\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   2.7s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.7126 - recall_at_precision: 0.2196\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   2.9s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.7091 - recall_at_precision: 0.2191\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   3.2s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.7409 - recall_at_precision: 0.2190\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   3.2s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.7170 - recall_at_precision: 0.2185\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.9s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.7125 - recall_at_precision: 0.2181\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   3.2s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.7144 - recall_at_precision: 0.2126\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   3.1s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.7112 - recall_at_precision: 0.2121\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   3.4s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7110 - recall_at_precision: 0.2116\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   3.3s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7001 - recall_at_precision: 0.2110\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   3.7s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7118 - recall_at_precision: 0.2106\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   3.4s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7145 - recall_at_precision: 0.2101\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   3.3s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7057 - recall_at_precision: 0.2095\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   3.6s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7053 - recall_at_precision: 0.2089\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   3.3s\n",
      "248/248 [==============================] - 4s 5ms/step - loss: 0.7129 - recall_at_precision: 0.2085\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.0s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7113 - recall_at_precision: 0.2081\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   3.5s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7118 - recall_at_precision: 0.2077\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   3.4s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7106 - recall_at_precision: 0.2072\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   3.8s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7114 - recall_at_precision: 0.2068\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7114 - recall_at_precision: 0.2015\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   4.7s\n",
      "248/248 [==============================] - 4s 5ms/step - loss: 0.7132 - recall_at_precision: 0.2011\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   4.7s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7095 - recall_at_precision: 0.2006\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.7098 - recall_at_precision: 0.2002\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   3.2s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.7126 - recall_at_precision: 0.1998\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   3.1s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.7157 - recall_at_precision: 0.1994\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   6.3s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.7101 - recall_at_precision: 0.1990\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   3.1s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.7154 - recall_at_precision: 0.1986\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   2.9s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.7169 - recall_at_precision: 0.1982\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   3.1s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.7052 - recall_at_precision: 0.1977\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   3.1s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.7079 - recall_at_precision: 0.1973\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   3.1s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.7133 - recall_at_precision: 0.1969\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   3.5s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.7048 - recall_at_precision: 0.1965\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   2.9s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.7136 - recall_at_precision: 0.1916\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   3.2s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7120 - recall_at_precision: 0.1911\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   3.2s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.7157 - recall_at_precision: 0.1907\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   3.2s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.7144 - recall_at_precision: 0.1903\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   5.5s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.7087 - recall_at_precision: 0.1899\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   3.2s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7154 - recall_at_precision: 0.1896\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   3.3s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7108 - recall_at_precision: 0.1892\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   3.2s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7117 - recall_at_precision: 0.1888\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   3.4s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7110 - recall_at_precision: 0.1885\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   3.7s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.7082 - recall_at_precision: 0.1881\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   3.3s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7121 - recall_at_precision: 0.1878\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   3.5s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7094 - recall_at_precision: 0.1874\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   5.0s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7143 - recall_at_precision: 0.1871\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   3.6s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7094 - recall_at_precision: 0.1867\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.0s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7096 - recall_at_precision: 0.1818\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   3.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7284 - recall_at_precision: 0.1816\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7073 - recall_at_precision: 0.1812\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   3.5s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7109 - recall_at_precision: 0.1808\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.1s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7193 - recall_at_precision: 0.1805\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   4.8s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7115 - recall_at_precision: 0.1800\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=40, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   4.9s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.5308 - recall_at_precision: 0.1806\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   2.7s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.5172 - recall_at_precision: 0.1813\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   2.9s\n",
      "248/248 [==============================] - 2s 5ms/step - loss: 0.5155 - recall_at_precision: 0.1818\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   2.9s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.5480 - recall_at_precision: 0.1824\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   3.2s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.5432 - recall_at_precision: 0.1873\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   3.0s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.5860 - recall_at_precision: 0.1873\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   3.1s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5732 - recall_at_precision: 0.1875\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   3.2s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5154 - recall_at_precision: 0.1879\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   3.1s\n",
      "248/248 [==============================] - 2s 5ms/step - loss: 0.5989 - recall_at_precision: 0.1880\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   3.0s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5680 - recall_at_precision: 0.1882\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   3.5s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5424 - recall_at_precision: 0.1886\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   3.1s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5757 - recall_at_precision: 0.1888\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5533 - recall_at_precision: 0.1892\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   3.3s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5959 - recall_at_precision: 0.1893\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   3.1s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5599 - recall_at_precision: 0.1896\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   5.6s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5793 - recall_at_precision: 0.1898\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   3.5s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5625 - recall_at_precision: 0.1899\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   4.6s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.6155 - recall_at_precision: 0.1895\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   4.6s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5763 - recall_at_precision: 0.1897\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   4.6s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5873 - recall_at_precision: 0.1897\n",
      "62/62 [==============================] - 1s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   5.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5369 - recall_at_precision: 0.1900\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   3.8s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5535 - recall_at_precision: 0.1901\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.7s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5559 - recall_at_precision: 0.1904\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   3.8s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5983 - recall_at_precision: 0.1904\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   3.6s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5366 - recall_at_precision: 0.1954\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.0s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5380 - recall_at_precision: 0.1958\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   4.9s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5561 - recall_at_precision: 0.1961\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 5s 10ms/step - loss: 0.5550 - recall_at_precision: 0.1963\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   5.4s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.6037 - recall_at_precision: 0.1961\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   4.4s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.6291 - recall_at_precision: 0.1961\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   4.3s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.5181 - recall_at_precision: 0.1966\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   2.8s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.5208 - recall_at_precision: 0.1971\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   3.0s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.5275 - recall_at_precision: 0.1976\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   3.1s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5541 - recall_at_precision: 0.1981\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   3.3s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.5130 - recall_at_precision: 0.1987\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   2.8s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5565 - recall_at_precision: 0.1991\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   3.6s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5172 - recall_at_precision: 0.1997\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   3.2s\n",
      "248/248 [==============================] - 2s 5ms/step - loss: 0.5415 - recall_at_precision: 0.2000\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   3.0s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5742 - recall_at_precision: 0.2001\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   3.1s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5591 - recall_at_precision: 0.2053\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   3.0s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5562 - recall_at_precision: 0.2056\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   3.7s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5492 - recall_at_precision: 0.2060\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5179 - recall_at_precision: 0.2064\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   3.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5984 - recall_at_precision: 0.2064\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.7s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5497 - recall_at_precision: 0.2067\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.9s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5950 - recall_at_precision: 0.2066\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.7s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5581 - recall_at_precision: 0.2068\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   5.3s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5631 - recall_at_precision: 0.2071\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   3.5s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.6288 - recall_at_precision: 0.2069\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   3.5s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5758 - recall_at_precision: 0.2071\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.7s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5406 - recall_at_precision: 0.2074\n",
      "62/62 [==============================] - 1s 3ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   5.5s\n",
      "248/248 [==============================] - 5s 8ms/step - loss: 0.5752 - recall_at_precision: 0.2074\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   6.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5489 - recall_at_precision: 0.2077\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6360 - recall_at_precision: 0.2075\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   3.9s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5516 - recall_at_precision: 0.2077\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   5.0s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5703 - recall_at_precision: 0.2079\n",
      "62/62 [==============================] - 1s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.8s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.6046 - recall_at_precision: 0.2077\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.3s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5876 - recall_at_precision: 0.2076\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   4.9s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6070 - recall_at_precision: 0.2074\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   4.0s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.6390 - recall_at_precision: 0.2071\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.5803 - recall_at_precision: 0.2071\n",
      "62/62 [==============================] - 1s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   3.6s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5804 - recall_at_precision: 0.2070\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.5991 - recall_at_precision: 0.2071\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   3.0s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.5824 - recall_at_precision: 0.2073\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   3.1s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.6194 - recall_at_precision: 0.2070\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   3.1s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5981 - recall_at_precision: 0.2069\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.6s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.6195 - recall_at_precision: 0.2066\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   3.1s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.6009 - recall_at_precision: 0.2064\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   3.6s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5870 - recall_at_precision: 0.2065\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   3.1s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5933 - recall_at_precision: 0.2118\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   3.6s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.6122 - recall_at_precision: 0.2115\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.4s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5842 - recall_at_precision: 0.2114\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   3.2s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.6292 - recall_at_precision: 0.2111\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   3.7s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5708 - recall_at_precision: 0.2112\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.6637 - recall_at_precision: 0.2107\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   3.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6437 - recall_at_precision: 0.2103\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   3.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6363 - recall_at_precision: 0.2099\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   3.7s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.6285 - recall_at_precision: 0.2096\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   5.2s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.6690 - recall_at_precision: 0.2091\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   3.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5974 - recall_at_precision: 0.2090\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   3.7s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6286 - recall_at_precision: 0.2086\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.8s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.6411 - recall_at_precision: 0.2082\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.8s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.6310 - recall_at_precision: 0.2077\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   5.5s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6210 - recall_at_precision: 0.2073\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.6357 - recall_at_precision: 0.2070\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6310 - recall_at_precision: 0.2065\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   4.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6127 - recall_at_precision: 0.2063\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.1s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.6845 - recall_at_precision: 0.2059\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6782 - recall_at_precision: 0.2054\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   4.0s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6827 - recall_at_precision: 0.2049\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   4.1s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.5455 - recall_at_precision: 0.2052\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   2.9s\n",
      "248/248 [==============================] - 2s 5ms/step - loss: 0.5576 - recall_at_precision: 0.2053\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   3.0s\n",
      "248/248 [==============================] - 3s 4ms/step - loss: 0.6180 - recall_at_precision: 0.2052\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   3.5s\n",
      "248/248 [==============================] - 2s 4ms/step - loss: 0.5906 - recall_at_precision: 0.2052\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   3.1s\n",
      "248/248 [==============================] - 2s 5ms/step - loss: 0.5735 - recall_at_precision: 0.2053\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   3.0s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.6017 - recall_at_precision: 0.2051\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   3.2s\n",
      "248/248 [==============================] - 2s 5ms/step - loss: 0.6144 - recall_at_precision: 0.2049\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   3.0s\n",
      "248/248 [==============================] - 2s 5ms/step - loss: 0.6316 - recall_at_precision: 0.2045\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   3.1s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.6184 - recall_at_precision: 0.2041\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.9s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.6140 - recall_at_precision: 0.2040\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   3.5s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.6286 - recall_at_precision: 0.2036\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5745 - recall_at_precision: 0.2037\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   3.4s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5867 - recall_at_precision: 0.2038\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   3.1s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.6131 - recall_at_precision: 0.2037\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   4.9s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5823 - recall_at_precision: 0.2039\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   3.2s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.6327 - recall_at_precision: 0.2035\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   3.4s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.6207 - recall_at_precision: 0.2031\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.9s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6620 - recall_at_precision: 0.2027\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.7s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.6153 - recall_at_precision: 0.2025\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   5.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6178 - recall_at_precision: 0.2024\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.6s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5946 - recall_at_precision: 0.2023\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6442 - recall_at_precision: 0.2019\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   5.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6697 - recall_at_precision: 0.2015\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   5.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6307 - recall_at_precision: 0.2011\n",
      "62/62 [==============================] - 1s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6306 - recall_at_precision: 0.2009\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   5.0s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.6360 - recall_at_precision: 0.2005\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   4.9s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6185 - recall_at_precision: 0.2003\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   4.0s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.6340 - recall_at_precision: 0.1999\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   4.2s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.6414 - recall_at_precision: 0.1994\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.3s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.6303 - recall_at_precision: 0.1992\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 2s 5ms/step - loss: 0.5359 - recall_at_precision: 0.1998\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   2.9s\n",
      "248/248 [==============================] - 2s 5ms/step - loss: 0.5230 - recall_at_precision: 0.2004\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   3.1s\n",
      "248/248 [==============================] - 2s 5ms/step - loss: 0.5072 - recall_at_precision: 0.2011\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   2.8s\n",
      "248/248 [==============================] - 2s 5ms/step - loss: 0.4906 - recall_at_precision: 0.2020\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   3.2s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5191 - recall_at_precision: 0.2026\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   3.4s\n",
      "248/248 [==============================] - 2s 5ms/step - loss: 0.5216 - recall_at_precision: 0.2033\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   3.1s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4850 - recall_at_precision: 0.2094\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   3.3s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5342 - recall_at_precision: 0.2100\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   4.6s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5125 - recall_at_precision: 0.2107\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   5.9s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5161 - recall_at_precision: 0.2115\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   3.8s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5208 - recall_at_precision: 0.2122\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   5.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5078 - recall_at_precision: 0.2130\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5145 - recall_at_precision: 0.2137\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   3.4s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5216 - recall_at_precision: 0.2145\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   3.1s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5659 - recall_at_precision: 0.2150\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   3.4s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.5151 - recall_at_precision: 0.2157\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   5.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5760 - recall_at_precision: 0.2161\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5328 - recall_at_precision: 0.2167\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   3.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5342 - recall_at_precision: 0.2174\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5412 - recall_at_precision: 0.2181\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   3.9s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5116 - recall_at_precision: 0.2187\n",
      "62/62 [==============================] - 1s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   6.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5586 - recall_at_precision: 0.2193\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.8s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5389 - recall_at_precision: 0.2199\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.8s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5272 - recall_at_precision: 0.2206\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.8s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5546 - recall_at_precision: 0.2212\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5480 - recall_at_precision: 0.2218\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   4.7s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5538 - recall_at_precision: 0.2223\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   3.9s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5593 - recall_at_precision: 0.2229\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   4.9s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5910 - recall_at_precision: 0.2233\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   4.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5381 - recall_at_precision: 0.2240\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   4.1s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.4980 - recall_at_precision: 0.2247\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   3.6s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5035 - recall_at_precision: 0.2253\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   4.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4942 - recall_at_precision: 0.2261\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   3.9s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.4903 - recall_at_precision: 0.2322\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   3.4s\n",
      "248/248 [==============================] - 2s 5ms/step - loss: 0.4871 - recall_at_precision: 0.2330\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   3.1s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5064 - recall_at_precision: 0.2336\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   4.6s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5133 - recall_at_precision: 0.2343\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   3.0s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5015 - recall_at_precision: 0.2350\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   3.6s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5215 - recall_at_precision: 0.2356\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   3.1s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.4909 - recall_at_precision: 0.2363\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   4.6s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.4979 - recall_at_precision: 0.2370\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5006 - recall_at_precision: 0.2377\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5280 - recall_at_precision: 0.2383\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.9s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4973 - recall_at_precision: 0.2391\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.7s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5195 - recall_at_precision: 0.2397\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   3.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5513 - recall_at_precision: 0.2402\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5096 - recall_at_precision: 0.2408\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5193 - recall_at_precision: 0.2415\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   5.1s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5410 - recall_at_precision: 0.2421\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   5.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5744 - recall_at_precision: 0.2424\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.7s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5446 - recall_at_precision: 0.2430\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   4.8s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5464 - recall_at_precision: 0.2435\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   4.0s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5213 - recall_at_precision: 0.2441\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.5651 - recall_at_precision: 0.2446\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5237 - recall_at_precision: 0.2453\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   3.8s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5337 - recall_at_precision: 0.2458\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5544 - recall_at_precision: 0.2464\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   4.0s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5218 - recall_at_precision: 0.2469\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   3.9s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5377 - recall_at_precision: 0.2475\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.7s\n",
      "248/248 [==============================] - 5s 9ms/step - loss: 0.5634 - recall_at_precision: 0.2480\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   6.0s\n",
      "248/248 [==============================] - 2s 5ms/step - loss: 0.5330 - recall_at_precision: 0.2542\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   3.0s\n",
      "248/248 [==============================] - 2s 5ms/step - loss: 0.5795 - recall_at_precision: 0.2546\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   3.0s\n",
      "248/248 [==============================] - 2s 5ms/step - loss: 0.5216 - recall_at_precision: 0.2551\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   2.9s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5477 - recall_at_precision: 0.2556\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   3.7s\n",
      "248/248 [==============================] - 2s 5ms/step - loss: 0.5545 - recall_at_precision: 0.2561\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   3.0s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5720 - recall_at_precision: 0.2566\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5742 - recall_at_precision: 0.2569\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.4s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5426 - recall_at_precision: 0.2574\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.4s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5987 - recall_at_precision: 0.2577\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   3.1s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5444 - recall_at_precision: 0.2583\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   5.0s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5493 - recall_at_precision: 0.2588\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5801 - recall_at_precision: 0.2592\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.7s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5609 - recall_at_precision: 0.2597\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5969 - recall_at_precision: 0.2601\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5759 - recall_at_precision: 0.2606\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   3.8s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.6300 - recall_at_precision: 0.2607\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   5.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6522 - recall_at_precision: 0.2609\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   4.6s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5824 - recall_at_precision: 0.2612\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   3.7s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6328 - recall_at_precision: 0.2557\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   3.6s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5996 - recall_at_precision: 0.2560\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   3.6s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.6397 - recall_at_precision: 0.2561\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6008 - recall_at_precision: 0.2565\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6791 - recall_at_precision: 0.2565\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.7s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7190 - recall_at_precision: 0.2564\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   5.1s\n",
      "248/248 [==============================] - 5s 8ms/step - loss: 0.7050 - recall_at_precision: 0.2562\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   6.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6384 - recall_at_precision: 0.2563\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   6.0s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.6876 - recall_at_precision: 0.2562\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.7s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.7120 - recall_at_precision: 0.2559\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   4.9s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.6087 - recall_at_precision: 0.2563\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.1s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6169 - recall_at_precision: 0.2565\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   3.8s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5216 - recall_at_precision: 0.2570\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   3.3s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5472 - recall_at_precision: 0.2575\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   3.0s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5334 - recall_at_precision: 0.2580\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   3.0s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5620 - recall_at_precision: 0.2584\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   3.1s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5472 - recall_at_precision: 0.2589\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   3.1s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5614 - recall_at_precision: 0.2593\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.4s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5738 - recall_at_precision: 0.2596\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   3.7s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5799 - recall_at_precision: 0.2599\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   3.2s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5138 - recall_at_precision: 0.2605\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.4s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5531 - recall_at_precision: 0.2609\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5827 - recall_at_precision: 0.2612\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   5.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6157 - recall_at_precision: 0.2615\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6018 - recall_at_precision: 0.2617\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   5.0s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5703 - recall_at_precision: 0.2621\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   3.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5876 - recall_at_precision: 0.2624\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   3.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6225 - recall_at_precision: 0.2627\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   3.7s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5715 - recall_at_precision: 0.2631\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6235 - recall_at_precision: 0.2632\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   5.0s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6165 - recall_at_precision: 0.2635\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.6164 - recall_at_precision: 0.2637\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.6353 - recall_at_precision: 0.2639\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   5.0s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6563 - recall_at_precision: 0.2639\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 5s 8ms/step - loss: 0.7084 - recall_at_precision: 0.2637\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   5.9s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6414 - recall_at_precision: 0.2638\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   5.0s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6387 - recall_at_precision: 0.2639\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.0s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.6846 - recall_at_precision: 0.2639\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7115 - recall_at_precision: 0.2636\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   4.9s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.7124 - recall_at_precision: 0.2635\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.3s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.6769 - recall_at_precision: 0.2635\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6780 - recall_at_precision: 0.2634\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   4.4s\n",
      "248/248 [==============================] - 2s 5ms/step - loss: 0.7001 - recall_at_precision: 0.2631\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   3.0s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7029 - recall_at_precision: 0.2571\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   3.1s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7073 - recall_at_precision: 0.2568\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   3.2s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7050 - recall_at_precision: 0.2564\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   3.5s\n",
      "248/248 [==============================] - 2s 5ms/step - loss: 0.7056 - recall_at_precision: 0.2561\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   2.9s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7023 - recall_at_precision: 0.2557\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   4.6s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.6972 - recall_at_precision: 0.2554\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   4.9s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6986 - recall_at_precision: 0.2550\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   3.5s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7053 - recall_at_precision: 0.2547\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7100 - recall_at_precision: 0.2544\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   3.6s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7057 - recall_at_precision: 0.2541\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6999 - recall_at_precision: 0.2537\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7023 - recall_at_precision: 0.2534\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   3.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7156 - recall_at_precision: 0.2531\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   3.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7066 - recall_at_precision: 0.2528\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   4.8s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7062 - recall_at_precision: 0.2524\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   4.6s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7041 - recall_at_precision: 0.2521\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   4.6s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6997 - recall_at_precision: 0.2517\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   3.7s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7072 - recall_at_precision: 0.2514\n",
      "62/62 [==============================] - 0s 4ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.7036 - recall_at_precision: 0.2511\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   5.8s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7070 - recall_at_precision: 0.2508\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.0s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7004 - recall_at_precision: 0.2504\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7071 - recall_at_precision: 0.2501\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.7s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7028 - recall_at_precision: 0.2497\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.8s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.7021 - recall_at_precision: 0.2494\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.2s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.7023 - recall_at_precision: 0.2490\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   4.1s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.7064 - recall_at_precision: 0.2487\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   4.1s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.7050 - recall_at_precision: 0.2484\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.7059 - recall_at_precision: 0.2481\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   5.1s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.7051 - recall_at_precision: 0.2478\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   4.7s\n",
      "248/248 [==============================] - 2s 5ms/step - loss: 0.7004 - recall_at_precision: 0.2474\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   2.9s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7010 - recall_at_precision: 0.2471\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7026 - recall_at_precision: 0.2468\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   3.5s\n",
      "248/248 [==============================] - 2s 5ms/step - loss: 0.7051 - recall_at_precision: 0.2465\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   3.1s\n",
      "248/248 [==============================] - 2s 5ms/step - loss: 0.7032 - recall_at_precision: 0.2461\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   3.0s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7039 - recall_at_precision: 0.2458\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   3.4s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7048 - recall_at_precision: 0.2455\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   3.7s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7077 - recall_at_precision: 0.2399\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   4.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7016 - recall_at_precision: 0.2396\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   4.3s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7041 - recall_at_precision: 0.2393\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   3.3s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7073 - recall_at_precision: 0.2390\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   3.8s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.7045 - recall_at_precision: 0.2387\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   6.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7022 - recall_at_precision: 0.2384\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.1s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7035 - recall_at_precision: 0.2381\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7024 - recall_at_precision: 0.2377\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7012 - recall_at_precision: 0.2374\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   5.1s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.7017 - recall_at_precision: 0.2371\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7039 - recall_at_precision: 0.2368\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.0s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7078 - recall_at_precision: 0.2365\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   3.8s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7172 - recall_at_precision: 0.2362\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.6s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.7036 - recall_at_precision: 0.2359\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   5.0s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7067 - recall_at_precision: 0.2356\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   3.9s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7015 - recall_at_precision: 0.2353\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   5.3s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7068 - recall_at_precision: 0.2350\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   5.0s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.7056 - recall_at_precision: 0.2347\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   4.3s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.7023 - recall_at_precision: 0.2343\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.1s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7007 - recall_at_precision: 0.2340\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.5s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7021 - recall_at_precision: 0.2337\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.2s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.7075 - recall_at_precision: 0.2334\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   4.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7066 - recall_at_precision: 0.2331\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7073 - recall_at_precision: 0.2328\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   3.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7125 - recall_at_precision: 0.2326\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7070 - recall_at_precision: 0.2323\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   3.9s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7087 - recall_at_precision: 0.2321\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7103 - recall_at_precision: 0.2318\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7086 - recall_at_precision: 0.2316\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   3.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7112 - recall_at_precision: 0.2313\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.6s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7127 - recall_at_precision: 0.2311\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.6s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7112 - recall_at_precision: 0.2309\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   5.0s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7034 - recall_at_precision: 0.2306\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   3.4s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.7113 - recall_at_precision: 0.2304\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.8s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7018 - recall_at_precision: 0.2301\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   5.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7067 - recall_at_precision: 0.2298\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7069 - recall_at_precision: 0.2296\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7150 - recall_at_precision: 0.2293\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   5.2s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7218 - recall_at_precision: 0.2240\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   3.8s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7103 - recall_at_precision: 0.2237\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   3.8s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7132 - recall_at_precision: 0.2235\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   3.9s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7072 - recall_at_precision: 0.2232\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   4.7s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.7105 - recall_at_precision: 0.2230\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   5.4s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7106 - recall_at_precision: 0.2228\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.0s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.7161 - recall_at_precision: 0.2227\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.2s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7068 - recall_at_precision: 0.2224\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   5.1s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.7083 - recall_at_precision: 0.2222\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.7s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.7104 - recall_at_precision: 0.2220\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   5.6s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7097 - recall_at_precision: 0.2218\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   4.5s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7173 - recall_at_precision: 0.2216\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   4.9s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.7076 - recall_at_precision: 0.2214\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.1s\n",
      "248/248 [==============================] - 5s 9ms/step - loss: 0.7087 - recall_at_precision: 0.2211\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.3s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.7094 - recall_at_precision: 0.2209\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.1s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7140 - recall_at_precision: 0.2207\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   4.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7154 - recall_at_precision: 0.2205\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7089 - recall_at_precision: 0.2202\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   3.4s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.7121 - recall_at_precision: 0.2200\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   3.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7123 - recall_at_precision: 0.2198\n",
      "62/62 [==============================] - 1s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   3.9s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.7103 - recall_at_precision: 0.2196\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   5.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7060 - recall_at_precision: 0.2193\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.4s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7170 - recall_at_precision: 0.2191\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7120 - recall_at_precision: 0.2189\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.6s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7133 - recall_at_precision: 0.2187\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7113 - recall_at_precision: 0.2136\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   3.7s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7074 - recall_at_precision: 0.2133\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   5.4s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7113 - recall_at_precision: 0.2131\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   4.7s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7110 - recall_at_precision: 0.2129\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7119 - recall_at_precision: 0.2127\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   4.7s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7120 - recall_at_precision: 0.2125\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   3.8s\n",
      "248/248 [==============================] - 5s 8ms/step - loss: 0.7085 - recall_at_precision: 0.2122\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   5.4s\n",
      "248/248 [==============================] - 5s 7ms/step - loss: 0.7098 - recall_at_precision: 0.2120\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   5.5s\n",
      "248/248 [==============================] - 5s 8ms/step - loss: 0.7111 - recall_at_precision: 0.2118\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   5.8s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7127 - recall_at_precision: 0.2117\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   3.7s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7188 - recall_at_precision: 0.2115\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.7s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.7124 - recall_at_precision: 0.2113\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   5.3s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7097 - recall_at_precision: 0.2111\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7073 - recall_at_precision: 0.2109\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.7s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7089 - recall_at_precision: 0.2106\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7171 - recall_at_precision: 0.2104\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.7104 - recall_at_precision: 0.2102\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.3s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7078 - recall_at_precision: 0.2100\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7094 - recall_at_precision: 0.2098\n",
      "62/62 [==============================] - 1s 4ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   4.9s\n",
      "248/248 [==============================] - 5s 8ms/step - loss: 0.7142 - recall_at_precision: 0.2096\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=50, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.3s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5366 - recall_at_precision: 0.2099\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   3.0s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5334 - recall_at_precision: 0.2101\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   4.3s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.4954 - recall_at_precision: 0.2104\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   3.7s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5189 - recall_at_precision: 0.2108\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   4.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5576 - recall_at_precision: 0.2109\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   4.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5370 - recall_at_precision: 0.2111\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   4.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5377 - recall_at_precision: 0.2114\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   4.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5122 - recall_at_precision: 0.2117\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5731 - recall_at_precision: 0.2118\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   3.6s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5582 - recall_at_precision: 0.2119\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4943 - recall_at_precision: 0.2123\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5587 - recall_at_precision: 0.2124\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   3.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5425 - recall_at_precision: 0.2125\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.6012 - recall_at_precision: 0.2125\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4995 - recall_at_precision: 0.2128\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   5.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5116 - recall_at_precision: 0.2131\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   3.8s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.4988 - recall_at_precision: 0.2134\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   4.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5333 - recall_at_precision: 0.2136\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5348 - recall_at_precision: 0.2138\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   3.8s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.5003 - recall_at_precision: 0.2189\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   5.2s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5234 - recall_at_precision: 0.2191\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.8s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5191 - recall_at_precision: 0.2194\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.7s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5521 - recall_at_precision: 0.2195\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.7s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5922 - recall_at_precision: 0.2195\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.1s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5500 - recall_at_precision: 0.2195\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   5.5s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5595 - recall_at_precision: 0.2196\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   5.6s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5704 - recall_at_precision: 0.2196\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5589 - recall_at_precision: 0.2197\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   4.4s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5612 - recall_at_precision: 0.2198\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   4.9s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5485 - recall_at_precision: 0.2199\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   5.7s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5030 - recall_at_precision: 0.2202\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   3.1s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5127 - recall_at_precision: 0.2205\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   4.3s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5390 - recall_at_precision: 0.2207\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   3.1s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5044 - recall_at_precision: 0.2210\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5264 - recall_at_precision: 0.2213\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   4.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5104 - recall_at_precision: 0.2216\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   3.9s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5022 - recall_at_precision: 0.2219\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5115 - recall_at_precision: 0.2222\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5230 - recall_at_precision: 0.2224\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   3.8s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5079 - recall_at_precision: 0.2227\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5587 - recall_at_precision: 0.2227\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5366 - recall_at_precision: 0.2229\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   5.0s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5353 - recall_at_precision: 0.2231\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5501 - recall_at_precision: 0.2233\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   3.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5104 - recall_at_precision: 0.2236\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5359 - recall_at_precision: 0.2238\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5580 - recall_at_precision: 0.2239\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   5.0s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5398 - recall_at_precision: 0.2241\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   3.9s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5464 - recall_at_precision: 0.2242\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5605 - recall_at_precision: 0.2295\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.7s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5249 - recall_at_precision: 0.2298\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5442 - recall_at_precision: 0.2299\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   5.4s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5655 - recall_at_precision: 0.2300\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   5.6s\n",
      "248/248 [==============================] - 5s 9ms/step - loss: 0.5889 - recall_at_precision: 0.2300\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   6.1s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5090 - recall_at_precision: 0.2302\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   5.2s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5653 - recall_at_precision: 0.2303\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   4.9s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5992 - recall_at_precision: 0.2302\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   4.2s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5453 - recall_at_precision: 0.2303\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.5s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5935 - recall_at_precision: 0.2303\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5600 - recall_at_precision: 0.2304\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   4.8s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5817 - recall_at_precision: 0.2304\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.2s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5965 - recall_at_precision: 0.2304\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   3.1s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5855 - recall_at_precision: 0.2304\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.7s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5726 - recall_at_precision: 0.2305\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5640 - recall_at_precision: 0.2306\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   3.0s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5923 - recall_at_precision: 0.2307\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5654 - recall_at_precision: 0.2308\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5565 - recall_at_precision: 0.2308\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6262 - recall_at_precision: 0.2307\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   5.1s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5849 - recall_at_precision: 0.2307\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6309 - recall_at_precision: 0.2305\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   3.7s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6234 - recall_at_precision: 0.2303\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5811 - recall_at_precision: 0.2303\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.7s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6112 - recall_at_precision: 0.2302\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5907 - recall_at_precision: 0.2302\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.1s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6641 - recall_at_precision: 0.2299\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   4.6s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5969 - recall_at_precision: 0.2298\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   4.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5940 - recall_at_precision: 0.2298\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   3.9s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.6195 - recall_at_precision: 0.2295\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   4.7s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5942 - recall_at_precision: 0.2294\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   4.4s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5970 - recall_at_precision: 0.2294\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.6411 - recall_at_precision: 0.2291\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6501 - recall_at_precision: 0.2288\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5615 - recall_at_precision: 0.2289\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5760 - recall_at_precision: 0.2289\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   5.3s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6301 - recall_at_precision: 0.2288\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5716 - recall_at_precision: 0.2288\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   4.8s\n",
      "248/248 [==============================] - 5s 9ms/step - loss: 0.6175 - recall_at_precision: 0.2287\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.6s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6096 - recall_at_precision: 0.2285\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.2s\n",
      "248/248 [==============================] - 5s 9ms/step - loss: 0.6295 - recall_at_precision: 0.2284\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.7s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.5821 - recall_at_precision: 0.2284\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   4.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5852 - recall_at_precision: 0.2284\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   4.3s\n",
      "248/248 [==============================] - 3s 5ms/step - loss: 0.6112 - recall_at_precision: 0.2284\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   3.1s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5903 - recall_at_precision: 0.2285\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   4.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5880 - recall_at_precision: 0.2285\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   4.2s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5870 - recall_at_precision: 0.2285\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5580 - recall_at_precision: 0.2287\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   5.1s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5584 - recall_at_precision: 0.2288\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6042 - recall_at_precision: 0.2288\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.4s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5863 - recall_at_precision: 0.2289\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.6071 - recall_at_precision: 0.2288\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5415 - recall_at_precision: 0.2289\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.6038 - recall_at_precision: 0.2287\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   4.2s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.6745 - recall_at_precision: 0.2284\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   3.8s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5988 - recall_at_precision: 0.2284\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   4.7s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.6224 - recall_at_precision: 0.2283\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.0s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5777 - recall_at_precision: 0.2282\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   3.9s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.6070 - recall_at_precision: 0.2281\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   5.3s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5894 - recall_at_precision: 0.2281\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.0s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.6167 - recall_at_precision: 0.2280\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.0s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.6069 - recall_at_precision: 0.2279\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5862 - recall_at_precision: 0.2279\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.8s\n",
      "248/248 [==============================] - 5s 8ms/step - loss: 0.6022 - recall_at_precision: 0.2278\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   6.1s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6412 - recall_at_precision: 0.2275\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.6010 - recall_at_precision: 0.2275\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.1s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6145 - recall_at_precision: 0.2273\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6096 - recall_at_precision: 0.2272\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   4.4s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.6056 - recall_at_precision: 0.2271\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.6s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5996 - recall_at_precision: 0.2270\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6313 - recall_at_precision: 0.2268\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.1s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4996 - recall_at_precision: 0.2272\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4804 - recall_at_precision: 0.2277\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   4.5s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.4852 - recall_at_precision: 0.2281\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.4985 - recall_at_precision: 0.2339\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   6.1s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5055 - recall_at_precision: 0.2343\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   5.0s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5306 - recall_at_precision: 0.2347\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   3.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4915 - recall_at_precision: 0.2352\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4925 - recall_at_precision: 0.2356\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   3.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.4723 - recall_at_precision: 0.2361\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   4.6s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.5082 - recall_at_precision: 0.2365\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   5.2s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.4987 - recall_at_precision: 0.2370\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   3.7s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5006 - recall_at_precision: 0.2374\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   3.7s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.4943 - recall_at_precision: 0.2378\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5301 - recall_at_precision: 0.2382\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   4.0s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5239 - recall_at_precision: 0.2386\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   3.7s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5110 - recall_at_precision: 0.2390\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   5.2s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5026 - recall_at_precision: 0.2394\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   4.9s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5316 - recall_at_precision: 0.2398\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   5.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5622 - recall_at_precision: 0.2401\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5508 - recall_at_precision: 0.2405\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   4.6s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5494 - recall_at_precision: 0.2408\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   5.3s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5146 - recall_at_precision: 0.2412\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   5.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5106 - recall_at_precision: 0.2416\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5412 - recall_at_precision: 0.2419\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5333 - recall_at_precision: 0.2423\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 5s 8ms/step - loss: 0.5357 - recall_at_precision: 0.2427\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   5.6s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5388 - recall_at_precision: 0.2430\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5161 - recall_at_precision: 0.2434\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   5.2s\n",
      "248/248 [==============================] - 5s 10ms/step - loss: 0.5844 - recall_at_precision: 0.2436\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   5.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5406 - recall_at_precision: 0.2440\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   4.6s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4739 - recall_at_precision: 0.2445\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   3.6s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4728 - recall_at_precision: 0.2449\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   4.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4812 - recall_at_precision: 0.2454\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   4.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4882 - recall_at_precision: 0.2458\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4843 - recall_at_precision: 0.2462\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   4.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5012 - recall_at_precision: 0.2466\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   3.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.4937 - recall_at_precision: 0.2470\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   5.0s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5234 - recall_at_precision: 0.2473\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5172 - recall_at_precision: 0.2477\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   3.8s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5443 - recall_at_precision: 0.2480\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5063 - recall_at_precision: 0.2484\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.8s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5042 - recall_at_precision: 0.2488\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   5.4s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5273 - recall_at_precision: 0.2491\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   5.4s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.5201 - recall_at_precision: 0.2495\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.8s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5194 - recall_at_precision: 0.2499\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5083 - recall_at_precision: 0.2558\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.7s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5120 - recall_at_precision: 0.2562\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.5249 - recall_at_precision: 0.2565\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5219 - recall_at_precision: 0.2569\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   5.1s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5118 - recall_at_precision: 0.2573\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.6s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5471 - recall_at_precision: 0.2576\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   5.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.4919 - recall_at_precision: 0.2580\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   5.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5200 - recall_at_precision: 0.2584\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   5.7s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5196 - recall_at_precision: 0.2588\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   5.4s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5452 - recall_at_precision: 0.2591\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   4.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5404 - recall_at_precision: 0.2594\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5042 - recall_at_precision: 0.2598\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5584 - recall_at_precision: 0.2601\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5604 - recall_at_precision: 0.2604\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.7s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5299 - recall_at_precision: 0.2608\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   4.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5163 - recall_at_precision: 0.2611\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5246 - recall_at_precision: 0.2614\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5377 - recall_at_precision: 0.2618\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5180 - recall_at_precision: 0.2621\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.5489 - recall_at_precision: 0.2624\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5257 - recall_at_precision: 0.2627\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5879 - recall_at_precision: 0.2629\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5250 - recall_at_precision: 0.2633\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   5.1s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5302 - recall_at_precision: 0.2636\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   5.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5597 - recall_at_precision: 0.2639\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.4s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.6083 - recall_at_precision: 0.2641\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   5.1s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5722 - recall_at_precision: 0.2643\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5684 - recall_at_precision: 0.2645\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5498 - recall_at_precision: 0.2649\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   3.7s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5646 - recall_at_precision: 0.2651\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.7s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5755 - recall_at_precision: 0.2654\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   4.4s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5562 - recall_at_precision: 0.2657\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   6.2s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.6755 - recall_at_precision: 0.2657\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6881 - recall_at_precision: 0.2656\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.6034 - recall_at_precision: 0.2658\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   4.7s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6270 - recall_at_precision: 0.2659\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   5.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6394 - recall_at_precision: 0.2660\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   5.1s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5884 - recall_at_precision: 0.2663\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6139 - recall_at_precision: 0.2664\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.8s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.6241 - recall_at_precision: 0.2666\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6447 - recall_at_precision: 0.2667\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.1s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7116 - recall_at_precision: 0.2666\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.6s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7066 - recall_at_precision: 0.2665\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6706 - recall_at_precision: 0.2665\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   4.5s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.6761 - recall_at_precision: 0.2665\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5072 - recall_at_precision: 0.2668\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   4.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5177 - recall_at_precision: 0.2672\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   3.6s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5264 - recall_at_precision: 0.2675\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   4.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5101 - recall_at_precision: 0.2679\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   3.1s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5610 - recall_at_precision: 0.2681\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   3.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5306 - recall_at_precision: 0.2684\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5628 - recall_at_precision: 0.2687\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5510 - recall_at_precision: 0.2689\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.9s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5411 - recall_at_precision: 0.2693\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.4s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5520 - recall_at_precision: 0.2695\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5326 - recall_at_precision: 0.2699\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   5.3s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5562 - recall_at_precision: 0.2701\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5711 - recall_at_precision: 0.2704\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.6334 - recall_at_precision: 0.2705\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   5.2s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5551 - recall_at_precision: 0.2707\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5594 - recall_at_precision: 0.2710\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5730 - recall_at_precision: 0.2713\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.6138 - recall_at_precision: 0.2714\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5932 - recall_at_precision: 0.2716\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.1s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5785 - recall_at_precision: 0.2718\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   5.1s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5937 - recall_at_precision: 0.2720\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.3s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7149 - recall_at_precision: 0.2718\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   5.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6562 - recall_at_precision: 0.2719\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   5.5s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6828 - recall_at_precision: 0.2718\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6082 - recall_at_precision: 0.2720\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   5.1s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6741 - recall_at_precision: 0.2720\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6629 - recall_at_precision: 0.2721\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6335 - recall_at_precision: 0.2665\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   4.9s\n",
      "248/248 [==============================] - 4s 10ms/step - loss: 0.6490 - recall_at_precision: 0.2666\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6691 - recall_at_precision: 0.2666\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7076 - recall_at_precision: 0.2664\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   4.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7020 - recall_at_precision: 0.2662\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   4.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7082 - recall_at_precision: 0.2659\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   4.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7036 - recall_at_precision: 0.2657\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   4.7s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7070 - recall_at_precision: 0.2655\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   4.6s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.7018 - recall_at_precision: 0.2652\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   5.1s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.6982 - recall_at_precision: 0.2650\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7040 - recall_at_precision: 0.2648\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7095 - recall_at_precision: 0.2646\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   4.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7065 - recall_at_precision: 0.2643\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   3.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7035 - recall_at_precision: 0.2641\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   4.7s\n",
      "248/248 [==============================] - 5s 7ms/step - loss: 0.7053 - recall_at_precision: 0.2639\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   6.7s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7024 - recall_at_precision: 0.2636\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   4.8s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7023 - recall_at_precision: 0.2635\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7037 - recall_at_precision: 0.2632\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   4.7s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7036 - recall_at_precision: 0.2630\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   5.7s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7045 - recall_at_precision: 0.2628\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   4.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7052 - recall_at_precision: 0.2625\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   5.2s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7040 - recall_at_precision: 0.2623\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   3.9s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7058 - recall_at_precision: 0.2621\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   4.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7027 - recall_at_precision: 0.2619\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.4s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7024 - recall_at_precision: 0.2616\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.7s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7038 - recall_at_precision: 0.2614\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   5.6s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7098 - recall_at_precision: 0.2612\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.2s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7042 - recall_at_precision: 0.2610\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.8s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7005 - recall_at_precision: 0.2608\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7042 - recall_at_precision: 0.2606\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   5.2s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7011 - recall_at_precision: 0.2603\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   6.3s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7042 - recall_at_precision: 0.2601\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   4.6s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7040 - recall_at_precision: 0.2599\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7051 - recall_at_precision: 0.2597\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   3.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7032 - recall_at_precision: 0.2594\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   3.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7028 - recall_at_precision: 0.2592\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   4.9s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7032 - recall_at_precision: 0.2590\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7033 - recall_at_precision: 0.2588\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7173 - recall_at_precision: 0.2586\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   3.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7042 - recall_at_precision: 0.2584\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   3.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7071 - recall_at_precision: 0.2582\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7042 - recall_at_precision: 0.2580\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7051 - recall_at_precision: 0.2577\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   4.9s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7042 - recall_at_precision: 0.2575\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.2s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7077 - recall_at_precision: 0.2573\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.7005 - recall_at_precision: 0.2571\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7064 - recall_at_precision: 0.2568\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.7053 - recall_at_precision: 0.2567\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   5.0s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7055 - recall_at_precision: 0.2565\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.7094 - recall_at_precision: 0.2563\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7060 - recall_at_precision: 0.2560\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.7s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.7012 - recall_at_precision: 0.2559\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7033 - recall_at_precision: 0.2556\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7026 - recall_at_precision: 0.2554\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   5.3s\n",
      "248/248 [==============================] - 5s 9ms/step - loss: 0.7028 - recall_at_precision: 0.2552\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   5.6s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7036 - recall_at_precision: 0.2550\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   5.4s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7054 - recall_at_precision: 0.2548\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7081 - recall_at_precision: 0.2546\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   4.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7043 - recall_at_precision: 0.2544\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.5s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7018 - recall_at_precision: 0.2542\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7168 - recall_at_precision: 0.2540\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.1s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7101 - recall_at_precision: 0.2538\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7116 - recall_at_precision: 0.2536\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7158 - recall_at_precision: 0.2480\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7109 - recall_at_precision: 0.2478\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7138 - recall_at_precision: 0.2477\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7043 - recall_at_precision: 0.2475\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.9s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7110 - recall_at_precision: 0.2473\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7092 - recall_at_precision: 0.2471\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7099 - recall_at_precision: 0.2470\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.8s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7129 - recall_at_precision: 0.2468\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7073 - recall_at_precision: 0.2466\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7045 - recall_at_precision: 0.2464\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7184 - recall_at_precision: 0.2463\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   3.8s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7070 - recall_at_precision: 0.2461\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.7155 - recall_at_precision: 0.2459\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   5.1s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7152 - recall_at_precision: 0.2458\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   3.9s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7163 - recall_at_precision: 0.2456\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7148 - recall_at_precision: 0.2454\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   5.5s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.7154 - recall_at_precision: 0.2453\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   5.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7095 - recall_at_precision: 0.2451\n",
      "62/62 [==============================] - 1s 3ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   5.5s\n",
      "248/248 [==============================] - 5s 8ms/step - loss: 0.7096 - recall_at_precision: 0.2449\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   6.3s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7198 - recall_at_precision: 0.2448\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   5.0s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.7067 - recall_at_precision: 0.2446\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.2s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7178 - recall_at_precision: 0.2445\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.3s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7158 - recall_at_precision: 0.2443\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7123 - recall_at_precision: 0.2442\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.7126 - recall_at_precision: 0.2440\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.8s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7098 - recall_at_precision: 0.2438\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   4.7s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7085 - recall_at_precision: 0.2437\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.1s\n",
      "248/248 [==============================] - 5s 9ms/step - loss: 0.7124 - recall_at_precision: 0.2435\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.7s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7108 - recall_at_precision: 0.2434\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.4s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7167 - recall_at_precision: 0.2432\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7109 - recall_at_precision: 0.2431\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   4.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7102 - recall_at_precision: 0.2429\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7159 - recall_at_precision: 0.2428\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7124 - recall_at_precision: 0.2426\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   3.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7097 - recall_at_precision: 0.2424\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   5.0s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7112 - recall_at_precision: 0.2422\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7160 - recall_at_precision: 0.2421\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7067 - recall_at_precision: 0.2419\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7084 - recall_at_precision: 0.2417\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.7119 - recall_at_precision: 0.2416\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   5.2s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.7128 - recall_at_precision: 0.2414\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   4.2s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7178 - recall_at_precision: 0.2413\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7183 - recall_at_precision: 0.2359\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7127 - recall_at_precision: 0.2358\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7123 - recall_at_precision: 0.2356\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   4.7s\n",
      "248/248 [==============================] - 4s 10ms/step - loss: 0.7062 - recall_at_precision: 0.2354\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7114 - recall_at_precision: 0.2353\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.1s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7115 - recall_at_precision: 0.2351\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7147 - recall_at_precision: 0.2349\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.7s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.7092 - recall_at_precision: 0.2348\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7203 - recall_at_precision: 0.2346\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 5s 8ms/step - loss: 0.7149 - recall_at_precision: 0.2345\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   6.5s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7177 - recall_at_precision: 0.2343\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.2s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7100 - recall_at_precision: 0.2342\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7130 - recall_at_precision: 0.2340\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.8s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7075 - recall_at_precision: 0.2338\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.1s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7161 - recall_at_precision: 0.2337\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7041 - recall_at_precision: 0.2335\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   4.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7139 - recall_at_precision: 0.2334\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7144 - recall_at_precision: 0.2332\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=60, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   4.8s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4999 - recall_at_precision: 0.2334\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   4.3s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.4570 - recall_at_precision: 0.2337\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   4.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5123 - recall_at_precision: 0.2339\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   5.1s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5309 - recall_at_precision: 0.2340\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   4.9s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5181 - recall_at_precision: 0.2343\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4954 - recall_at_precision: 0.2344\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5130 - recall_at_precision: 0.2346\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4861 - recall_at_precision: 0.2348\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   3.6s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5747 - recall_at_precision: 0.2349\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.4896 - recall_at_precision: 0.2351\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   4.4s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5105 - recall_at_precision: 0.2353\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5138 - recall_at_precision: 0.2354\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   3.8s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.5212 - recall_at_precision: 0.2355\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5264 - recall_at_precision: 0.2357\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5566 - recall_at_precision: 0.2357\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   5.1s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5160 - recall_at_precision: 0.2411\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   5.5s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5360 - recall_at_precision: 0.2412\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   4.9s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5645 - recall_at_precision: 0.2412\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   4.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5676 - recall_at_precision: 0.2413\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5347 - recall_at_precision: 0.2414\n",
      "62/62 [==============================] - 1s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   5.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.4852 - recall_at_precision: 0.2416\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.3s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5815 - recall_at_precision: 0.2416\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5549 - recall_at_precision: 0.2417\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5959 - recall_at_precision: 0.2416\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5610 - recall_at_precision: 0.2417\n",
      "62/62 [==============================] - 1s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   5.6s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5303 - recall_at_precision: 0.2418\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   4.7s\n",
      "248/248 [==============================] - 4s 10ms/step - loss: 0.5245 - recall_at_precision: 0.2419\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   5.1s\n",
      "248/248 [==============================] - 5s 9ms/step - loss: 0.5498 - recall_at_precision: 0.2420\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   6.3s\n",
      "248/248 [==============================] - 5s 9ms/step - loss: 0.5357 - recall_at_precision: 0.2421\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   6.5s\n",
      "248/248 [==============================] - 5s 9ms/step - loss: 0.5550 - recall_at_precision: 0.2422\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   6.1s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5054 - recall_at_precision: 0.2423\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   4.0s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4673 - recall_at_precision: 0.2426\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.4911 - recall_at_precision: 0.2428\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   4.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5095 - recall_at_precision: 0.2430\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   4.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4996 - recall_at_precision: 0.2432\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5080 - recall_at_precision: 0.2433\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5000 - recall_at_precision: 0.2435\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   5.0s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5430 - recall_at_precision: 0.2436\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5585 - recall_at_precision: 0.2437\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   4.8s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5171 - recall_at_precision: 0.2439\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   4.3s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5170 - recall_at_precision: 0.2440\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.7s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5055 - recall_at_precision: 0.2441\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5160 - recall_at_precision: 0.2443\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   5.3s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.5831 - recall_at_precision: 0.2443\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   3.9s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5315 - recall_at_precision: 0.2444\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.5017 - recall_at_precision: 0.2446\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.2s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5304 - recall_at_precision: 0.2447\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5432 - recall_at_precision: 0.2448\n",
      "62/62 [==============================] - 1s 3ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.9s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.5393 - recall_at_precision: 0.2449\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.7s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5296 - recall_at_precision: 0.2450\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5343 - recall_at_precision: 0.2451\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 5s 9ms/step - loss: 0.5723 - recall_at_precision: 0.2451\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   5.7s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.4967 - recall_at_precision: 0.2452\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   4.8s\n",
      "248/248 [==============================] - 5s 8ms/step - loss: 0.5012 - recall_at_precision: 0.2454\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   5.4s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5745 - recall_at_precision: 0.2454\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   4.4s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5312 - recall_at_precision: 0.2455\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5336 - recall_at_precision: 0.2456\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5576 - recall_at_precision: 0.2457\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 5s 9ms/step - loss: 0.5220 - recall_at_precision: 0.2458\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.7s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5569 - recall_at_precision: 0.2458\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   4.9s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5236 - recall_at_precision: 0.2459\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5178 - recall_at_precision: 0.2461\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5249 - recall_at_precision: 0.2462\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   5.1s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5719 - recall_at_precision: 0.2462\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.3s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.5855 - recall_at_precision: 0.2462\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5377 - recall_at_precision: 0.2463\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5868 - recall_at_precision: 0.2462\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5474 - recall_at_precision: 0.2517\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   3.4s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.5643 - recall_at_precision: 0.2517\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.8s\n",
      "248/248 [==============================] - 4s 10ms/step - loss: 0.6317 - recall_at_precision: 0.2516\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.8s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5792 - recall_at_precision: 0.2515\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.9s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5606 - recall_at_precision: 0.2516\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   5.1s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5391 - recall_at_precision: 0.2516\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.4s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.6171 - recall_at_precision: 0.2515\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   3.8s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5847 - recall_at_precision: 0.2515\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.7s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5597 - recall_at_precision: 0.2515\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5952 - recall_at_precision: 0.2515\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   5.4s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.5702 - recall_at_precision: 0.2515\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   4.7s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5452 - recall_at_precision: 0.2515\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   4.7s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.5807 - recall_at_precision: 0.2515\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   4.7s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5783 - recall_at_precision: 0.2515\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6131 - recall_at_precision: 0.2515\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5774 - recall_at_precision: 0.2514\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.7s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6265 - recall_at_precision: 0.2513\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.8s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.6176 - recall_at_precision: 0.2512\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5850 - recall_at_precision: 0.2512\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 5s 8ms/step - loss: 0.5972 - recall_at_precision: 0.2511\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.4s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5418 - recall_at_precision: 0.2512\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.4s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.6214 - recall_at_precision: 0.2511\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   4.7s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.6015 - recall_at_precision: 0.2510\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   4.9s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5329 - recall_at_precision: 0.2512\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5037 - recall_at_precision: 0.2513\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5514 - recall_at_precision: 0.2514\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5545 - recall_at_precision: 0.2515\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   3.8s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5313 - recall_at_precision: 0.2516\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   3.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5666 - recall_at_precision: 0.2517\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.3s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5889 - recall_at_precision: 0.2516\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.4s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5660 - recall_at_precision: 0.2516\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.3s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6046 - recall_at_precision: 0.2516\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   5.1s\n",
      "248/248 [==============================] - 5s 7ms/step - loss: 0.5715 - recall_at_precision: 0.2516\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   5.6s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5387 - recall_at_precision: 0.2517\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   5.2s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5820 - recall_at_precision: 0.2516\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   3.8s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5568 - recall_at_precision: 0.2516\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.6202 - recall_at_precision: 0.2515\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.6542 - recall_at_precision: 0.2513\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5652 - recall_at_precision: 0.2513\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   5.5s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.5837 - recall_at_precision: 0.2513\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5812 - recall_at_precision: 0.2513\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.7s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.5850 - recall_at_precision: 0.2513\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.0s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5967 - recall_at_precision: 0.2512\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.6093 - recall_at_precision: 0.2511\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   5.0s\n",
      "248/248 [==============================] - 5s 8ms/step - loss: 0.6236 - recall_at_precision: 0.2509\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   6.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5976 - recall_at_precision: 0.2508\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5989 - recall_at_precision: 0.2508\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.6018 - recall_at_precision: 0.2507\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5730 - recall_at_precision: 0.2507\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   4.9s\n",
      "248/248 [==============================] - 5s 9ms/step - loss: 0.6074 - recall_at_precision: 0.2507\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.6s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5636 - recall_at_precision: 0.2507\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   4.6s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.6166 - recall_at_precision: 0.2506\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   4.7s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.6317 - recall_at_precision: 0.2505\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   4.9s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4812 - recall_at_precision: 0.2508\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   3.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4947 - recall_at_precision: 0.2511\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   3.3s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.5032 - recall_at_precision: 0.2513\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   4.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4804 - recall_at_precision: 0.2516\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   5.2s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5051 - recall_at_precision: 0.2519\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.4943 - recall_at_precision: 0.2522\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   3.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.4793 - recall_at_precision: 0.2525\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4830 - recall_at_precision: 0.2528\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   3.5s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.5079 - recall_at_precision: 0.2531\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   4.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5032 - recall_at_precision: 0.2534\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   3.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5020 - recall_at_precision: 0.2537\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.4864 - recall_at_precision: 0.2540\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   4.1s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.4929 - recall_at_precision: 0.2543\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   4.8s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5072 - recall_at_precision: 0.2546\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5300 - recall_at_precision: 0.2549\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   5.1s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.4936 - recall_at_precision: 0.2552\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   5.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5026 - recall_at_precision: 0.2554\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   4.7s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.4905 - recall_at_precision: 0.2558\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   4.0s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5395 - recall_at_precision: 0.2560\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   4.7s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5420 - recall_at_precision: 0.2562\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5105 - recall_at_precision: 0.2565\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   5.4s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5058 - recall_at_precision: 0.2568\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   5.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.4990 - recall_at_precision: 0.2571\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5253 - recall_at_precision: 0.2574\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5350 - recall_at_precision: 0.2576\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 5s 9ms/step - loss: 0.5272 - recall_at_precision: 0.2579\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   5.5s\n",
      "248/248 [==============================] - 4s 10ms/step - loss: 0.5300 - recall_at_precision: 0.2581\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   5.2s\n",
      "248/248 [==============================] - 5s 9ms/step - loss: 0.5638 - recall_at_precision: 0.2583\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   6.0s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5970 - recall_at_precision: 0.2584\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5181 - recall_at_precision: 0.2587\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4860 - recall_at_precision: 0.2590\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   3.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4812 - recall_at_precision: 0.2648\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   4.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5114 - recall_at_precision: 0.2651\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   4.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4882 - recall_at_precision: 0.2654\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   4.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4787 - recall_at_precision: 0.2657\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   3.2s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5039 - recall_at_precision: 0.2659\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   3.9s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.4822 - recall_at_precision: 0.2662\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   4.4s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.4917 - recall_at_precision: 0.2665\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   5.1s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.4986 - recall_at_precision: 0.2668\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.4808 - recall_at_precision: 0.2671\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   5.1s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5077 - recall_at_precision: 0.2674\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.4905 - recall_at_precision: 0.2677\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.2s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5023 - recall_at_precision: 0.2679\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.1s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5008 - recall_at_precision: 0.2682\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5086 - recall_at_precision: 0.2685\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.4992 - recall_at_precision: 0.2688\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5168 - recall_at_precision: 0.2690\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   5.6s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5033 - recall_at_precision: 0.2693\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   5.7s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5253 - recall_at_precision: 0.2695\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.0s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5141 - recall_at_precision: 0.2698\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.6s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.4949 - recall_at_precision: 0.2701\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   4.7s\n",
      "248/248 [==============================] - 4s 10ms/step - loss: 0.4993 - recall_at_precision: 0.2704\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   5.4s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5274 - recall_at_precision: 0.2706\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   5.3s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5360 - recall_at_precision: 0.2708\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   4.3s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5257 - recall_at_precision: 0.2711\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   5.7s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5214 - recall_at_precision: 0.2714\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5540 - recall_at_precision: 0.2715\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5305 - recall_at_precision: 0.2718\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   4.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5404 - recall_at_precision: 0.2720\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.1s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5304 - recall_at_precision: 0.2723\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4942 - recall_at_precision: 0.2725\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4943 - recall_at_precision: 0.2728\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.4980 - recall_at_precision: 0.2730\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   3.5s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5363 - recall_at_precision: 0.2733\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5084 - recall_at_precision: 0.2735\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5518 - recall_at_precision: 0.2737\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5841 - recall_at_precision: 0.2739\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5478 - recall_at_precision: 0.2741\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5330 - recall_at_precision: 0.2743\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5480 - recall_at_precision: 0.2745\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.3s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5756 - recall_at_precision: 0.2747\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5407 - recall_at_precision: 0.2749\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5829 - recall_at_precision: 0.2750\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.7s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5401 - recall_at_precision: 0.2753\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   5.1s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5646 - recall_at_precision: 0.2755\n",
      "62/62 [==============================] - 0s 4ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.7s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5750 - recall_at_precision: 0.2757\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   5.7s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.6320 - recall_at_precision: 0.2757\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   4.1s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.6167 - recall_at_precision: 0.2758\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   4.7s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.6119 - recall_at_precision: 0.2760\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   5.2s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.6319 - recall_at_precision: 0.2761\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   4.1s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6390 - recall_at_precision: 0.2761\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.4s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.6474 - recall_at_precision: 0.2762\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5939 - recall_at_precision: 0.2763\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.5s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6585 - recall_at_precision: 0.2763\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6066 - recall_at_precision: 0.2765\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   5.4s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6560 - recall_at_precision: 0.2765\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   4.5s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.6519 - recall_at_precision: 0.2766\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.1s\n",
      "248/248 [==============================] - 5s 9ms/step - loss: 0.6221 - recall_at_precision: 0.2767\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.8s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.6342 - recall_at_precision: 0.2768\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   4.8s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5965 - recall_at_precision: 0.2769\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5438 - recall_at_precision: 0.2771\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   3.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5231 - recall_at_precision: 0.2774\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   3.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5107 - recall_at_precision: 0.2776\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   3.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5354 - recall_at_precision: 0.2778\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   4.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5397 - recall_at_precision: 0.2780\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   4.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5541 - recall_at_precision: 0.2782\n",
      "62/62 [==============================] - 1s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   5.1s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5300 - recall_at_precision: 0.2784\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5295 - recall_at_precision: 0.2786\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5644 - recall_at_precision: 0.2788\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.5380 - recall_at_precision: 0.2790\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   3.9s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5685 - recall_at_precision: 0.2792\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   5.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5572 - recall_at_precision: 0.2794\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5605 - recall_at_precision: 0.2795\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   5.2s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5917 - recall_at_precision: 0.2797\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   3.8s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5351 - recall_at_precision: 0.2799\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   3.9s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.5696 - recall_at_precision: 0.2801\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6018 - recall_at_precision: 0.2802\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5759 - recall_at_precision: 0.2804\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.2s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.5710 - recall_at_precision: 0.2806\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   5.4s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5920 - recall_at_precision: 0.2807\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6014 - recall_at_precision: 0.2809\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.7s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5868 - recall_at_precision: 0.2810\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5968 - recall_at_precision: 0.2811\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   5.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5952 - recall_at_precision: 0.2813\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   5.2s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6023 - recall_at_precision: 0.2814\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.4s\n",
      "248/248 [==============================] - 5s 11ms/step - loss: 0.5966 - recall_at_precision: 0.2815\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   7.8s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.6339 - recall_at_precision: 0.2816\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.3s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.6083 - recall_at_precision: 0.2817\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 5s 9ms/step - loss: 0.6202 - recall_at_precision: 0.2818\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.6s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6011 - recall_at_precision: 0.2819\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7033 - recall_at_precision: 0.2818\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   3.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7052 - recall_at_precision: 0.2816\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   4.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7040 - recall_at_precision: 0.2814\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7056 - recall_at_precision: 0.2812\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   3.9s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7037 - recall_at_precision: 0.2811\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   3.7s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.7058 - recall_at_precision: 0.2809\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   4.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7023 - recall_at_precision: 0.2807\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   3.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7071 - recall_at_precision: 0.2805\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   4.0s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7117 - recall_at_precision: 0.2804\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   3.7s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7052 - recall_at_precision: 0.2802\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   4.4s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7054 - recall_at_precision: 0.2800\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   3.8s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.7072 - recall_at_precision: 0.2799\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   5.2s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7025 - recall_at_precision: 0.2797\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   3.9s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7044 - recall_at_precision: 0.2795\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   4.7s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7068 - recall_at_precision: 0.2793\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   3.9s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7009 - recall_at_precision: 0.2791\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7011 - recall_at_precision: 0.2790\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   5.6s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7013 - recall_at_precision: 0.2788\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   5.2s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7024 - recall_at_precision: 0.2786\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.7046 - recall_at_precision: 0.2784\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7018 - recall_at_precision: 0.2783\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.7s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7059 - recall_at_precision: 0.2781\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   5.0s\n",
      "248/248 [==============================] - 5s 12ms/step - loss: 0.7037 - recall_at_precision: 0.2779\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   5.3s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7055 - recall_at_precision: 0.2778\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.7s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7103 - recall_at_precision: 0.2776\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7038 - recall_at_precision: 0.2774\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   4.9s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7133 - recall_at_precision: 0.2773\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   4.9s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7051 - recall_at_precision: 0.2771\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   5.2s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7057 - recall_at_precision: 0.2769\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   6.6s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7073 - recall_at_precision: 0.2768\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   4.6s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7049 - recall_at_precision: 0.2766\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   3.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7073 - recall_at_precision: 0.2764\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   3.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7032 - recall_at_precision: 0.2707\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   3.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7057 - recall_at_precision: 0.2705\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   4.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7022 - recall_at_precision: 0.2703\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   4.9s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7091 - recall_at_precision: 0.2702\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7078 - recall_at_precision: 0.2700\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   3.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7054 - recall_at_precision: 0.2698\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   4.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7053 - recall_at_precision: 0.2697\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7016 - recall_at_precision: 0.2695\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   3.4s\n",
      "248/248 [==============================] - 5s 8ms/step - loss: 0.7073 - recall_at_precision: 0.2693\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   5.4s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.7000 - recall_at_precision: 0.2692\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.4s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7048 - recall_at_precision: 0.2690\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.7s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7061 - recall_at_precision: 0.2688\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   3.7s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7054 - recall_at_precision: 0.2687\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   3.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7059 - recall_at_precision: 0.2685\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.3s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.7005 - recall_at_precision: 0.2683\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   5.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7067 - recall_at_precision: 0.2682\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.6s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.7061 - recall_at_precision: 0.2680\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.2s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7044 - recall_at_precision: 0.2679\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.6s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7127 - recall_at_precision: 0.2677\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7120 - recall_at_precision: 0.2676\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   4.7s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7034 - recall_at_precision: 0.2674\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   5.0s\n",
      "248/248 [==============================] - 5s 8ms/step - loss: 0.6998 - recall_at_precision: 0.2672\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   6.1s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7001 - recall_at_precision: 0.2671\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   4.3s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7071 - recall_at_precision: 0.2669\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7038 - recall_at_precision: 0.2667\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7068 - recall_at_precision: 0.2666\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.3s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7066 - recall_at_precision: 0.2664\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.1s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7044 - recall_at_precision: 0.2663\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7151 - recall_at_precision: 0.2662\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7085 - recall_at_precision: 0.2660\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   3.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7118 - recall_at_precision: 0.2659\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7103 - recall_at_precision: 0.2658\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   5.0s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7189 - recall_at_precision: 0.2657\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7128 - recall_at_precision: 0.2655\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.8s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.7104 - recall_at_precision: 0.2654\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.7179 - recall_at_precision: 0.2653\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   5.1s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7155 - recall_at_precision: 0.2651\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7060 - recall_at_precision: 0.2650\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.7142 - recall_at_precision: 0.2648\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   5.1s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7044 - recall_at_precision: 0.2647\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7139 - recall_at_precision: 0.2646\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7132 - recall_at_precision: 0.2645\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7144 - recall_at_precision: 0.2643\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.0s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.7088 - recall_at_precision: 0.2642\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7103 - recall_at_precision: 0.2640\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   6.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7045 - recall_at_precision: 0.2639\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   4.5s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.7186 - recall_at_precision: 0.2638\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   4.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7107 - recall_at_precision: 0.2636\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   4.7s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7118 - recall_at_precision: 0.2635\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   5.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7167 - recall_at_precision: 0.2633\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   5.3s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7104 - recall_at_precision: 0.2632\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.7s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7262 - recall_at_precision: 0.2631\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.8s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.7114 - recall_at_precision: 0.2630\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.8s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7164 - recall_at_precision: 0.2628\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.1s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7101 - recall_at_precision: 0.2627\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.5s\n",
      "248/248 [==============================] - 4s 10ms/step - loss: 0.7127 - recall_at_precision: 0.2626\n",
      "62/62 [==============================] - 0s 4ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.2s\n",
      "248/248 [==============================] - 5s 9ms/step - loss: 0.7129 - recall_at_precision: 0.2625\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   6.0s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7076 - recall_at_precision: 0.2623\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7135 - recall_at_precision: 0.2622\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   4.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7079 - recall_at_precision: 0.2621\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   3.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7112 - recall_at_precision: 0.2619\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   5.0s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7122 - recall_at_precision: 0.2618\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   4.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7138 - recall_at_precision: 0.2617\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   3.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7098 - recall_at_precision: 0.2615\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   3.7s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7066 - recall_at_precision: 0.2614\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7080 - recall_at_precision: 0.2613\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7157 - recall_at_precision: 0.2611\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   3.7s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7101 - recall_at_precision: 0.2556\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   5.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7152 - recall_at_precision: 0.2555\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   5.4s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7065 - recall_at_precision: 0.2553\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7075 - recall_at_precision: 0.2552\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   4.4s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7096 - recall_at_precision: 0.2550\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7086 - recall_at_precision: 0.2549\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   3.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7074 - recall_at_precision: 0.2548\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   5.3s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7119 - recall_at_precision: 0.2546\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.7s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7113 - recall_at_precision: 0.2545\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.7s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7142 - recall_at_precision: 0.2544\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7086 - recall_at_precision: 0.2543\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.7s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7120 - recall_at_precision: 0.2541\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7074 - recall_at_precision: 0.2540\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 5s 9ms/step - loss: 0.7083 - recall_at_precision: 0.2539\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   5.4s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7125 - recall_at_precision: 0.2538\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7079 - recall_at_precision: 0.2536\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.8s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7045 - recall_at_precision: 0.2535\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   4.7s\n",
      "248/248 [==============================] - 5s 9ms/step - loss: 0.7120 - recall_at_precision: 0.2533\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.4s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7161 - recall_at_precision: 0.2532\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.1s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7130 - recall_at_precision: 0.2531\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   4.5s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7127 - recall_at_precision: 0.2530\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=70, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   4.8s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4607 - recall_at_precision: 0.2532\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   4.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4571 - recall_at_precision: 0.2534\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   4.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5201 - recall_at_precision: 0.2535\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   3.9s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4843 - recall_at_precision: 0.2537\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   3.4s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5052 - recall_at_precision: 0.2538\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   3.6s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.4882 - recall_at_precision: 0.2540\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   5.3s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.4609 - recall_at_precision: 0.2542\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   4.4s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5103 - recall_at_precision: 0.2543\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5231 - recall_at_precision: 0.2544\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   4.9s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.4750 - recall_at_precision: 0.2545\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   3.6s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.5266 - recall_at_precision: 0.2546\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   4.1s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5118 - recall_at_precision: 0.2547\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   4.1s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5003 - recall_at_precision: 0.2548\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   5.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5211 - recall_at_precision: 0.2550\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   5.2s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5072 - recall_at_precision: 0.2551\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   5.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.4887 - recall_at_precision: 0.2552\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5380 - recall_at_precision: 0.2607\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5494 - recall_at_precision: 0.2608\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   5.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5199 - recall_at_precision: 0.2609\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.5194 - recall_at_precision: 0.2610\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   4.7s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5267 - recall_at_precision: 0.2611\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   5.2s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5099 - recall_at_precision: 0.2612\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.5s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5172 - recall_at_precision: 0.2613\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   5.0s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5135 - recall_at_precision: 0.2614\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.5s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5264 - recall_at_precision: 0.2614\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 5s 9ms/step - loss: 0.4949 - recall_at_precision: 0.2616\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   5.5s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5357 - recall_at_precision: 0.2616\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   5.1s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5453 - recall_at_precision: 0.2617\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   5.2s\n",
      "248/248 [==============================] - 5s 9ms/step - loss: 0.5235 - recall_at_precision: 0.2618\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   6.0s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5323 - recall_at_precision: 0.2619\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4829 - recall_at_precision: 0.2620\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4864 - recall_at_precision: 0.2622\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   4.9s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.4811 - recall_at_precision: 0.2623\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   4.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4844 - recall_at_precision: 0.2625\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   3.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5136 - recall_at_precision: 0.2626\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   4.3s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.4983 - recall_at_precision: 0.2628\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   4.4s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.4870 - recall_at_precision: 0.2629\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   3.7s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.4963 - recall_at_precision: 0.2631\n",
      "62/62 [==============================] - 1s 12ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   4.3s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5045 - recall_at_precision: 0.2632\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   4.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.4893 - recall_at_precision: 0.2633\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   4.4s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.4748 - recall_at_precision: 0.2635\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   5.4s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.5003 - recall_at_precision: 0.2636\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.7s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5178 - recall_at_precision: 0.2637\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.7s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.4886 - recall_at_precision: 0.2639\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.0s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5199 - recall_at_precision: 0.2640\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   5.2s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5072 - recall_at_precision: 0.2640\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.6s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.4898 - recall_at_precision: 0.2642\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.6s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.5022 - recall_at_precision: 0.2643\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.6s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5080 - recall_at_precision: 0.2643\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.1s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5266 - recall_at_precision: 0.2644\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   5.2s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5291 - recall_at_precision: 0.2645\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   4.5s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5287 - recall_at_precision: 0.2646\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   5.2s\n",
      "248/248 [==============================] - 5s 9ms/step - loss: 0.5498 - recall_at_precision: 0.2646\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   5.8s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5437 - recall_at_precision: 0.2646\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5676 - recall_at_precision: 0.2647\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   4.8s\n",
      "248/248 [==============================] - 5s 9ms/step - loss: 0.5179 - recall_at_precision: 0.2648\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.5s\n",
      "248/248 [==============================] - 4s 10ms/step - loss: 0.5164 - recall_at_precision: 0.2648\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.2s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5143 - recall_at_precision: 0.2649\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5818 - recall_at_precision: 0.2649\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.1s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5190 - recall_at_precision: 0.2650\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5452 - recall_at_precision: 0.2651\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.9s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5009 - recall_at_precision: 0.2652\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.3s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5250 - recall_at_precision: 0.2653\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.5s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5525 - recall_at_precision: 0.2654\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   5.1s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5130 - recall_at_precision: 0.2655\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5547 - recall_at_precision: 0.2655\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5200 - recall_at_precision: 0.2656\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   3.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6026 - recall_at_precision: 0.2655\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   5.1s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5647 - recall_at_precision: 0.2655\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5458 - recall_at_precision: 0.2656\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.5498 - recall_at_precision: 0.2656\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.0s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.5824 - recall_at_precision: 0.2656\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.7s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.5662 - recall_at_precision: 0.2656\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5754 - recall_at_precision: 0.2656\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   5.1s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.5620 - recall_at_precision: 0.2656\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5344 - recall_at_precision: 0.2657\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   5.1s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5952 - recall_at_precision: 0.2656\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   5.1s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5886 - recall_at_precision: 0.2656\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   4.2s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5821 - recall_at_precision: 0.2656\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   5.0s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.6341 - recall_at_precision: 0.2655\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   5.1s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5271 - recall_at_precision: 0.2656\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   5.0s\n",
      "248/248 [==============================] - 5s 10ms/step - loss: 0.6004 - recall_at_precision: 0.2655\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   6.5s\n",
      "248/248 [==============================] - 5s 8ms/step - loss: 0.5778 - recall_at_precision: 0.2655\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   6.1s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.6310 - recall_at_precision: 0.2654\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   5.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5503 - recall_at_precision: 0.2654\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   5.4s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5781 - recall_at_precision: 0.2654\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.1s\n",
      "248/248 [==============================] - 5s 9ms/step - loss: 0.5996 - recall_at_precision: 0.2654\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   6.1s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5672 - recall_at_precision: 0.2654\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   4.6s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5545 - recall_at_precision: 0.2654\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.1s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5521 - recall_at_precision: 0.2655\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.1s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5189 - recall_at_precision: 0.2656\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5668 - recall_at_precision: 0.2712\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   4.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5213 - recall_at_precision: 0.2713\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   3.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5244 - recall_at_precision: 0.2714\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5306 - recall_at_precision: 0.2715\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   3.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5525 - recall_at_precision: 0.2715\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5850 - recall_at_precision: 0.2715\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   5.2s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5646 - recall_at_precision: 0.2715\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.3s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5358 - recall_at_precision: 0.2715\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.8s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5790 - recall_at_precision: 0.2715\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.9s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5585 - recall_at_precision: 0.2716\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   4.7s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5577 - recall_at_precision: 0.2716\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   3.8s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5551 - recall_at_precision: 0.2716\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   4.0s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5596 - recall_at_precision: 0.2716\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   5.2s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.6122 - recall_at_precision: 0.2716\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5336 - recall_at_precision: 0.2716\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.6s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.5622 - recall_at_precision: 0.2717\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.6s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5801 - recall_at_precision: 0.2717\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.7s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5662 - recall_at_precision: 0.2717\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   5.1s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5401 - recall_at_precision: 0.2717\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.7s\n",
      "248/248 [==============================] - 4s 10ms/step - loss: 0.6002 - recall_at_precision: 0.2717\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 5s 9ms/step - loss: 0.5777 - recall_at_precision: 0.2717\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   6.2s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5625 - recall_at_precision: 0.2717\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.6s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5594 - recall_at_precision: 0.2717\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   5.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5778 - recall_at_precision: 0.2717\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   5.4s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.6098 - recall_at_precision: 0.2716\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5564 - recall_at_precision: 0.2717\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5630 - recall_at_precision: 0.2717\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.1s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.6322 - recall_at_precision: 0.2716\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.1s\n",
      "248/248 [==============================] - 5s 9ms/step - loss: 0.6010 - recall_at_precision: 0.2715\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=relu, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.7s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4798 - recall_at_precision: 0.2717\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4915 - recall_at_precision: 0.2719\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.4815 - recall_at_precision: 0.2722\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4752 - recall_at_precision: 0.2724\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.4888 - recall_at_precision: 0.2726\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.4766 - recall_at_precision: 0.2729\n",
      "62/62 [==============================] - 1s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   4.3s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.4696 - recall_at_precision: 0.2731\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.4810 - recall_at_precision: 0.2733\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   4.4s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.4833 - recall_at_precision: 0.2736\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.4964 - recall_at_precision: 0.2738\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   4.4s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.4794 - recall_at_precision: 0.2740\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   4.7s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.4901 - recall_at_precision: 0.2742\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5149 - recall_at_precision: 0.2744\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   5.1s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5116 - recall_at_precision: 0.2747\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5017 - recall_at_precision: 0.2749\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   4.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.4940 - recall_at_precision: 0.2751\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   5.4s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5013 - recall_at_precision: 0.2753\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   4.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.4944 - recall_at_precision: 0.2756\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   5.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5084 - recall_at_precision: 0.2758\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   5.2s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.5113 - recall_at_precision: 0.2760\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   4.6s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5017 - recall_at_precision: 0.2762\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5149 - recall_at_precision: 0.2764\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.8s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5208 - recall_at_precision: 0.2766\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.6s\n",
      "248/248 [==============================] - 5s 9ms/step - loss: 0.5548 - recall_at_precision: 0.2768\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   5.7s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5171 - recall_at_precision: 0.2770\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.4s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.4992 - recall_at_precision: 0.2772\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   5.3s\n",
      "248/248 [==============================] - 5s 10ms/step - loss: 0.5322 - recall_at_precision: 0.2774\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   6.2s\n",
      "248/248 [==============================] - 5s 10ms/step - loss: 0.5050 - recall_at_precision: 0.2776\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   8.6s\n",
      "248/248 [==============================] - 5s 9ms/step - loss: 0.5182 - recall_at_precision: 0.2778\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   5.5s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5387 - recall_at_precision: 0.2780\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   4.8s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4746 - recall_at_precision: 0.2783\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   3.6s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4558 - recall_at_precision: 0.2785\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   3.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4764 - recall_at_precision: 0.2787\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.4874 - recall_at_precision: 0.2789\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   4.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4944 - recall_at_precision: 0.2792\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   3.3s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.4823 - recall_at_precision: 0.2794\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   4.4s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.4784 - recall_at_precision: 0.2796\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.4868 - recall_at_precision: 0.2798\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   4.7s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.4982 - recall_at_precision: 0.2800\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   4.3s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5163 - recall_at_precision: 0.2802\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   4.1s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.5035 - recall_at_precision: 0.2804\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.4904 - recall_at_precision: 0.2807\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   5.2s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.4944 - recall_at_precision: 0.2809\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5053 - recall_at_precision: 0.2811\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   3.8s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5155 - recall_at_precision: 0.2813\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.7s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5043 - recall_at_precision: 0.2815\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.4922 - recall_at_precision: 0.2817\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.7s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5279 - recall_at_precision: 0.2819\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   5.2s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5142 - recall_at_precision: 0.2821\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.7s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.5261 - recall_at_precision: 0.2823\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.4973 - recall_at_precision: 0.2825\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   5.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5054 - recall_at_precision: 0.2827\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   4.8s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.4914 - recall_at_precision: 0.2829\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5258 - recall_at_precision: 0.2831\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   5.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5241 - recall_at_precision: 0.2833\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5461 - recall_at_precision: 0.2835\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   4.9s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5328 - recall_at_precision: 0.2836\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.3s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5109 - recall_at_precision: 0.2838\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 5s 9ms/step - loss: 0.5217 - recall_at_precision: 0.2840\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.4s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5249 - recall_at_precision: 0.2842\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5017 - recall_at_precision: 0.2844\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   3.4s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5121 - recall_at_precision: 0.2846\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5065 - recall_at_precision: 0.2848\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.9s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5318 - recall_at_precision: 0.2850\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5302 - recall_at_precision: 0.2851\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.7s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5169 - recall_at_precision: 0.2912\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.4896 - recall_at_precision: 0.2914\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.3s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5427 - recall_at_precision: 0.2915\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   3.7s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5702 - recall_at_precision: 0.2917\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   3.9s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5241 - recall_at_precision: 0.2918\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   3.9s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.5573 - recall_at_precision: 0.2920\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5049 - recall_at_precision: 0.2922\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   5.0s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.6053 - recall_at_precision: 0.2923\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5343 - recall_at_precision: 0.2925\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5342 - recall_at_precision: 0.2926\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5717 - recall_at_precision: 0.2928\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5683 - recall_at_precision: 0.2929\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   4.4s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5301 - recall_at_precision: 0.2931\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   5.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5637 - recall_at_precision: 0.2933\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5843 - recall_at_precision: 0.2934\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   4.9s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5660 - recall_at_precision: 0.2936\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5487 - recall_at_precision: 0.2937\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.6s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5753 - recall_at_precision: 0.2939\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   5.7s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5731 - recall_at_precision: 0.2940\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6341 - recall_at_precision: 0.2941\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   5.0s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5777 - recall_at_precision: 0.2942\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.2s\n",
      "248/248 [==============================] - 5s 10ms/step - loss: 0.6518 - recall_at_precision: 0.2942\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.9s\n",
      "248/248 [==============================] - 4s 10ms/step - loss: 0.6182 - recall_at_precision: 0.2943\n",
      "62/62 [==============================] - 1s 15ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   6.2s\n",
      "248/248 [==============================] - 5s 11ms/step - loss: 0.6231 - recall_at_precision: 0.2944\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   8.0s\n",
      "248/248 [==============================] - 5s 9ms/step - loss: 0.6313 - recall_at_precision: 0.2945\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.9s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5045 - recall_at_precision: 0.2947\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.4965 - recall_at_precision: 0.2949\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   3.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5111 - recall_at_precision: 0.2951\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   4.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5178 - recall_at_precision: 0.2952\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   4.2s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.5140 - recall_at_precision: 0.2954\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   5.0s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5121 - recall_at_precision: 0.2956\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5649 - recall_at_precision: 0.2957\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.6s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.5031 - recall_at_precision: 0.2959\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   5.1s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.5455 - recall_at_precision: 0.2961\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.0s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5490 - recall_at_precision: 0.2962\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.5350 - recall_at_precision: 0.2964\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.5307 - recall_at_precision: 0.2966\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   5.2s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.5515 - recall_at_precision: 0.2967\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   4.7s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.5492 - recall_at_precision: 0.2969\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.5504 - recall_at_precision: 0.2971\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5565 - recall_at_precision: 0.2972\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.7s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5642 - recall_at_precision: 0.2974\n",
      "62/62 [==============================] - 1s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.7s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5781 - recall_at_precision: 0.2975\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5927 - recall_at_precision: 0.2976\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.2s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5492 - recall_at_precision: 0.2978\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   5.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5720 - recall_at_precision: 0.2979\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   5.3s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.5810 - recall_at_precision: 0.2980\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.5842 - recall_at_precision: 0.2981\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   5.4s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.6007 - recall_at_precision: 0.2982\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.5s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.6002 - recall_at_precision: 0.2984\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   5.3s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7176 - recall_at_precision: 0.2983\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.1s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.6655 - recall_at_precision: 0.2983\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.1s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.6018 - recall_at_precision: 0.2984\n",
      "62/62 [==============================] - 1s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.9s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.6111 - recall_at_precision: 0.2985\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.1s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.6353 - recall_at_precision: 0.2985\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=tanh, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.7009 - recall_at_precision: 0.2984\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   5.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7043 - recall_at_precision: 0.2982\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   3.6s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7037 - recall_at_precision: 0.2923\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7065 - recall_at_precision: 0.2921\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7066 - recall_at_precision: 0.2920\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=7; total time=   4.8s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7078 - recall_at_precision: 0.2919\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   4.4s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7088 - recall_at_precision: 0.2917\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7017 - recall_at_precision: 0.2916\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   4.3s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7106 - recall_at_precision: 0.2914\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   4.4s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7032 - recall_at_precision: 0.2913\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=8; total time=   4.4s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7045 - recall_at_precision: 0.2911\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7014 - recall_at_precision: 0.2910\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   4.3s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7079 - recall_at_precision: 0.2909\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   5.4s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7031 - recall_at_precision: 0.2907\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   4.7s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7026 - recall_at_precision: 0.2906\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=9; total time=   4.9s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7070 - recall_at_precision: 0.2904\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   4.3s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7072 - recall_at_precision: 0.2903\n",
      "62/62 [==============================] - 1s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   5.2s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7040 - recall_at_precision: 0.2901\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7062 - recall_at_precision: 0.2900\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7054 - recall_at_precision: 0.2899\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=10; total time=   4.4s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7021 - recall_at_precision: 0.2897\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.7s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7030 - recall_at_precision: 0.2896\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   5.2s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7030 - recall_at_precision: 0.2894\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   5.5s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7032 - recall_at_precision: 0.2893\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   4.7s\n",
      "248/248 [==============================] - 5s 10ms/step - loss: 0.7052 - recall_at_precision: 0.2892\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=11; total time=   5.8s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7042 - recall_at_precision: 0.2890\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   5.5s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7072 - recall_at_precision: 0.2889\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   5.2s\n",
      "248/248 [==============================] - 4s 10ms/step - loss: 0.7023 - recall_at_precision: 0.2888\n",
      "62/62 [==============================] - 1s 3ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   6.4s\n",
      "248/248 [==============================] - 5s 10ms/step - loss: 0.7045 - recall_at_precision: 0.2886\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   6.3s\n",
      "248/248 [==============================] - 5s 9ms/step - loss: 0.7033 - recall_at_precision: 0.2885\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=75, num_layers=12; total time=   5.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7048 - recall_at_precision: 0.2883\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   4.7s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7056 - recall_at_precision: 0.2882\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   4.3s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7072 - recall_at_precision: 0.2881\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7073 - recall_at_precision: 0.2879\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   4.2s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7090 - recall_at_precision: 0.2878\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=7; total time=   5.0s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.7041 - recall_at_precision: 0.2877\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   5.2s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7025 - recall_at_precision: 0.2875\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7052 - recall_at_precision: 0.2874\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   4.3s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7059 - recall_at_precision: 0.2872\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   4.4s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7058 - recall_at_precision: 0.2871\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.7046 - recall_at_precision: 0.2870\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7033 - recall_at_precision: 0.2868\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   5.2s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7069 - recall_at_precision: 0.2867\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.6997 - recall_at_precision: 0.2865\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.9s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7042 - recall_at_precision: 0.2864\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.7034 - recall_at_precision: 0.2863\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.7s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.7030 - recall_at_precision: 0.2861\n",
      "62/62 [==============================] - 1s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   5.6s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7052 - recall_at_precision: 0.2860\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   5.5s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7056 - recall_at_precision: 0.2858\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7007 - recall_at_precision: 0.2857\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=10; total time=   4.7s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7055 - recall_at_precision: 0.2856\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   4.5s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7058 - recall_at_precision: 0.2854\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   5.2s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7022 - recall_at_precision: 0.2853\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   5.5s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7065 - recall_at_precision: 0.2852\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   5.0s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7072 - recall_at_precision: 0.2850\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=11; total time=   4.6s\n",
      "248/248 [==============================] - 5s 10ms/step - loss: 0.7069 - recall_at_precision: 0.2849\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.4s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7042 - recall_at_precision: 0.2848\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.2s\n",
      "248/248 [==============================] - 4s 10ms/step - loss: 0.7048 - recall_at_precision: 0.2846\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.1s\n",
      "248/248 [==============================] - 6s 9ms/step - loss: 0.7055 - recall_at_precision: 0.2845\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   7.0s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7041 - recall_at_precision: 0.2844\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.2, num_epochs=100, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7113 - recall_at_precision: 0.2843\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7091 - recall_at_precision: 0.2841\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7135 - recall_at_precision: 0.2840\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   3.5s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7090 - recall_at_precision: 0.2839\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.4s\n",
      "248/248 [==============================] - 3s 6ms/step - loss: 0.7093 - recall_at_precision: 0.2838\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=7; total time=   4.9s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7099 - recall_at_precision: 0.2837\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   3.7s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7113 - recall_at_precision: 0.2836\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7126 - recall_at_precision: 0.2834\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7108 - recall_at_precision: 0.2833\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   3.8s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7123 - recall_at_precision: 0.2832\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=8; total time=   4.7s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7124 - recall_at_precision: 0.2831\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.7s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7113 - recall_at_precision: 0.2830\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   5.9s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.7110 - recall_at_precision: 0.2829\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.0s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.7116 - recall_at_precision: 0.2828\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.7s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.7100 - recall_at_precision: 0.2826\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.7131 - recall_at_precision: 0.2825\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   4.7s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7142 - recall_at_precision: 0.2824\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   5.1s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7102 - recall_at_precision: 0.2823\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7106 - recall_at_precision: 0.2822\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   4.6s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7098 - recall_at_precision: 0.2821\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7167 - recall_at_precision: 0.2820\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.8s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7182 - recall_at_precision: 0.2819\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   5.1s\n",
      "248/248 [==============================] - 5s 10ms/step - loss: 0.7127 - recall_at_precision: 0.2818\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   5.7s\n",
      "248/248 [==============================] - 5s 9ms/step - loss: 0.7142 - recall_at_precision: 0.2817\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   5.6s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7046 - recall_at_precision: 0.2815\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7121 - recall_at_precision: 0.2814\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.2s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7093 - recall_at_precision: 0.2813\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.2s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7097 - recall_at_precision: 0.2812\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.2s\n",
      "248/248 [==============================] - 5s 9ms/step - loss: 0.7158 - recall_at_precision: 0.2811\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.8s\n",
      "248/248 [==============================] - 4s 10ms/step - loss: 0.7134 - recall_at_precision: 0.2810\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=75, num_layers=12; total time=   5.2s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7030 - recall_at_precision: 0.2809\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7085 - recall_at_precision: 0.2807\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   4.5s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.7164 - recall_at_precision: 0.2751\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   5.2s\n",
      "248/248 [==============================] - 4s 7ms/step - loss: 0.7214 - recall_at_precision: 0.2750\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   4.5s\n",
      "248/248 [==============================] - 4s 6ms/step - loss: 0.7081 - recall_at_precision: 0.2749\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=7; total time=   5.3s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7071 - recall_at_precision: 0.2748\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   3.8s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7096 - recall_at_precision: 0.2746\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7128 - recall_at_precision: 0.2745\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.4s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7127 - recall_at_precision: 0.2744\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.4s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7060 - recall_at_precision: 0.2743\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=8; total time=   4.4s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7107 - recall_at_precision: 0.2742\n",
      "62/62 [==============================] - 1s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   5.2s\n",
      "248/248 [==============================] - 3s 8ms/step - loss: 0.7048 - recall_at_precision: 0.2741\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7153 - recall_at_precision: 0.2740\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   4.5s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7115 - recall_at_precision: 0.2738\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 3s 7ms/step - loss: 0.7131 - recall_at_precision: 0.2737\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=9; total time=   4.6s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7080 - recall_at_precision: 0.2736\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.3s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7094 - recall_at_precision: 0.2735\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   5.5s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7195 - recall_at_precision: 0.2734\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.1s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7149 - recall_at_precision: 0.2733\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   5.1s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7178 - recall_at_precision: 0.2732\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=10; total time=   4.8s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7088 - recall_at_precision: 0.2731\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.4s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7085 - recall_at_precision: 0.2730\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.6s\n",
      "248/248 [==============================] - 5s 9ms/step - loss: 0.7237 - recall_at_precision: 0.2729\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   6.0s\n",
      "248/248 [==============================] - 4s 8ms/step - loss: 0.7078 - recall_at_precision: 0.2728\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.9s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7089 - recall_at_precision: 0.2726\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=11; total time=   4.5s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7105 - recall_at_precision: 0.2725\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.0s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7131 - recall_at_precision: 0.2724\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   4.9s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7133 - recall_at_precision: 0.2723\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.5s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7122 - recall_at_precision: 0.2722\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.4s\n",
      "248/248 [==============================] - 4s 9ms/step - loss: 0.7099 - recall_at_precision: 0.2721\n",
      "62/62 [==============================] - 0s 2ms/step\n",
      "[CV] END H=80, activation=sigmoid, dropout_probability=0.3, num_epochs=100, num_layers=12; total time=   5.0s\n",
      "310/310 [==============================] - 4s 8ms/step - loss: 0.5139 - recall_at_precision: 0.2723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=KerasClassifier(H=10, activation='relu', dropout_probability=0.2, input_dim=12, model=<function compile_mlp at 0x7fd7d778de60>, num_epochs=50, num_layers=3),\n",
       "             param_grid={'H': [40, 50, 60, 70, 80],\n",
       "                         'activation': ('relu', 'tanh', 'sigmoid'),\n",
       "                         'dropout_probability': [0.2, 0.3],\n",
       "                         'num_epochs': [75, 100],\n",
       "                         'num_layers': [7, 8, 9, 10, 11, 12]},\n",
       "             scoring='f1', verbose=2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 360,
     "status": "ok",
     "timestamp": 1667478766305,
     "user": {
      "displayName": "Victor Wong",
      "userId": "11168613095769754614"
     },
     "user_tz": -480
    },
    "id": "n6OwFVh35BfG",
    "outputId": "aaace8fa-9d0b-4789-e7db-b7319994dc88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'H': 60,\n",
       " 'activation': 'relu',\n",
       " 'dropout_probability': 0.2,\n",
       " 'num_epochs': 75,\n",
       " 'num_layers': 10}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1667478772446,
     "user": {
      "displayName": "Victor Wong",
      "userId": "11168613095769754614"
     },
     "user_tz": -480
    },
    "id": "fI8a4KorlDMQ",
    "outputId": "ea7a8764-399c-4f2c-9f5e-aae9fc143f2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8598840668211614"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 322,
     "status": "ok",
     "timestamp": 1667478788127,
     "user": {
      "displayName": "Victor Wong",
      "userId": "11168613095769754614"
     },
     "user_tz": -480
    },
    "id": "DQbAZo3p_y6y",
    "outputId": "e8083186-f4be-4692-8d8f-de35c667666f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KerasClassifier(\n",
       "\tmodel=<function compile_mlp at 0x7fd7d778de60>\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       "\tinput_dim=12\n",
       "\tH=60\n",
       "\tnum_epochs=75\n",
       "\tnum_layers=10\n",
       "\tactivation=relu\n",
       "\tdropout_probability=0.2\n",
       "\tclass_weight=None\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mlp = grid.best_estimator_\n",
    "best_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 921
    },
    "executionInfo": {
     "elapsed": 712,
     "status": "ok",
     "timestamp": 1667478838649,
     "user": {
      "displayName": "Victor Wong",
      "userId": "11168613095769754614"
     },
     "user_tz": -480
    },
    "id": "OWiuIdYUlETw",
    "outputId": "60a961c0-f9b5-40e5-ecbb-59f86a9759e4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-52b1ec7e-a5e5-4ab1-a796-7d3ad36cbf61\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_H</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>param_dropout_probability</th>\n",
       "      <th>param_num_epochs</th>\n",
       "      <th>param_num_layers</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.269723</td>\n",
       "      <td>1.763868</td>\n",
       "      <td>0.256154</td>\n",
       "      <td>0.003644</td>\n",
       "      <td>40</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>75</td>\n",
       "      <td>7</td>\n",
       "      <td>{'H': 40, 'activation': 'relu', 'dropout_proba...</td>\n",
       "      <td>0.840157</td>\n",
       "      <td>0.849462</td>\n",
       "      <td>0.837480</td>\n",
       "      <td>0.843267</td>\n",
       "      <td>0.869372</td>\n",
       "      <td>0.847948</td>\n",
       "      <td>0.011432</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.508060</td>\n",
       "      <td>0.226203</td>\n",
       "      <td>0.304012</td>\n",
       "      <td>0.092718</td>\n",
       "      <td>40</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>75</td>\n",
       "      <td>8</td>\n",
       "      <td>{'H': 40, 'activation': 'relu', 'dropout_proba...</td>\n",
       "      <td>0.827473</td>\n",
       "      <td>0.828723</td>\n",
       "      <td>0.834793</td>\n",
       "      <td>0.816754</td>\n",
       "      <td>0.828905</td>\n",
       "      <td>0.827329</td>\n",
       "      <td>0.005865</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.090054</td>\n",
       "      <td>0.298628</td>\n",
       "      <td>0.267561</td>\n",
       "      <td>0.018038</td>\n",
       "      <td>40</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>75</td>\n",
       "      <td>9</td>\n",
       "      <td>{'H': 40, 'activation': 'relu', 'dropout_proba...</td>\n",
       "      <td>0.807093</td>\n",
       "      <td>0.824859</td>\n",
       "      <td>0.802974</td>\n",
       "      <td>0.829837</td>\n",
       "      <td>0.828893</td>\n",
       "      <td>0.818731</td>\n",
       "      <td>0.011383</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.856402</td>\n",
       "      <td>0.164006</td>\n",
       "      <td>0.272061</td>\n",
       "      <td>0.020201</td>\n",
       "      <td>40</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>75</td>\n",
       "      <td>10</td>\n",
       "      <td>{'H': 40, 'activation': 'relu', 'dropout_proba...</td>\n",
       "      <td>0.788797</td>\n",
       "      <td>0.837185</td>\n",
       "      <td>0.843886</td>\n",
       "      <td>0.827111</td>\n",
       "      <td>0.822329</td>\n",
       "      <td>0.823862</td>\n",
       "      <td>0.019084</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.992531</td>\n",
       "      <td>0.161860</td>\n",
       "      <td>0.272565</td>\n",
       "      <td>0.022007</td>\n",
       "      <td>40</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>75</td>\n",
       "      <td>11</td>\n",
       "      <td>{'H': 40, 'activation': 'relu', 'dropout_proba...</td>\n",
       "      <td>0.840373</td>\n",
       "      <td>0.784119</td>\n",
       "      <td>0.813046</td>\n",
       "      <td>0.831237</td>\n",
       "      <td>0.850178</td>\n",
       "      <td>0.823791</td>\n",
       "      <td>0.023307</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>3.978984</td>\n",
       "      <td>0.346362</td>\n",
       "      <td>0.348326</td>\n",
       "      <td>0.074033</td>\n",
       "      <td>80</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>{'H': 80, 'activation': 'sigmoid', 'dropout_pr...</td>\n",
       "      <td>0.630270</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126054</td>\n",
       "      <td>0.252108</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>4.189176</td>\n",
       "      <td>0.017048</td>\n",
       "      <td>0.493316</td>\n",
       "      <td>0.243556</td>\n",
       "      <td>80</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>9</td>\n",
       "      <td>{'H': 80, 'activation': 'sigmoid', 'dropout_pr...</td>\n",
       "      <td>0.630270</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.630743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252202</td>\n",
       "      <td>0.308884</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>4.289061</td>\n",
       "      <td>0.492117</td>\n",
       "      <td>0.476351</td>\n",
       "      <td>0.055950</td>\n",
       "      <td>80</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>{'H': 80, 'activation': 'sigmoid', 'dropout_pr...</td>\n",
       "      <td>0.630270</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.630743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252202</td>\n",
       "      <td>0.308884</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>4.458329</td>\n",
       "      <td>0.575885</td>\n",
       "      <td>0.453220</td>\n",
       "      <td>0.064476</td>\n",
       "      <td>80</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>11</td>\n",
       "      <td>{'H': 80, 'activation': 'sigmoid', 'dropout_pr...</td>\n",
       "      <td>0.630270</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126054</td>\n",
       "      <td>0.252108</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>4.671990</td>\n",
       "      <td>0.203492</td>\n",
       "      <td>0.482304</td>\n",
       "      <td>0.061575</td>\n",
       "      <td>80</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>12</td>\n",
       "      <td>{'H': 80, 'activation': 'sigmoid', 'dropout_pr...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 18 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52b1ec7e-a5e5-4ab1-a796-7d3ad36cbf61')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-52b1ec7e-a5e5-4ab1-a796-7d3ad36cbf61 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-52b1ec7e-a5e5-4ab1-a796-7d3ad36cbf61');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time param_H  \\\n",
       "0         3.269723      1.763868         0.256154        0.003644      40   \n",
       "1         2.508060      0.226203         0.304012        0.092718      40   \n",
       "2         3.090054      0.298628         0.267561        0.018038      40   \n",
       "3         2.856402      0.164006         0.272061        0.020201      40   \n",
       "4         2.992531      0.161860         0.272565        0.022007      40   \n",
       "..             ...           ...              ...             ...     ...   \n",
       "355       3.978984      0.346362         0.348326        0.074033      80   \n",
       "356       4.189176      0.017048         0.493316        0.243556      80   \n",
       "357       4.289061      0.492117         0.476351        0.055950      80   \n",
       "358       4.458329      0.575885         0.453220        0.064476      80   \n",
       "359       4.671990      0.203492         0.482304        0.061575      80   \n",
       "\n",
       "    param_activation param_dropout_probability param_num_epochs  \\\n",
       "0               relu                       0.2               75   \n",
       "1               relu                       0.2               75   \n",
       "2               relu                       0.2               75   \n",
       "3               relu                       0.2               75   \n",
       "4               relu                       0.2               75   \n",
       "..               ...                       ...              ...   \n",
       "355          sigmoid                       0.3              100   \n",
       "356          sigmoid                       0.3              100   \n",
       "357          sigmoid                       0.3              100   \n",
       "358          sigmoid                       0.3              100   \n",
       "359          sigmoid                       0.3              100   \n",
       "\n",
       "    param_num_layers                                             params  \\\n",
       "0                  7  {'H': 40, 'activation': 'relu', 'dropout_proba...   \n",
       "1                  8  {'H': 40, 'activation': 'relu', 'dropout_proba...   \n",
       "2                  9  {'H': 40, 'activation': 'relu', 'dropout_proba...   \n",
       "3                 10  {'H': 40, 'activation': 'relu', 'dropout_proba...   \n",
       "4                 11  {'H': 40, 'activation': 'relu', 'dropout_proba...   \n",
       "..               ...                                                ...   \n",
       "355                8  {'H': 80, 'activation': 'sigmoid', 'dropout_pr...   \n",
       "356                9  {'H': 80, 'activation': 'sigmoid', 'dropout_pr...   \n",
       "357               10  {'H': 80, 'activation': 'sigmoid', 'dropout_pr...   \n",
       "358               11  {'H': 80, 'activation': 'sigmoid', 'dropout_pr...   \n",
       "359               12  {'H': 80, 'activation': 'sigmoid', 'dropout_pr...   \n",
       "\n",
       "     split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0             0.840157           0.849462           0.837480   \n",
       "1             0.827473           0.828723           0.834793   \n",
       "2             0.807093           0.824859           0.802974   \n",
       "3             0.788797           0.837185           0.843886   \n",
       "4             0.840373           0.784119           0.813046   \n",
       "..                 ...                ...                ...   \n",
       "355           0.630270           0.000000           0.000000   \n",
       "356           0.630270           0.000000           0.630743   \n",
       "357           0.630270           0.000000           0.630743   \n",
       "358           0.630270           0.000000           0.000000   \n",
       "359           0.000000           0.000000           0.000000   \n",
       "\n",
       "     split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0             0.843267           0.869372         0.847948        0.011432   \n",
       "1             0.816754           0.828905         0.827329        0.005865   \n",
       "2             0.829837           0.828893         0.818731        0.011383   \n",
       "3             0.827111           0.822329         0.823862        0.019084   \n",
       "4             0.831237           0.850178         0.823791        0.023307   \n",
       "..                 ...                ...              ...             ...   \n",
       "355           0.000000           0.000000         0.126054        0.252108   \n",
       "356           0.000000           0.000000         0.252202        0.308884   \n",
       "357           0.000000           0.000000         0.252202        0.308884   \n",
       "358           0.000000           0.000000         0.126054        0.252108   \n",
       "359           0.000000           0.000000         0.000000        0.000000   \n",
       "\n",
       "     rank_test_score  \n",
       "0                 19  \n",
       "1                 88  \n",
       "2                114  \n",
       "3                 93  \n",
       "4                 94  \n",
       "..               ...  \n",
       "355              255  \n",
       "356              242  \n",
       "357              242  \n",
       "358              255  \n",
       "359              290  \n",
       "\n",
       "[360 rows x 18 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(grid.cv_results_)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "amfA_ymSlMGN"
   },
   "outputs": [],
   "source": [
    "results.to_csv('mlp-grid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 951,
     "status": "ok",
     "timestamp": 1667478846718,
     "user": {
      "displayName": "Victor Wong",
      "userId": "11168613095769754614"
     },
     "user_tz": -480
    },
    "id": "vIZUvFOFln3L",
    "outputId": "5d988608-8ef6-496a-e380-b0f849cc8915"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8669649164115847"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mlp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5451,
     "status": "ok",
     "timestamp": 1668342068949,
     "user": {
      "displayName": "Darrell Lai",
      "userId": "03944376215088217788"
     },
     "user_tz": -480
    },
    "id": "ldoXpZhxfmC3",
    "outputId": "d0ad20dc-e50c-42eb-94e3-4c30196754c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310/310 [==============================] - 3s 4ms/step - loss: 0.4807 - recall_at_precision_1: 0.7179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6f58e03b50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tuned = compile_mlp(X_train_full.shape[1], 60, 75, 10, 'relu', 0.2)\n",
    "model_tuned.fit(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 918,
     "status": "ok",
     "timestamp": 1668342075386,
     "user": {
      "displayName": "Darrell Lai",
      "userId": "03944376215088217788"
     },
     "user_tz": -480
    },
    "id": "LqByDjKFEDy_",
    "outputId": "6d8f0d03-de34-4fab-e2fe-d277765b311a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8224629149988227"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predicted_y = model_tuned.predict(X_test)\n",
    "predicted_y = (predicted_y > 0.5).astype('int32')\n",
    "accuracy_score(predicted_y, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 43
    },
    "executionInfo": {
     "elapsed": 733,
     "status": "ok",
     "timestamp": 1668342131197,
     "user": {
      "displayName": "Darrell Lai",
      "userId": "03944376215088217788"
     },
     "user_tz": -480
    },
    "id": "5WmAU4G1K5BE",
    "outputId": "ede08bb7-76c2-46c0-84d0-92e9cd7a07cf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div align='center'><img src='data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABkAAAAWCAYAAAA1vze2AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAdxJREFUeNq0Vt1Rg0AQJjcpgBJiBWIFkgoMFYhPPAIVECogPuYpdJBYgXQQrMCUkA50V7+d2ZwXuXPGm9khHLu3f9+3l1nkWNvtNqfHLgpfQ1EUS3tz5nAQ0+NIsiAZSc6eDlI8M3J00B/mDuUKDk6kfOebAgW3pkdD0pFcODGW4gKKvOrAUm04MA4QDt1OEIXU9hDigfS5rC1eS5T90gltck1Xrizo257kgySZcNRzgCSxCvgiE9nckPJo2b/B2AcEkk2OwL8bD8gmOKR1GPbaCUqxEgTq0tLvgb6zfo7+DgYGkkWL2tqLDV4RSITfbHPPfJKIrWz4nJQTMPAWA7IbD6imcNaDeDfgk+4No+wZr40BL3g9eQJJCFqRQ54KiSt72lsLpE3o3MCBSxDuq4yOckU2hKXRuwBH3OyMR4g1UpyTYw6mlmBqNdUXRM1NfyF5EPI6JkcpIDBIX8jX6DR/6ckAZJ0wEAdLR8DEk6OfC1Pp8BKo6TQIwPJbvJ6toK5lmuvJoRtfK6Ym1iRYIarRo2UyYHvRN5qpakR3yoizWrouoyuXXQqI185LCw07op5ZyCRGL99h24InP0e9xdQukEKVmhzrqZuRIfwISB//cP3Wk3f8f/yR+BRgAHu00HjLcEQBAAAAAElFTkSuQmCC' /></div><script charset='utf-8'>!function(t){function e(r){if(n[r])return n[r].exports;var i=n[r]={i:r,l:!1,exports:{}};return t[r].call(i.exports,i,i.exports,e),i.l=!0,i.exports}var n={};return e.m=t,e.c=n,e.i=function(t){return t},e.d=function(t,n,r){e.o(t,n)||Object.defineProperty(t,n,{configurable:!1,enumerable:!0,get:r})},e.n=function(t){var n=t&&t.__esModule?function(){return t.default}:function(){return t};return e.d(n,\"a\",n),n},e.o=function(t,e){return Object.prototype.hasOwnProperty.call(t,e)},e.p=\"\",e(e.s=410)}([function(t,e,n){\"use strict\";function r(t,e,n,r,o,a,u,c){if(i(e),!t){var s;if(void 0===e)s=new Error(\"Minified exception occurred; use the non-minified dev environment for the full error message and additional helpful warnings.\");else{var l=[n,r,o,a,u,c],f=0;s=new Error(e.replace(/%s/g,function(){return l[f++]})),s.name=\"Invariant Violation\"}throw s.framesToPop=1,s}}var i=function(t){};t.exports=r},function(t,e,n){\"use strict\";var r=n(8),i=r;t.exports=i},function(t,e,n){\"use strict\";function r(t){for(var e=arguments.length-1,n=\"Minified React error #\"+t+\"; visit http://facebook.github.io/react/docs/error-decoder.html?invariant=\"+t,r=0;r<e;r++)n+=\"&args[]=\"+encodeURIComponent(arguments[r+1]);n+=\" for the full message or use the non-minified dev environment for full errors and additional helpful warnings.\";var i=new Error(n);throw i.name=\"Invariant Violation\",i.framesToPop=1,i}t.exports=r},function(t,e,n){\"use strict\";function r(t){if(null===t||void 0===t)throw new TypeError(\"Object.assign cannot be called with null or undefined\");return Object(t)}function i(){try{if(!Object.assign)return!1;var t=new String(\"abc\");if(t[5]=\"de\",\"5\"===Object.getOwnPropertyNames(t)[0])return!1;for(var e={},n=0;n<10;n++)e[\"_\"+String.fromCharCode(n)]=n;var r=Object.getOwnPropertyNames(e).map(function(t){return e[t]});if(\"0123456789\"!==r.join(\"\"))return!1;var i={};return\"abcdefghijklmnopqrst\".split(\"\").forEach(function(t){i[t]=t}),\"abcdefghijklmnopqrst\"===Object.keys(Object.assign({},i)).join(\"\")}catch(t){return!1}}/*\n",
       "object-assign\n",
       "(c) Sindre Sorhus\n",
       "@license MIT\n",
       "*/\n",
       "var o=Object.getOwnPropertySymbols,a=Object.prototype.hasOwnProperty,u=Object.prototype.propertyIsEnumerable;t.exports=i()?Object.assign:function(t,e){for(var n,i,c=r(t),s=1;s<arguments.length;s++){n=Object(arguments[s]);for(var l in n)a.call(n,l)&&(c[l]=n[l]);if(o){i=o(n);for(var f=0;f<i.length;f++)u.call(n,i[f])&&(c[i[f]]=n[i[f]])}}return c}},function(t,e,n){\"use strict\";function r(t,e){return 1===t.nodeType&&t.getAttribute(d)===String(e)||8===t.nodeType&&t.nodeValue===\" react-text: \"+e+\" \"||8===t.nodeType&&t.nodeValue===\" react-empty: \"+e+\" \"}function i(t){for(var e;e=t._renderedComponent;)t=e;return t}function o(t,e){var n=i(t);n._hostNode=e,e[g]=n}function a(t){var e=t._hostNode;e&&(delete e[g],t._hostNode=null)}function u(t,e){if(!(t._flags&v.hasCachedChildNodes)){var n=t._renderedChildren,a=e.firstChild;t:for(var u in n)if(n.hasOwnProperty(u)){var c=n[u],s=i(c)._domID;if(0!==s){for(;null!==a;a=a.nextSibling)if(r(a,s)){o(c,a);continue t}f(\"32\",s)}}t._flags|=v.hasCachedChildNodes}}function c(t){if(t[g])return t[g];for(var e=[];!t[g];){if(e.push(t),!t.parentNode)return null;t=t.parentNode}for(var n,r;t&&(r=t[g]);t=e.pop())n=r,e.length&&u(r,t);return n}function s(t){var e=c(t);return null!=e&&e._hostNode===t?e:null}function l(t){if(void 0===t._hostNode?f(\"33\"):void 0,t._hostNode)return t._hostNode;for(var e=[];!t._hostNode;)e.push(t),t._hostParent?void 0:f(\"34\"),t=t._hostParent;for(;e.length;t=e.pop())u(t,t._hostNode);return t._hostNode}var f=n(2),p=n(21),h=n(157),d=(n(0),p.ID_ATTRIBUTE_NAME),v=h,g=\"__reactInternalInstance$\"+Math.random().toString(36).slice(2),m={getClosestInstanceFromNode:c,getInstanceFromNode:s,getNodeFromInstance:l,precacheChildNodes:u,precacheNode:o,uncacheNode:a};t.exports=m},function(t,e,n){\"use strict\";function r(t,e,n,a){function u(e){return t(e=new Date(+e)),e}return u.floor=u,u.ceil=function(n){return t(n=new Date(n-1)),e(n,1),t(n),n},u.round=function(t){var e=u(t),n=u.ceil(t);return t-e<n-t?e:n},u.offset=function(t,n){return e(t=new Date(+t),null==n?1:Math.floor(n)),t},u.range=function(n,r,i){var o=[];if(n=u.ceil(n),i=null==i?1:Math.floor(i),!(n<r&&i>0))return o;do o.push(new Date(+n));while(e(n,i),t(n),n<r);return o},u.filter=function(n){return r(function(e){if(e>=e)for(;t(e),!n(e);)e.setTime(e-1)},function(t,r){if(t>=t)for(;--r>=0;)for(;e(t,1),!n(t););})},n&&(u.count=function(e,r){return i.setTime(+e),o.setTime(+r),t(i),t(o),Math.floor(n(i,o))},u.every=function(t){return t=Math.floor(t),isFinite(t)&&t>0?t>1?u.filter(a?function(e){return a(e)%t===0}:function(e){return u.count(0,e)%t===0}):u:null}),u}e.a=r;var i=new Date,o=new Date},function(t,e,n){\"use strict\";var r=!(\"undefined\"==typeof window||!window.document||!window.document.createElement),i={canUseDOM:r,canUseWorkers:\"undefined\"!=typeof Worker,canUseEventListeners:r&&!(!window.addEventListener&&!window.attachEvent),canUseViewport:r&&!!window.screen,isInWorker:!r};t.exports=i},function(t,e,n){\"use strict\";function r(t,e){this._groups=t,this._parents=e}function i(){return new r([[document.documentElement]],D)}var o=n(272),a=n(273),u=n(261),c=n(255),s=n(131),l=n(260),f=n(265),p=n(268),h=n(275),d=n(253),v=n(267),g=n(266),m=n(274),y=n(259),_=n(258),b=n(252),x=n(276),w=n(269),C=n(254),M=n(277),k=n(262),E=n(270),T=n(264),S=n(251),P=n(263),N=n(271),A=n(256),O=n(70),I=n(257);n.d(e,\"c\",function(){return D}),e.b=r;var D=[null];r.prototype=i.prototype={constructor:r,select:o.a,selectAll:a.a,filter:u.a,data:c.a,enter:s.a,exit:l.a,merge:f.a,order:p.a,sort:h.a,call:d.a,nodes:v.a,node:g.a,size:m.a,empty:y.a,each:_.a,attr:b.a,style:x.a,property:w.a,classed:C.a,text:M.a,html:k.a,raise:E.a,lower:T.a,append:S.a,insert:P.a,remove:N.a,datum:A.a,on:O.c,dispatch:I.a},e.a=i},function(t,e,n){\"use strict\";function r(t){return function(){return t}}var i=function(){};i.thatReturns=r,i.thatReturnsFalse=r(!1),i.thatReturnsTrue=r(!0),i.thatReturnsNull=r(null),i.thatReturnsThis=function(){return this},i.thatReturnsArgument=function(t){return t},t.exports=i},function(t,e,n){\"use strict\";var r=null;t.exports={debugTool:r}},function(t,e,n){\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0});var r=n(59);n.d(e,\"color\",function(){return r.a}),n.d(e,\"rgb\",function(){return r.b}),n.d(e,\"hsl\",function(){return r.c});var i=n(210);n.d(e,\"lab\",function(){return i.a}),n.d(e,\"hcl\",function(){return i.b});var o=n(209);n.d(e,\"cubehelix\",function(){return o.a})},function(t,e,n){\"use strict\";function r(){T.ReactReconcileTransaction&&x?void 0:l(\"123\")}function i(){this.reinitializeTransaction(),this.dirtyComponentsLength=null,this.callbackQueue=p.getPooled(),this.reconcileTransaction=T.ReactReconcileTransaction.getPooled(!0)}function o(t,e,n,i,o,a){return r(),x.batchedUpdates(t,e,n,i,o,a)}function a(t,e){return t._mountOrder-e._mountOrder}function u(t){var e=t.dirtyComponentsLength;e!==m.length?l(\"124\",e,m.length):void 0,m.sort(a),y++;for(var n=0;n<e;n++){var r=m[n],i=r._pendingCallbacks;r._pendingCallbacks=null;var o;if(d.logTopLevelRenders){var u=r;r._currentElement.type.isReactTopLevelWrapper&&(u=r._renderedComponent),o=\"React update: \"+u.getName(),console.time(o)}if(v.performUpdateIfNecessary(r,t.reconcileTransaction,y),o&&console.timeEnd(o),i)for(var c=0;c<i.length;c++)t.callbackQueue.enqueue(i[c],r.getPublicInstance())}}function c(t){return r(),x.isBatchingUpdates?(m.push(t),void(null==t._updateBatchNumber&&(t._updateBatchNumber=y+1))):void x.batchedUpdates(c,t)}function s(t,e){x.isBatchingUpdates?void 0:l(\"125\"),_.enqueue(t,e),b=!0}var l=n(2),f=n(3),p=n(155),h=n(17),d=n(160),v=n(24),g=n(53),m=(n(0),[]),y=0,_=p.getPooled(),b=!1,x=null,w={initialize:function(){this.dirtyComponentsLength=m.length},close:function(){this.dirtyComponentsLength!==m.length?(m.splice(0,this.dirtyComponentsLength),k()):m.length=0}},C={initialize:function(){this.callbackQueue.reset()},close:function(){this.callbackQueue.notifyAll()}},M=[w,C];f(i.prototype,g,{getTransactionWrappers:function(){return M},destructor:function(){this.dirtyComponentsLength=null,p.release(this.callbackQueue),this.callbackQueue=null,T.ReactReconcileTransaction.release(this.reconcileTransaction),this.reconcileTransaction=null},perform:function(t,e,n){return g.perform.call(this,this.reconcileTransaction.perform,this.reconcileTransaction,t,e,n)}}),h.addPoolingTo(i);var k=function(){for(;m.length||b;){if(m.length){var t=i.getPooled();t.perform(u,null,t),i.release(t)}if(b){b=!1;var e=_;_=p.getPooled(),e.notifyAll(),p.release(e)}}},E={injectReconcileTransaction:function(t){t?void 0:l(\"126\"),T.ReactReconcileTransaction=t},injectBatchingStrategy:function(t){t?void 0:l(\"127\"),\"function\"!=typeof t.batchedUpdates?l(\"128\"):void 0,\"boolean\"!=typeof t.isBatchingUpdates?l(\"129\"):void 0,x=t}},T={ReactReconcileTransaction:null,batchedUpdates:o,enqueueUpdate:c,flushBatchedUpdates:k,injection:E,asap:s};t.exports=T},function(t,e,n){\"use strict\";var r=n(102);n.d(e,\"c\",function(){return r.a});var i=n(18);n.d(e,\"f\",function(){return i.a});var o=n(103);n.d(e,\"d\",function(){return o.a});var a=(n(185),n(104),n(105),n(186),n(197),n(198),n(108),n(188),n(189),n(190),n(191),n(106),n(192),n(193),n(57));n.d(e,\"e\",function(){return a.a});var u=n(107);n.d(e,\"g\",function(){return u.a});var c=(n(194),n(195),n(196),n(109));n.d(e,\"a\",function(){return c.a}),n.d(e,\"b\",function(){return c.b});n(110),n(111),n(199)},function(t,e,n){\"use strict\";n.d(e,\"e\",function(){return r}),n.d(e,\"d\",function(){return i}),n.d(e,\"c\",function(){return o}),n.d(e,\"b\",function(){return a}),n.d(e,\"a\",function(){return u});var r=1e3,i=6e4,o=36e5,a=864e5,u=6048e5},function(t,e,n){\"use strict\";function r(t,e,n,r){this.dispatchConfig=t,this._targetInst=e,this.nativeEvent=n;var i=this.constructor.Interface;for(var o in i)if(i.hasOwnProperty(o)){var u=i[o];u?this[o]=u(n):\"target\"===o?this.target=r:this[o]=n[o]}var c=null!=n.defaultPrevented?n.defaultPrevented:n.returnValue===!1;return c?this.isDefaultPrevented=a.thatReturnsTrue:this.isDefaultPrevented=a.thatReturnsFalse,this.isPropagationStopped=a.thatReturnsFalse,this}var i=n(3),o=n(17),a=n(8),u=(n(1),\"function\"==typeof Proxy,[\"dispatchConfig\",\"_targetInst\",\"nativeEvent\",\"isDefaultPrevented\",\"isPropagationStopped\",\"_dispatchListeners\",\"_dispatchInstances\"]),c={type:null,target:null,currentTarget:a.thatReturnsNull,eventPhase:null,bubbles:null,cancelable:null,timeStamp:function(t){return t.timeStamp||Date.now()},defaultPrevented:null,isTrusted:null};i(r.prototype,{preventDefault:function(){this.defaultPrevented=!0;var t=this.nativeEvent;t&&(t.preventDefault?t.preventDefault():\"unknown\"!=typeof t.returnValue&&(t.returnValue=!1),this.isDefaultPrevented=a.thatReturnsTrue)},stopPropagation:function(){var t=this.nativeEvent;t&&(t.stopPropagation?t.stopPropagation():\"unknown\"!=typeof t.cancelBubble&&(t.cancelBubble=!0),this.isPropagationStopped=a.thatReturnsTrue)},persist:function(){this.isPersistent=a.thatReturnsTrue},isPersistent:a.thatReturnsFalse,destructor:function(){var t=this.constructor.Interface;for(var e in t)this[e]=null;for(var n=0;n<u.length;n++)this[u[n]]=null}}),r.Interface=c,r.augmentClass=function(t,e){var n=this,r=function(){};r.prototype=n.prototype;var a=new r;i(a,t.prototype),t.prototype=a,t.prototype.constructor=t,t.Interface=i({},n.Interface,e),t.augmentClass=n.augmentClass,o.addPoolingTo(t,o.fourArgumentPooler)},o.addPoolingTo(r,o.fourArgumentPooler),t.exports=r},function(t,e,n){\"use strict\";var r={current:null};t.exports=r},function(t,e,n){\"use strict\";n.d(e,\"a\",function(){return i}),n.d(e,\"b\",function(){return o});var r=Array.prototype,i=r.map,o=r.slice},function(t,e,n){\"use strict\";var r=n(2),i=(n(0),function(t){var e=this;if(e.instancePool.length){var n=e.instancePool.pop();return e.call(n,t),n}return new e(t)}),o=function(t,e){var n=this;if(n.instancePool.length){var r=n.instancePool.pop();return n.call(r,t,e),r}return new n(t,e)},a=function(t,e,n){var r=this;if(r.instancePool.length){var i=r.instancePool.pop();return r.call(i,t,e,n),i}return new r(t,e,n)},u=function(t,e,n,r){var i=this;if(i.instancePool.length){var o=i.instancePool.pop();return i.call(o,t,e,n,r),o}return new i(t,e,n,r)},c=function(t){var e=this;t instanceof e?void 0:r(\"25\"),t.destructor(),e.instancePool.length<e.poolSize&&e.instancePool.push(t)},s=10,l=i,f=function(t,e){var n=t;return n.instancePool=[],n.getPooled=e||l,n.poolSize||(n.poolSize=s),n.release=c,n},p={addPoolingTo:f,oneArgumentPooler:i,twoArgumentPooler:o,threeArgumentPooler:a,fourArgumentPooler:u};t.exports=p},function(t,e,n){\"use strict\";e.a=function(t,e){return t<e?-1:t>e?1:t>=e?0:NaN}},function(t,e,n){\"use strict\";e.a=function(t){return function(){return t}}},function(t,e,n){\"use strict\";function r(t){if(g){var e=t.node,n=t.children;if(n.length)for(var r=0;r<n.length;r++)m(e,n[r],null);else null!=t.html?f(e,t.html):null!=t.text&&h(e,t.text)}}function i(t,e){t.parentNode.replaceChild(e.node,t),r(e)}function o(t,e){g?t.children.push(e):t.node.appendChild(e.node)}function a(t,e){g?t.html=e:f(t.node,e)}function u(t,e){g?t.text=e:h(t.node,e)}function c(){return this.node.nodeName}function s(t){return{node:t,children:[],html:null,text:null,toString:c}}var l=n(82),f=n(55),p=n(90),h=n(171),d=1,v=11,g=\"undefined\"!=typeof document&&\"number\"==typeof document.documentMode||\"undefined\"!=typeof navigator&&\"string\"==typeof navigator.userAgent&&/\\bEdge\\/\\d/.test(navigator.userAgent),m=p(function(t,e,n){e.node.nodeType===v||e.node.nodeType===d&&\"object\"===e.node.nodeName.toLowerCase()&&(null==e.node.namespaceURI||e.node.namespaceURI===l.html)?(r(e),t.insertBefore(e.node,n)):(t.insertBefore(e.node,n),r(e))});s.insertTreeBefore=m,s.replaceChildWithTree=i,s.queueChild=o,s.queueHTML=a,s.queueText=u,t.exports=s},function(t,e,n){\"use strict\";function r(t,e){return(t&e)===e}var i=n(2),o=(n(0),{MUST_USE_PROPERTY:1,HAS_BOOLEAN_VALUE:4,HAS_NUMERIC_VALUE:8,HAS_POSITIVE_NUMERIC_VALUE:24,HAS_OVERLOADED_BOOLEAN_VALUE:32,injectDOMPropertyConfig:function(t){var e=o,n=t.Properties||{},a=t.DOMAttributeNamespaces||{},c=t.DOMAttributeNames||{},s=t.DOMPropertyNames||{},l=t.DOMMutationMethods||{};t.isCustomAttribute&&u._isCustomAttributeFunctions.push(t.isCustomAttribute);for(var f in n){u.properties.hasOwnProperty(f)?i(\"48\",f):void 0;var p=f.toLowerCase(),h=n[f],d={attributeName:p,attributeNamespace:null,propertyName:f,mutationMethod:null,mustUseProperty:r(h,e.MUST_USE_PROPERTY),hasBooleanValue:r(h,e.HAS_BOOLEAN_VALUE),hasNumericValue:r(h,e.HAS_NUMERIC_VALUE),hasPositiveNumericValue:r(h,e.HAS_POSITIVE_NUMERIC_VALUE),hasOverloadedBooleanValue:r(h,e.HAS_OVERLOADED_BOOLEAN_VALUE)};if(d.hasBooleanValue+d.hasNumericValue+d.hasOverloadedBooleanValue<=1?void 0:i(\"50\",f),c.hasOwnProperty(f)){var v=c[f];d.attributeName=v}a.hasOwnProperty(f)&&(d.attributeNamespace=a[f]),s.hasOwnProperty(f)&&(d.propertyName=s[f]),l.hasOwnProperty(f)&&(d.mutationMethod=l[f]),u.properties[f]=d}}}),a=\":A-Z_a-z\\\\u00C0-\\\\u00D6\\\\u00D8-\\\\u00F6\\\\u00F8-\\\\u02FF\\\\u0370-\\\\u037D\\\\u037F-\\\\u1FFF\\\\u200C-\\\\u200D\\\\u2070-\\\\u218F\\\\u2C00-\\\\u2FEF\\\\u3001-\\\\uD7FF\\\\uF900-\\\\uFDCF\\\\uFDF0-\\\\uFFFD\",u={ID_ATTRIBUTE_NAME:\"data-reactid\",ROOT_ATTRIBUTE_NAME:\"data-reactroot\",ATTRIBUTE_NAME_START_CHAR:a,ATTRIBUTE_NAME_CHAR:a+\"\\\\-.0-9\\\\u00B7\\\\u0300-\\\\u036F\\\\u203F-\\\\u2040\",properties:{},getPossibleStandardName:null,_isCustomAttributeFunctions:[],isCustomAttribute:function(t){for(var e=0;e<u._isCustomAttributeFunctions.length;e++){var n=u._isCustomAttributeFunctions[e];if(n(t))return!0}return!1},injection:o};t.exports=u},function(t,e,n){\"use strict\";function r(t){return\"button\"===t||\"input\"===t||\"select\"===t||\"textarea\"===t}function i(t,e,n){switch(t){case\"onClick\":case\"onClickCapture\":case\"onDoubleClick\":case\"onDoubleClickCapture\":case\"onMouseDown\":case\"onMouseDownCapture\":case\"onMouseMove\":case\"onMouseMoveCapture\":case\"onMouseUp\":case\"onMouseUpCapture\":return!(!n.disabled||!r(e));default:return!1}}var o=n(2),a=n(83),u=n(50),c=n(87),s=n(165),l=n(166),f=(n(0),{}),p=null,h=function(t,e){t&&(u.executeDispatchesInOrder(t,e),t.isPersistent()||t.constructor.release(t))},d=function(t){return h(t,!0)},v=function(t){return h(t,!1)},g=function(t){return\".\"+t._rootNodeID},m={injection:{injectEventPluginOrder:a.injectEventPluginOrder,injectEventPluginsByName:a.injectEventPluginsByName},putListener:function(t,e,n){\"function\"!=typeof n?o(\"94\",e,typeof n):void 0;var r=g(t),i=f[e]||(f[e]={});i[r]=n;var u=a.registrationNameModules[e];u&&u.didPutListener&&u.didPutListener(t,e,n)},getListener:function(t,e){var n=f[e];if(i(e,t._currentElement.type,t._currentElement.props))return null;var r=g(t);return n&&n[r]},deleteListener:function(t,e){var n=a.registrationNameModules[e];n&&n.willDeleteListener&&n.willDeleteListener(t,e);var r=f[e];if(r){var i=g(t);delete r[i]}},deleteAllListeners:function(t){var e=g(t);for(var n in f)if(f.hasOwnProperty(n)&&f[n][e]){var r=a.registrationNameModules[n];r&&r.willDeleteListener&&r.willDeleteListener(t,n),delete f[n][e]}},extractEvents:function(t,e,n,r){for(var i,o=a.plugins,u=0;u<o.length;u++){var c=o[u];if(c){var l=c.extractEvents(t,e,n,r);l&&(i=s(i,l))}}return i},enqueueEvents:function(t){t&&(p=s(p,t))},processEventQueue:function(t){var e=p;p=null,t?l(e,d):l(e,v),p?o(\"95\"):void 0,c.rethrowCaughtError()},__purge:function(){f={}},__getListenerBank:function(){return f}};t.exports=m},function(t,e,n){\"use strict\";function r(t,e,n){var r=e.dispatchConfig.phasedRegistrationNames[n];return m(t,r)}function i(t,e,n){var i=r(t,n,e);i&&(n._dispatchListeners=v(n._dispatchListeners,i),n._dispatchInstances=v(n._dispatchInstances,t))}function o(t){t&&t.dispatchConfig.phasedRegistrationNames&&d.traverseTwoPhase(t._targetInst,i,t)}function a(t){if(t&&t.dispatchConfig.phasedRegistrationNames){var e=t._targetInst,n=e?d.getParentInstance(e):null;d.traverseTwoPhase(n,i,t)}}function u(t,e,n){if(n&&n.dispatchConfig.registrationName){var r=n.dispatchConfig.registrationName,i=m(t,r);i&&(n._dispatchListeners=v(n._dispatchListeners,i),n._dispatchInstances=v(n._dispatchInstances,t))}}function c(t){t&&t.dispatchConfig.registrationName&&u(t._targetInst,null,t)}function s(t){g(t,o)}function l(t){g(t,a)}function f(t,e,n,r){d.traverseEnterLeave(n,r,u,t,e)}function p(t){g(t,c)}var h=n(22),d=n(50),v=n(165),g=n(166),m=(n(1),h.getListener),y={accumulateTwoPhaseDispatches:s,accumulateTwoPhaseDispatchesSkipTarget:l,accumulateDirectDispatches:p,accumulateEnterLeaveDispatches:f};t.exports=y},function(t,e,n){\"use strict\";function r(){i.attachRefs(this,this._currentElement)}var i=n(368),o=(n(9),n(1),{mountComponent:function(t,e,n,i,o,a){var u=t.mountComponent(e,n,i,o,a);return t._currentElement&&null!=t._currentElement.ref&&e.getReactMountReady().enqueue(r,t),u},getHostNode:function(t){return t.getHostNode()},unmountComponent:function(t,e){i.detachRefs(t,t._currentElement),t.unmountComponent(e)},receiveComponent:function(t,e,n,o){var a=t._currentElement;if(e!==a||o!==t._context){var u=i.shouldUpdateRefs(a,e);u&&i.detachRefs(t,a),t.receiveComponent(e,n,o),u&&t._currentElement&&null!=t._currentElement.ref&&n.getReactMountReady().enqueue(r,t)}},performUpdateIfNecessary:function(t,e,n){t._updateBatchNumber===n&&t.performUpdateIfNecessary(e)}});t.exports=o},function(t,e,n){\"use strict\";function r(t,e,n,r){return i.call(this,t,e,n,r)}var i=n(14),o=n(93),a={view:function(t){if(t.view)return t.view;var e=o(t);if(e.window===e)return e;var n=e.ownerDocument;return n?n.defaultView||n.parentWindow:window},detail:function(t){return t.detail||0}};i.augmentClass(r,a),t.exports=r},function(t,e,n){\"use strict\";var r=n(3),i=n(401),o=n(97),a=n(406),u=n(402),c=n(403),s=n(27),l=n(404),f=n(407),p=n(408),h=(n(1),s.createElement),d=s.createFactory,v=s.cloneElement,g=r,m={Children:{map:i.map,forEach:i.forEach,count:i.count,toArray:i.toArray,only:p},Component:o,PureComponent:a,createElement:h,cloneElement:v,isValidElement:s.isValidElement,PropTypes:l,createClass:u.createClass,createFactory:d,createMixin:function(t){return t},DOM:c,version:f,__spread:g};t.exports=m},function(t,e,n){\"use strict\";function r(t){return void 0!==t.ref}function i(t){return void 0!==t.key}var o=n(3),a=n(15),u=(n(1),n(176),Object.prototype.hasOwnProperty),c=n(174),s={key:!0,ref:!0,__self:!0,__source:!0},l=function(t,e,n,r,i,o,a){var u={$$typeof:c,type:t,key:e,ref:n,props:a,_owner:o};return u};l.createElement=function(t,e,n){var o,c={},f=null,p=null,h=null,d=null;if(null!=e){r(e)&&(p=e.ref),i(e)&&(f=\"\"+e.key),h=void 0===e.__self?null:e.__self,d=void 0===e.__source?null:e.__source;for(o in e)u.call(e,o)&&!s.hasOwnProperty(o)&&(c[o]=e[o])}var v=arguments.length-2;if(1===v)c.children=n;else if(v>1){for(var g=Array(v),m=0;m<v;m++)g[m]=arguments[m+2];c.children=g}if(t&&t.defaultProps){var y=t.defaultProps;for(o in y)void 0===c[o]&&(c[o]=y[o])}return l(t,f,p,h,d,a.current,c)},l.createFactory=function(t){var e=l.createElement.bind(null,t);return e.type=t,e},l.cloneAndReplaceKey=function(t,e){var n=l(t.type,e,t.ref,t._self,t._source,t._owner,t.props);return n},l.cloneElement=function(t,e,n){var c,f=o({},t.props),p=t.key,h=t.ref,d=t._self,v=t._source,g=t._owner;if(null!=e){r(e)&&(h=e.ref,g=a.current),i(e)&&(p=\"\"+e.key);var m;t.type&&t.type.defaultProps&&(m=t.type.defaultProps);for(c in e)u.call(e,c)&&!s.hasOwnProperty(c)&&(void 0===e[c]&&void 0!==m?f[c]=m[c]:f[c]=e[c])}var y=arguments.length-2;if(1===y)f.children=n;else if(y>1){for(var _=Array(y),b=0;b<y;b++)_[b]=arguments[b+2];f.children=_}return l(t.type,p,h,d,v,g,f)},l.isValidElement=function(t){return\"object\"==typeof t&&null!==t&&t.$$typeof===c},t.exports=l},function(t,e,n){\"use strict\";function r(t){for(var e=arguments.length-1,n=\"Minified React error #\"+t+\"; visit http://facebook.github.io/react/docs/error-decoder.html?invariant=\"+t,r=0;r<e;r++)n+=\"&args[]=\"+encodeURIComponent(arguments[r+1]);n+=\" for the full message or use the non-minified dev environment for full errors and additional helpful warnings.\";var i=new Error(n);throw i.name=\"Invariant Violation\",i.framesToPop=1,i}t.exports=r},function(t,e,n){\"use strict\";e.a=function(t){return null===t?NaN:+t}},function(t,e,n){\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0});var r=n(211);n.d(e,\"formatDefaultLocale\",function(){return r.a}),n.d(e,\"format\",function(){return r.b}),n.d(e,\"formatPrefix\",function(){return r.c});var i=n(117);n.d(e,\"formatLocale\",function(){return i.a});var o=n(115);n.d(e,\"formatSpecifier\",function(){return o.a});var a=n(215);n.d(e,\"precisionFixed\",function(){return a.a});var u=n(216);n.d(e,\"precisionPrefix\",function(){return u.a});var c=n(217);n.d(e,\"precisionRound\",function(){return c.a})},function(t,e,n){\"use strict\";var r=n(63);n.d(e,\"b\",function(){return r.a});var i=(n(118),n(62),n(119),n(121),n(43));n.d(e,\"a\",function(){return i.a});var o=(n(122),n(223));n.d(e,\"c\",function(){return o.a});var a=(n(124),n(225),n(227),n(123),n(220),n(221),n(219),n(218));n.d(e,\"d\",function(){return a.a});n(222)},function(t,e,n){\"use strict\";function r(t,e){return function(n){return t+n*e}}function i(t,e,n){return t=Math.pow(t,n),e=Math.pow(e,n)-t,n=1/n,function(r){return Math.pow(t+r*e,n)}}function o(t,e){var i=e-t;return i?r(t,i>180||i<-180?i-360*Math.round(i/360):i):n.i(c.a)(isNaN(t)?e:t)}function a(t){return 1===(t=+t)?u:function(e,r){return r-e?i(e,r,t):n.i(c.a)(isNaN(e)?r:e)}}function u(t,e){var i=e-t;return i?r(t,i):n.i(c.a)(isNaN(t)?e:t)}var c=n(120);e.b=o,e.c=a,e.a=u},function(t,e,n){\"use strict\";e.a=function(t){return t.match(/.{6}/g).map(function(t){return\"#\"+t})}},function(t,e,n){\"use strict\";function r(t){var e=t.domain;return t.ticks=function(t){var r=e();return n.i(o.a)(r[0],r[r.length-1],null==t?10:t)},t.tickFormat=function(t,r){return n.i(c.a)(e(),t,r)},t.nice=function(r){var i=e(),a=i.length-1,u=null==r?10:r,c=i[0],s=i[a],l=n.i(o.b)(c,s,u);return l&&(l=n.i(o.b)(Math.floor(c/l)*l,Math.ceil(s/l)*l,u),i[0]=Math.floor(c/l)*l,i[a]=Math.ceil(s/l)*l,e(i)),t},t}function i(){var t=n.i(u.a)(u.b,a.a);return t.copy=function(){return n.i(u.c)(t,i())},r(t)}var o=n(12),a=n(31),u=n(45),c=n(243);e.b=r,e.a=i},function(t,e,n){\"use strict\";n.d(e,\"a\",function(){return r}),n.d(e,\"b\",function(){return i}),n.d(e,\"d\",function(){return o}),n.d(e,\"c\",function(){return a});var r=1e-12,i=Math.PI,o=i/2,a=2*i},function(t,e,n){\"use strict\";e.a=function(t,e){if((r=t.length)>1)for(var n,r,i=1,o=t[e[0]],a=o.length;i<r;++i){n=o,o=t[e[i]];for(var u=0;u<a;++u)o[u][1]+=o[u][0]=isNaN(n[u][1])?n[u][0]:n[u][1]}}},function(t,e,n){\"use strict\";e.a=function(t){for(var e=t.length,n=new Array(e);--e>=0;)n[e]=e;return n}},function(t,e,n){\"use strict\";var r={};t.exports=r},function(t,e,n){(function(t,r){var i;(function(){function o(t,e){return t.set(e[0],e[1]),t}function a(t,e){return t.add(e),t}function u(t,e,n){switch(n.length){case 0:return t.call(e);case 1:return t.call(e,n[0]);case 2:return t.call(e,n[0],n[1]);case 3:return t.call(e,n[0],n[1],n[2])}return t.apply(e,n)}function c(t,e,n,r){for(var i=-1,o=null==t?0:t.length;++i<o;){var a=t[i];e(r,a,n(a),t)}return r}function s(t,e){for(var n=-1,r=null==t?0:t.length;++n<r&&e(t[n],n,t)!==!1;);return t}function l(t,e){for(var n=null==t?0:t.length;n--&&e(t[n],n,t)!==!1;);return t}function f(t,e){for(var n=-1,r=null==t?0:t.length;++n<r;)if(!e(t[n],n,t))return!1;return!0}function p(t,e){for(var n=-1,r=null==t?0:t.length,i=0,o=[];++n<r;){var a=t[n];e(a,n,t)&&(o[i++]=a)}return o}function h(t,e){var n=null==t?0:t.length;return!!n&&M(t,e,0)>-1}function d(t,e,n){for(var r=-1,i=null==t?0:t.length;++r<i;)if(n(e,t[r]))return!0;return!1}function v(t,e){for(var n=-1,r=null==t?0:t.length,i=Array(r);++n<r;)i[n]=e(t[n],n,t);return i}function g(t,e){for(var n=-1,r=e.length,i=t.length;++n<r;)t[i+n]=e[n];return t}function m(t,e,n,r){var i=-1,o=null==t?0:t.length;for(r&&o&&(n=t[++i]);++i<o;)n=e(n,t[i],i,t);return n}function y(t,e,n,r){var i=null==t?0:t.length;for(r&&i&&(n=t[--i]);i--;)n=e(n,t[i],i,t);return n}function _(t,e){for(var n=-1,r=null==t?0:t.length;++n<r;)if(e(t[n],n,t))return!0;return!1}function b(t){return t.split(\"\")}function x(t){return t.match(ze)||[]}function w(t,e,n){var r;return n(t,function(t,n,i){if(e(t,n,i))return r=n,!1}),r}function C(t,e,n,r){for(var i=t.length,o=n+(r?1:-1);r?o--:++o<i;)if(e(t[o],o,t))return o;return-1}function M(t,e,n){return e===e?Z(t,e,n):C(t,E,n)}function k(t,e,n,r){for(var i=n-1,o=t.length;++i<o;)if(r(t[i],e))return i;return-1}function E(t){return t!==t}function T(t,e){var n=null==t?0:t.length;return n?O(t,e)/n:Ut}function S(t){return function(e){return null==e?it:e[t]}}function P(t){return function(e){return null==t?it:t[e]}}function N(t,e,n,r,i){return i(t,function(t,i,o){n=r?(r=!1,t):e(n,t,i,o)}),n}function A(t,e){var n=t.length;for(t.sort(e);n--;)t[n]=t[n].value;return t}function O(t,e){for(var n,r=-1,i=t.length;++r<i;){var o=e(t[r]);o!==it&&(n=n===it?o:n+o)}return n}function I(t,e){for(var n=-1,r=Array(t);++n<t;)r[n]=e(n);return r}function D(t,e){return v(e,function(e){return[e,t[e]]})}function R(t){return function(e){return t(e)}}function L(t,e){return v(e,function(e){return t[e]})}function U(t,e){return t.has(e)}function F(t,e){for(var n=-1,r=t.length;++n<r&&M(e,t[n],0)>-1;);return n}function j(t,e){for(var n=t.length;n--&&M(e,t[n],0)>-1;);return n}function B(t,e){for(var n=t.length,r=0;n--;)t[n]===e&&++r;return r}function W(t){return\"\\\\\"+nr[t]}function V(t,e){return null==t?it:t[e]}function z(t){return Kn.test(t)}function H(t){return Gn.test(t)}function q(t){for(var e,n=[];!(e=t.next()).done;)n.push(e.value);return n}function Y(t){var e=-1,n=Array(t.size);return t.forEach(function(t,r){n[++e]=[r,t]}),n}function K(t,e){return function(n){return t(e(n))}}function G(t,e){for(var n=-1,r=t.length,i=0,o=[];++n<r;){var a=t[n];a!==e&&a!==ft||(t[n]=ft,o[i++]=n)}return o}function $(t){var e=-1,n=Array(t.size);return t.forEach(function(t){n[++e]=t}),n}function X(t){var e=-1,n=Array(t.size);return t.forEach(function(t){n[++e]=[t,t]}),n}function Z(t,e,n){for(var r=n-1,i=t.length;++r<i;)if(t[r]===e)return r;return-1}function Q(t,e,n){for(var r=n+1;r--;)if(t[r]===e)return r;return r}function J(t){return z(t)?et(t):_r(t)}function tt(t){return z(t)?nt(t):b(t)}function et(t){for(var e=qn.lastIndex=0;qn.test(t);)++e;return e}function nt(t){return t.match(qn)||[]}function rt(t){return t.match(Yn)||[]}var it,ot=\"4.17.4\",at=200,ut=\"Unsupported core-js use. Try https://npms.io/search?q=ponyfill.\",ct=\"Expected a function\",st=\"__lodash_hash_undefined__\",lt=500,ft=\"__lodash_placeholder__\",pt=1,ht=2,dt=4,vt=1,gt=2,mt=1,yt=2,_t=4,bt=8,xt=16,wt=32,Ct=64,Mt=128,kt=256,Et=512,Tt=30,St=\"...\",Pt=800,Nt=16,At=1,Ot=2,It=3,Dt=1/0,Rt=9007199254740991,Lt=1.7976931348623157e308,Ut=NaN,Ft=4294967295,jt=Ft-1,Bt=Ft>>>1,Wt=[[\"ary\",Mt],[\"bind\",mt],[\"bindKey\",yt],[\"curry\",bt],[\"curryRight\",xt],[\"flip\",Et],[\"partial\",wt],[\"partialRight\",Ct],[\"rearg\",kt]],Vt=\"[object Arguments]\",zt=\"[object Array]\",Ht=\"[object AsyncFunction]\",qt=\"[object Boolean]\",Yt=\"[object Date]\",Kt=\"[object DOMException]\",Gt=\"[object Error]\",$t=\"[object Function]\",Xt=\"[object GeneratorFunction]\",Zt=\"[object Map]\",Qt=\"[object Number]\",Jt=\"[object Null]\",te=\"[object Object]\",ee=\"[object Promise]\",ne=\"[object Proxy]\",re=\"[object RegExp]\",ie=\"[object Set]\",oe=\"[object String]\",ae=\"[object Symbol]\",ue=\"[object Undefined]\",ce=\"[object WeakMap]\",se=\"[object WeakSet]\",le=\"[object ArrayBuffer]\",fe=\"[object DataView]\",pe=\"[object Float32Array]\",he=\"[object Float64Array]\",de=\"[object Int8Array]\",ve=\"[object Int16Array]\",ge=\"[object Int32Array]\",me=\"[object Uint8Array]\",ye=\"[object Uint8ClampedArray]\",_e=\"[object Uint16Array]\",be=\"[object Uint32Array]\",xe=/\\b__p \\+= '';/g,we=/\\b(__p \\+=) '' \\+/g,Ce=/(__e\\(.*?\\)|\\b__t\\)) \\+\\n'';/g,Me=/&(?:amp|lt|gt|quot|#39);/g,ke=/[&<>\"']/g,Ee=RegExp(Me.source),Te=RegExp(ke.source),Se=/<%-([\\s\\S]+?)%>/g,Pe=/<%([\\s\\S]+?)%>/g,Ne=/<%=([\\s\\S]+?)%>/g,Ae=/\\.|\\[(?:[^[\\]]*|([\"'])(?:(?!\\1)[^\\\\]|\\\\.)*?\\1)\\]/,Oe=/^\\w*$/,Ie=/^\\./,De=/[^.[\\]]+|\\[(?:(-?\\d+(?:\\.\\d+)?)|([\"'])((?:(?!\\2)[^\\\\]|\\\\.)*?)\\2)\\]|(?=(?:\\.|\\[\\])(?:\\.|\\[\\]|$))/g,Re=/[\\\\^$.*+?()[\\]{}|]/g,Le=RegExp(Re.source),Ue=/^\\s+|\\s+$/g,Fe=/^\\s+/,je=/\\s+$/,Be=/\\{(?:\\n\\/\\* \\[wrapped with .+\\] \\*\\/)?\\n?/,We=/\\{\\n\\/\\* \\[wrapped with (.+)\\] \\*/,Ve=/,? & /,ze=/[^\\x00-\\x2f\\x3a-\\x40\\x5b-\\x60\\x7b-\\x7f]+/g,He=/\\\\(\\\\)?/g,qe=/\\$\\{([^\\\\}]*(?:\\\\.[^\\\\}]*)*)\\}/g,Ye=/\\w*$/,Ke=/^[-+]0x[0-9a-f]+$/i,Ge=/^0b[01]+$/i,$e=/^\\[object .+?Constructor\\]$/,Xe=/^0o[0-7]+$/i,Ze=/^(?:0|[1-9]\\d*)$/,Qe=/[\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\xff\\u0100-\\u017f]/g,Je=/($^)/,tn=/['\\n\\r\\u2028\\u2029\\\\]/g,en=\"\\\\ud800-\\\\udfff\",nn=\"\\\\u0300-\\\\u036f\",rn=\"\\\\ufe20-\\\\ufe2f\",on=\"\\\\u20d0-\\\\u20ff\",an=nn+rn+on,un=\"\\\\u2700-\\\\u27bf\",cn=\"a-z\\\\xdf-\\\\xf6\\\\xf8-\\\\xff\",sn=\"\\\\xac\\\\xb1\\\\xd7\\\\xf7\",ln=\"\\\\x00-\\\\x2f\\\\x3a-\\\\x40\\\\x5b-\\\\x60\\\\x7b-\\\\xbf\",fn=\"\\\\u2000-\\\\u206f\",pn=\" \\\\t\\\\x0b\\\\f\\\\xa0\\\\ufeff\\\\n\\\\r\\\\u2028\\\\u2029\\\\u1680\\\\u180e\\\\u2000\\\\u2001\\\\u2002\\\\u2003\\\\u2004\\\\u2005\\\\u2006\\\\u2007\\\\u2008\\\\u2009\\\\u200a\\\\u202f\\\\u205f\\\\u3000\",hn=\"A-Z\\\\xc0-\\\\xd6\\\\xd8-\\\\xde\",dn=\"\\\\ufe0e\\\\ufe0f\",vn=sn+ln+fn+pn,gn=\"['’]\",mn=\"[\"+en+\"]\",yn=\"[\"+vn+\"]\",_n=\"[\"+an+\"]\",bn=\"\\\\d+\",xn=\"[\"+un+\"]\",wn=\"[\"+cn+\"]\",Cn=\"[^\"+en+vn+bn+un+cn+hn+\"]\",Mn=\"\\\\ud83c[\\\\udffb-\\\\udfff]\",kn=\"(?:\"+_n+\"|\"+Mn+\")\",En=\"[^\"+en+\"]\",Tn=\"(?:\\\\ud83c[\\\\udde6-\\\\uddff]){2}\",Sn=\"[\\\\ud800-\\\\udbff][\\\\udc00-\\\\udfff]\",Pn=\"[\"+hn+\"]\",Nn=\"\\\\u200d\",An=\"(?:\"+wn+\"|\"+Cn+\")\",On=\"(?:\"+Pn+\"|\"+Cn+\")\",In=\"(?:\"+gn+\"(?:d|ll|m|re|s|t|ve))?\",Dn=\"(?:\"+gn+\"(?:D|LL|M|RE|S|T|VE))?\",Rn=kn+\"?\",Ln=\"[\"+dn+\"]?\",Un=\"(?:\"+Nn+\"(?:\"+[En,Tn,Sn].join(\"|\")+\")\"+Ln+Rn+\")*\",Fn=\"\\\\d*(?:(?:1st|2nd|3rd|(?![123])\\\\dth)\\\\b)\",jn=\"\\\\d*(?:(?:1ST|2ND|3RD|(?![123])\\\\dTH)\\\\b)\",Bn=Ln+Rn+Un,Wn=\"(?:\"+[xn,Tn,Sn].join(\"|\")+\")\"+Bn,Vn=\"(?:\"+[En+_n+\"?\",_n,Tn,Sn,mn].join(\"|\")+\")\",zn=RegExp(gn,\"g\"),Hn=RegExp(_n,\"g\"),qn=RegExp(Mn+\"(?=\"+Mn+\")|\"+Vn+Bn,\"g\"),Yn=RegExp([Pn+\"?\"+wn+\"+\"+In+\"(?=\"+[yn,Pn,\"$\"].join(\"|\")+\")\",On+\"+\"+Dn+\"(?=\"+[yn,Pn+An,\"$\"].join(\"|\")+\")\",Pn+\"?\"+An+\"+\"+In,Pn+\"+\"+Dn,jn,Fn,bn,Wn].join(\"|\"),\"g\"),Kn=RegExp(\"[\"+Nn+en+an+dn+\"]\"),Gn=/[a-z][A-Z]|[A-Z]{2,}[a-z]|[0-9][a-zA-Z]|[a-zA-Z][0-9]|[^a-zA-Z0-9 ]/,$n=[\"Array\",\"Buffer\",\"DataView\",\"Date\",\"Error\",\"Float32Array\",\"Float64Array\",\"Function\",\"Int8Array\",\"Int16Array\",\"Int32Array\",\"Map\",\"Math\",\"Object\",\"Promise\",\"RegExp\",\"Set\",\"String\",\"Symbol\",\"TypeError\",\"Uint8Array\",\"Uint8ClampedArray\",\"Uint16Array\",\"Uint32Array\",\"WeakMap\",\"_\",\"clearTimeout\",\"isFinite\",\"parseInt\",\"setTimeout\"],Xn=-1,Zn={};Zn[pe]=Zn[he]=Zn[de]=Zn[ve]=Zn[ge]=Zn[me]=Zn[ye]=Zn[_e]=Zn[be]=!0,Zn[Vt]=Zn[zt]=Zn[le]=Zn[qt]=Zn[fe]=Zn[Yt]=Zn[Gt]=Zn[$t]=Zn[Zt]=Zn[Qt]=Zn[te]=Zn[re]=Zn[ie]=Zn[oe]=Zn[ce]=!1;var Qn={};Qn[Vt]=Qn[zt]=Qn[le]=Qn[fe]=Qn[qt]=Qn[Yt]=Qn[pe]=Qn[he]=Qn[de]=Qn[ve]=Qn[ge]=Qn[Zt]=Qn[Qt]=Qn[te]=Qn[re]=Qn[ie]=Qn[oe]=Qn[ae]=Qn[me]=Qn[ye]=Qn[_e]=Qn[be]=!0,Qn[Gt]=Qn[$t]=Qn[ce]=!1;var Jn={\"À\":\"A\",\"Á\":\"A\",\"Â\":\"A\",\"Ã\":\"A\",\"Ä\":\"A\",\"Å\":\"A\",\"à\":\"a\",\"á\":\"a\",\"â\":\"a\",\"ã\":\"a\",\"ä\":\"a\",\"å\":\"a\",\"Ç\":\"C\",\"ç\":\"c\",\"Ð\":\"D\",\"ð\":\"d\",\"È\":\"E\",\"É\":\"E\",\"Ê\":\"E\",\"Ë\":\"E\",\"è\":\"e\",\"é\":\"e\",\"ê\":\"e\",\"ë\":\"e\",\"Ì\":\"I\",\"Í\":\"I\",\"Î\":\"I\",\"Ï\":\"I\",\"ì\":\"i\",\"í\":\"i\",\"î\":\"i\",\"ï\":\"i\",\"Ñ\":\"N\",\"ñ\":\"n\",\"Ò\":\"O\",\"Ó\":\"O\",\"Ô\":\"O\",\"Õ\":\"O\",\"Ö\":\"O\",\"Ø\":\"O\",\"ò\":\"o\",\"ó\":\"o\",\"ô\":\"o\",\"õ\":\"o\",\"ö\":\"o\",\"ø\":\"o\",\"Ù\":\"U\",\"Ú\":\"U\",\"Û\":\"U\",\"Ü\":\"U\",\"ù\":\"u\",\"ú\":\"u\",\"û\":\"u\",\"ü\":\"u\",\"Ý\":\"Y\",\"ý\":\"y\",\"ÿ\":\"y\",\"Æ\":\"Ae\",\"æ\":\"ae\",\"Þ\":\"Th\",\"þ\":\"th\",\"ß\":\"ss\",\"Ā\":\"A\",\"Ă\":\"A\",\"Ą\":\"A\",\"ā\":\"a\",\"ă\":\"a\",\"ą\":\"a\",\"Ć\":\"C\",\"Ĉ\":\"C\",\"Ċ\":\"C\",\"Č\":\"C\",\"ć\":\"c\",\"ĉ\":\"c\",\"ċ\":\"c\",\"č\":\"c\",\"Ď\":\"D\",\"Đ\":\"D\",\"ď\":\"d\",\"đ\":\"d\",\"Ē\":\"E\",\"Ĕ\":\"E\",\"Ė\":\"E\",\"Ę\":\"E\",\"Ě\":\"E\",\"ē\":\"e\",\"ĕ\":\"e\",\"ė\":\"e\",\"ę\":\"e\",\"ě\":\"e\",\"Ĝ\":\"G\",\"Ğ\":\"G\",\"Ġ\":\"G\",\"Ģ\":\"G\",\"ĝ\":\"g\",\"ğ\":\"g\",\"ġ\":\"g\",\"ģ\":\"g\",\"Ĥ\":\"H\",\"Ħ\":\"H\",\"ĥ\":\"h\",\"ħ\":\"h\",\"Ĩ\":\"I\",\"Ī\":\"I\",\"Ĭ\":\"I\",\"Į\":\"I\",\"İ\":\"I\",\"ĩ\":\"i\",\"ī\":\"i\",\"ĭ\":\"i\",\"į\":\"i\",\"ı\":\"i\",\"Ĵ\":\"J\",\"ĵ\":\"j\",\"Ķ\":\"K\",\"ķ\":\"k\",\"ĸ\":\"k\",\"Ĺ\":\"L\",\"Ļ\":\"L\",\"Ľ\":\"L\",\"Ŀ\":\"L\",\"Ł\":\"L\",\"ĺ\":\"l\",\"ļ\":\"l\",\"ľ\":\"l\",\"ŀ\":\"l\",\"ł\":\"l\",\"Ń\":\"N\",\"Ņ\":\"N\",\"Ň\":\"N\",\"Ŋ\":\"N\",\"ń\":\"n\",\"ņ\":\"n\",\"ň\":\"n\",\"ŋ\":\"n\",\"Ō\":\"O\",\"Ŏ\":\"O\",\"Ő\":\"O\",\"ō\":\"o\",\"ŏ\":\"o\",\"ő\":\"o\",\"Ŕ\":\"R\",\"Ŗ\":\"R\",\"Ř\":\"R\",\"ŕ\":\"r\",\"ŗ\":\"r\",\"ř\":\"r\",\"Ś\":\"S\",\"Ŝ\":\"S\",\"Ş\":\"S\",\"Š\":\"S\",\"ś\":\"s\",\"ŝ\":\"s\",\"ş\":\"s\",\"š\":\"s\",\"Ţ\":\"T\",\"Ť\":\"T\",\"Ŧ\":\"T\",\"ţ\":\"t\",\"ť\":\"t\",\"ŧ\":\"t\",\"Ũ\":\"U\",\"Ū\":\"U\",\"Ŭ\":\"U\",\"Ů\":\"U\",\"Ű\":\"U\",\"Ų\":\"U\",\"ũ\":\"u\",\"ū\":\"u\",\"ŭ\":\"u\",\"ů\":\"u\",\"ű\":\"u\",\"ų\":\"u\",\"Ŵ\":\"W\",\"ŵ\":\"w\",\"Ŷ\":\"Y\",\"ŷ\":\"y\",\"Ÿ\":\"Y\",\"Ź\":\"Z\",\"Ż\":\"Z\",\"Ž\":\"Z\",\"ź\":\"z\",\"ż\":\"z\",\"ž\":\"z\",\"Ĳ\":\"IJ\",\n",
       "\"ĳ\":\"ij\",\"Œ\":\"Oe\",\"œ\":\"oe\",\"ŉ\":\"'n\",\"ſ\":\"s\"},tr={\"&\":\"&amp;\",\"<\":\"&lt;\",\">\":\"&gt;\",'\"':\"&quot;\",\"'\":\"&#39;\"},er={\"&amp;\":\"&\",\"&lt;\":\"<\",\"&gt;\":\">\",\"&quot;\":'\"',\"&#39;\":\"'\"},nr={\"\\\\\":\"\\\\\",\"'\":\"'\",\"\\n\":\"n\",\"\\r\":\"r\",\"\\u2028\":\"u2028\",\"\\u2029\":\"u2029\"},rr=parseFloat,ir=parseInt,or=\"object\"==typeof t&&t&&t.Object===Object&&t,ar=\"object\"==typeof self&&self&&self.Object===Object&&self,ur=or||ar||Function(\"return this\")(),cr=\"object\"==typeof e&&e&&!e.nodeType&&e,sr=cr&&\"object\"==typeof r&&r&&!r.nodeType&&r,lr=sr&&sr.exports===cr,fr=lr&&or.process,pr=function(){try{return fr&&fr.binding&&fr.binding(\"util\")}catch(t){}}(),hr=pr&&pr.isArrayBuffer,dr=pr&&pr.isDate,vr=pr&&pr.isMap,gr=pr&&pr.isRegExp,mr=pr&&pr.isSet,yr=pr&&pr.isTypedArray,_r=S(\"length\"),br=P(Jn),xr=P(tr),wr=P(er),Cr=function t(e){function n(t){if(sc(t)&&!xp(t)&&!(t instanceof b)){if(t instanceof i)return t;if(bl.call(t,\"__wrapped__\"))return aa(t)}return new i(t)}function r(){}function i(t,e){this.__wrapped__=t,this.__actions__=[],this.__chain__=!!e,this.__index__=0,this.__values__=it}function b(t){this.__wrapped__=t,this.__actions__=[],this.__dir__=1,this.__filtered__=!1,this.__iteratees__=[],this.__takeCount__=Ft,this.__views__=[]}function P(){var t=new b(this.__wrapped__);return t.__actions__=Bi(this.__actions__),t.__dir__=this.__dir__,t.__filtered__=this.__filtered__,t.__iteratees__=Bi(this.__iteratees__),t.__takeCount__=this.__takeCount__,t.__views__=Bi(this.__views__),t}function Z(){if(this.__filtered__){var t=new b(this);t.__dir__=-1,t.__filtered__=!0}else t=this.clone(),t.__dir__*=-1;return t}function et(){var t=this.__wrapped__.value(),e=this.__dir__,n=xp(t),r=e<0,i=n?t.length:0,o=No(0,i,this.__views__),a=o.start,u=o.end,c=u-a,s=r?u:a-1,l=this.__iteratees__,f=l.length,p=0,h=Xl(c,this.__takeCount__);if(!n||!r&&i==c&&h==c)return xi(t,this.__actions__);var d=[];t:for(;c--&&p<h;){s+=e;for(var v=-1,g=t[s];++v<f;){var m=l[v],y=m.iteratee,_=m.type,b=y(g);if(_==Ot)g=b;else if(!b){if(_==At)continue t;break t}}d[p++]=g}return d}function nt(t){var e=-1,n=null==t?0:t.length;for(this.clear();++e<n;){var r=t[e];this.set(r[0],r[1])}}function ze(){this.__data__=uf?uf(null):{},this.size=0}function en(t){var e=this.has(t)&&delete this.__data__[t];return this.size-=e?1:0,e}function nn(t){var e=this.__data__;if(uf){var n=e[t];return n===st?it:n}return bl.call(e,t)?e[t]:it}function rn(t){var e=this.__data__;return uf?e[t]!==it:bl.call(e,t)}function on(t,e){var n=this.__data__;return this.size+=this.has(t)?0:1,n[t]=uf&&e===it?st:e,this}function an(t){var e=-1,n=null==t?0:t.length;for(this.clear();++e<n;){var r=t[e];this.set(r[0],r[1])}}function un(){this.__data__=[],this.size=0}function cn(t){var e=this.__data__,n=In(e,t);if(n<0)return!1;var r=e.length-1;return n==r?e.pop():Dl.call(e,n,1),--this.size,!0}function sn(t){var e=this.__data__,n=In(e,t);return n<0?it:e[n][1]}function ln(t){return In(this.__data__,t)>-1}function fn(t,e){var n=this.__data__,r=In(n,t);return r<0?(++this.size,n.push([t,e])):n[r][1]=e,this}function pn(t){var e=-1,n=null==t?0:t.length;for(this.clear();++e<n;){var r=t[e];this.set(r[0],r[1])}}function hn(){this.size=0,this.__data__={hash:new nt,map:new(nf||an),string:new nt}}function dn(t){var e=Eo(this,t).delete(t);return this.size-=e?1:0,e}function vn(t){return Eo(this,t).get(t)}function gn(t){return Eo(this,t).has(t)}function mn(t,e){var n=Eo(this,t),r=n.size;return n.set(t,e),this.size+=n.size==r?0:1,this}function yn(t){var e=-1,n=null==t?0:t.length;for(this.__data__=new pn;++e<n;)this.add(t[e])}function _n(t){return this.__data__.set(t,st),this}function bn(t){return this.__data__.has(t)}function xn(t){var e=this.__data__=new an(t);this.size=e.size}function wn(){this.__data__=new an,this.size=0}function Cn(t){var e=this.__data__,n=e.delete(t);return this.size=e.size,n}function Mn(t){return this.__data__.get(t)}function kn(t){return this.__data__.has(t)}function En(t,e){var n=this.__data__;if(n instanceof an){var r=n.__data__;if(!nf||r.length<at-1)return r.push([t,e]),this.size=++n.size,this;n=this.__data__=new pn(r)}return n.set(t,e),this.size=n.size,this}function Tn(t,e){var n=xp(t),r=!n&&bp(t),i=!n&&!r&&Cp(t),o=!n&&!r&&!i&&Sp(t),a=n||r||i||o,u=a?I(t.length,hl):[],c=u.length;for(var s in t)!e&&!bl.call(t,s)||a&&(\"length\"==s||i&&(\"offset\"==s||\"parent\"==s)||o&&(\"buffer\"==s||\"byteLength\"==s||\"byteOffset\"==s)||Fo(s,c))||u.push(s);return u}function Sn(t){var e=t.length;return e?t[ni(0,e-1)]:it}function Pn(t,e){return na(Bi(t),jn(e,0,t.length))}function Nn(t){return na(Bi(t))}function An(t,e,n){(n===it||$u(t[e],n))&&(n!==it||e in t)||Un(t,e,n)}function On(t,e,n){var r=t[e];bl.call(t,e)&&$u(r,n)&&(n!==it||e in t)||Un(t,e,n)}function In(t,e){for(var n=t.length;n--;)if($u(t[n][0],e))return n;return-1}function Dn(t,e,n,r){return _f(t,function(t,i,o){e(r,t,n(t),o)}),r}function Rn(t,e){return t&&Wi(e,Hc(e),t)}function Ln(t,e){return t&&Wi(e,qc(e),t)}function Un(t,e,n){\"__proto__\"==e&&Fl?Fl(t,e,{configurable:!0,enumerable:!0,value:n,writable:!0}):t[e]=n}function Fn(t,e){for(var n=-1,r=e.length,i=al(r),o=null==t;++n<r;)i[n]=o?it:Wc(t,e[n]);return i}function jn(t,e,n){return t===t&&(n!==it&&(t=t<=n?t:n),e!==it&&(t=t>=e?t:e)),t}function Bn(t,e,n,r,i,o){var a,u=e&pt,c=e&ht,l=e&dt;if(n&&(a=i?n(t,r,i,o):n(t)),a!==it)return a;if(!cc(t))return t;var f=xp(t);if(f){if(a=Io(t),!u)return Bi(t,a)}else{var p=Af(t),h=p==$t||p==Xt;if(Cp(t))return Si(t,u);if(p==te||p==Vt||h&&!i){if(a=c||h?{}:Do(t),!u)return c?zi(t,Ln(a,t)):Vi(t,Rn(a,t))}else{if(!Qn[p])return i?t:{};a=Ro(t,p,Bn,u)}}o||(o=new xn);var d=o.get(t);if(d)return d;o.set(t,a);var v=l?c?wo:xo:c?qc:Hc,g=f?it:v(t);return s(g||t,function(r,i){g&&(i=r,r=t[i]),On(a,i,Bn(r,e,n,i,t,o))}),a}function Wn(t){var e=Hc(t);return function(n){return Vn(n,t,e)}}function Vn(t,e,n){var r=n.length;if(null==t)return!r;for(t=fl(t);r--;){var i=n[r],o=e[i],a=t[i];if(a===it&&!(i in t)||!o(a))return!1}return!0}function qn(t,e,n){if(\"function\"!=typeof t)throw new dl(ct);return Df(function(){t.apply(it,n)},e)}function Yn(t,e,n,r){var i=-1,o=h,a=!0,u=t.length,c=[],s=e.length;if(!u)return c;n&&(e=v(e,R(n))),r?(o=d,a=!1):e.length>=at&&(o=U,a=!1,e=new yn(e));t:for(;++i<u;){var l=t[i],f=null==n?l:n(l);if(l=r||0!==l?l:0,a&&f===f){for(var p=s;p--;)if(e[p]===f)continue t;c.push(l)}else o(e,f,r)||c.push(l)}return c}function Kn(t,e){var n=!0;return _f(t,function(t,r,i){return n=!!e(t,r,i)}),n}function Gn(t,e,n){for(var r=-1,i=t.length;++r<i;){var o=t[r],a=e(o);if(null!=a&&(u===it?a===a&&!bc(a):n(a,u)))var u=a,c=o}return c}function Jn(t,e,n,r){var i=t.length;for(n=Ec(n),n<0&&(n=-n>i?0:i+n),r=r===it||r>i?i:Ec(r),r<0&&(r+=i),r=n>r?0:Tc(r);n<r;)t[n++]=e;return t}function tr(t,e){var n=[];return _f(t,function(t,r,i){e(t,r,i)&&n.push(t)}),n}function er(t,e,n,r,i){var o=-1,a=t.length;for(n||(n=Uo),i||(i=[]);++o<a;){var u=t[o];e>0&&n(u)?e>1?er(u,e-1,n,r,i):g(i,u):r||(i[i.length]=u)}return i}function nr(t,e){return t&&xf(t,e,Hc)}function or(t,e){return t&&wf(t,e,Hc)}function ar(t,e){return p(e,function(e){return oc(t[e])})}function cr(t,e){e=Ei(e,t);for(var n=0,r=e.length;null!=t&&n<r;)t=t[ra(e[n++])];return n&&n==r?t:it}function sr(t,e,n){var r=e(t);return xp(t)?r:g(r,n(t))}function fr(t){return null==t?t===it?ue:Jt:Ul&&Ul in fl(t)?Po(t):Xo(t)}function pr(t,e){return t>e}function _r(t,e){return null!=t&&bl.call(t,e)}function Cr(t,e){return null!=t&&e in fl(t)}function kr(t,e,n){return t>=Xl(e,n)&&t<$l(e,n)}function Er(t,e,n){for(var r=n?d:h,i=t[0].length,o=t.length,a=o,u=al(o),c=1/0,s=[];a--;){var l=t[a];a&&e&&(l=v(l,R(e))),c=Xl(l.length,c),u[a]=!n&&(e||i>=120&&l.length>=120)?new yn(a&&l):it}l=t[0];var f=-1,p=u[0];t:for(;++f<i&&s.length<c;){var g=l[f],m=e?e(g):g;if(g=n||0!==g?g:0,!(p?U(p,m):r(s,m,n))){for(a=o;--a;){var y=u[a];if(!(y?U(y,m):r(t[a],m,n)))continue t}p&&p.push(m),s.push(g)}}return s}function Tr(t,e,n,r){return nr(t,function(t,i,o){e(r,n(t),i,o)}),r}function Sr(t,e,n){e=Ei(e,t),t=Qo(t,e);var r=null==t?t:t[ra(ka(e))];return null==r?it:u(r,t,n)}function Pr(t){return sc(t)&&fr(t)==Vt}function Nr(t){return sc(t)&&fr(t)==le}function Ar(t){return sc(t)&&fr(t)==Yt}function Or(t,e,n,r,i){return t===e||(null==t||null==e||!sc(t)&&!sc(e)?t!==t&&e!==e:Ir(t,e,n,r,Or,i))}function Ir(t,e,n,r,i,o){var a=xp(t),u=xp(e),c=a?zt:Af(t),s=u?zt:Af(e);c=c==Vt?te:c,s=s==Vt?te:s;var l=c==te,f=s==te,p=c==s;if(p&&Cp(t)){if(!Cp(e))return!1;a=!0,l=!1}if(p&&!l)return o||(o=new xn),a||Sp(t)?mo(t,e,n,r,i,o):yo(t,e,c,n,r,i,o);if(!(n&vt)){var h=l&&bl.call(t,\"__wrapped__\"),d=f&&bl.call(e,\"__wrapped__\");if(h||d){var v=h?t.value():t,g=d?e.value():e;return o||(o=new xn),i(v,g,n,r,o)}}return!!p&&(o||(o=new xn),_o(t,e,n,r,i,o))}function Dr(t){return sc(t)&&Af(t)==Zt}function Rr(t,e,n,r){var i=n.length,o=i,a=!r;if(null==t)return!o;for(t=fl(t);i--;){var u=n[i];if(a&&u[2]?u[1]!==t[u[0]]:!(u[0]in t))return!1}for(;++i<o;){u=n[i];var c=u[0],s=t[c],l=u[1];if(a&&u[2]){if(s===it&&!(c in t))return!1}else{var f=new xn;if(r)var p=r(s,l,c,t,e,f);if(!(p===it?Or(l,s,vt|gt,r,f):p))return!1}}return!0}function Lr(t){if(!cc(t)||zo(t))return!1;var e=oc(t)?El:$e;return e.test(ia(t))}function Ur(t){return sc(t)&&fr(t)==re}function Fr(t){return sc(t)&&Af(t)==ie}function jr(t){return sc(t)&&uc(t.length)&&!!Zn[fr(t)]}function Br(t){return\"function\"==typeof t?t:null==t?Ds:\"object\"==typeof t?xp(t)?Yr(t[0],t[1]):qr(t):Vs(t)}function Wr(t){if(!Ho(t))return Gl(t);var e=[];for(var n in fl(t))bl.call(t,n)&&\"constructor\"!=n&&e.push(n);return e}function Vr(t){if(!cc(t))return $o(t);var e=Ho(t),n=[];for(var r in t)(\"constructor\"!=r||!e&&bl.call(t,r))&&n.push(r);return n}function zr(t,e){return t<e}function Hr(t,e){var n=-1,r=Xu(t)?al(t.length):[];return _f(t,function(t,i,o){r[++n]=e(t,i,o)}),r}function qr(t){var e=To(t);return 1==e.length&&e[0][2]?Yo(e[0][0],e[0][1]):function(n){return n===t||Rr(n,t,e)}}function Yr(t,e){return Bo(t)&&qo(e)?Yo(ra(t),e):function(n){var r=Wc(n,t);return r===it&&r===e?zc(n,t):Or(e,r,vt|gt)}}function Kr(t,e,n,r,i){t!==e&&xf(e,function(o,a){if(cc(o))i||(i=new xn),Gr(t,e,a,n,Kr,r,i);else{var u=r?r(t[a],o,a+\"\",t,e,i):it;u===it&&(u=o),An(t,a,u)}},qc)}function Gr(t,e,n,r,i,o,a){var u=t[n],c=e[n],s=a.get(c);if(s)return void An(t,n,s);var l=o?o(u,c,n+\"\",t,e,a):it,f=l===it;if(f){var p=xp(c),h=!p&&Cp(c),d=!p&&!h&&Sp(c);l=c,p||h||d?xp(u)?l=u:Zu(u)?l=Bi(u):h?(f=!1,l=Si(c,!0)):d?(f=!1,l=Ri(c,!0)):l=[]:mc(c)||bp(c)?(l=u,bp(u)?l=Pc(u):(!cc(u)||r&&oc(u))&&(l=Do(c))):f=!1}f&&(a.set(c,l),i(l,c,r,o,a),a.delete(c)),An(t,n,l)}function $r(t,e){var n=t.length;if(n)return e+=e<0?n:0,Fo(e,n)?t[e]:it}function Xr(t,e,n){var r=-1;e=v(e.length?e:[Ds],R(ko()));var i=Hr(t,function(t,n,i){var o=v(e,function(e){return e(t)});return{criteria:o,index:++r,value:t}});return A(i,function(t,e){return Ui(t,e,n)})}function Zr(t,e){return Qr(t,e,function(e,n){return zc(t,n)})}function Qr(t,e,n){for(var r=-1,i=e.length,o={};++r<i;){var a=e[r],u=cr(t,a);n(u,a)&&ci(o,Ei(a,t),u)}return o}function Jr(t){return function(e){return cr(e,t)}}function ti(t,e,n,r){var i=r?k:M,o=-1,a=e.length,u=t;for(t===e&&(e=Bi(e)),n&&(u=v(t,R(n)));++o<a;)for(var c=0,s=e[o],l=n?n(s):s;(c=i(u,l,c,r))>-1;)u!==t&&Dl.call(u,c,1),Dl.call(t,c,1);return t}function ei(t,e){for(var n=t?e.length:0,r=n-1;n--;){var i=e[n];if(n==r||i!==o){var o=i;Fo(i)?Dl.call(t,i,1):yi(t,i)}}return t}function ni(t,e){return t+zl(Jl()*(e-t+1))}function ri(t,e,n,r){for(var i=-1,o=$l(Vl((e-t)/(n||1)),0),a=al(o);o--;)a[r?o:++i]=t,t+=n;return a}function ii(t,e){var n=\"\";if(!t||e<1||e>Rt)return n;do e%2&&(n+=t),e=zl(e/2),e&&(t+=t);while(e);return n}function oi(t,e){return Rf(Zo(t,e,Ds),t+\"\")}function ai(t){return Sn(rs(t))}function ui(t,e){var n=rs(t);return na(n,jn(e,0,n.length))}function ci(t,e,n,r){if(!cc(t))return t;e=Ei(e,t);for(var i=-1,o=e.length,a=o-1,u=t;null!=u&&++i<o;){var c=ra(e[i]),s=n;if(i!=a){var l=u[c];s=r?r(l,c,u):it,s===it&&(s=cc(l)?l:Fo(e[i+1])?[]:{})}On(u,c,s),u=u[c]}return t}function si(t){return na(rs(t))}function li(t,e,n){var r=-1,i=t.length;e<0&&(e=-e>i?0:i+e),n=n>i?i:n,n<0&&(n+=i),i=e>n?0:n-e>>>0,e>>>=0;for(var o=al(i);++r<i;)o[r]=t[r+e];return o}function fi(t,e){var n;return _f(t,function(t,r,i){return n=e(t,r,i),!n}),!!n}function pi(t,e,n){var r=0,i=null==t?r:t.length;if(\"number\"==typeof e&&e===e&&i<=Bt){for(;r<i;){var o=r+i>>>1,a=t[o];null!==a&&!bc(a)&&(n?a<=e:a<e)?r=o+1:i=o}return i}return hi(t,e,Ds,n)}function hi(t,e,n,r){e=n(e);for(var i=0,o=null==t?0:t.length,a=e!==e,u=null===e,c=bc(e),s=e===it;i<o;){var l=zl((i+o)/2),f=n(t[l]),p=f!==it,h=null===f,d=f===f,v=bc(f);if(a)var g=r||d;else g=s?d&&(r||p):u?d&&p&&(r||!h):c?d&&p&&!h&&(r||!v):!h&&!v&&(r?f<=e:f<e);g?i=l+1:o=l}return Xl(o,jt)}function di(t,e){for(var n=-1,r=t.length,i=0,o=[];++n<r;){var a=t[n],u=e?e(a):a;if(!n||!$u(u,c)){var c=u;o[i++]=0===a?0:a}}return o}function vi(t){return\"number\"==typeof t?t:bc(t)?Ut:+t}function gi(t){if(\"string\"==typeof t)return t;if(xp(t))return v(t,gi)+\"\";if(bc(t))return mf?mf.call(t):\"\";var e=t+\"\";return\"0\"==e&&1/t==-Dt?\"-0\":e}function mi(t,e,n){var r=-1,i=h,o=t.length,a=!0,u=[],c=u;if(n)a=!1,i=d;else if(o>=at){var s=e?null:Tf(t);if(s)return $(s);a=!1,i=U,c=new yn}else c=e?[]:u;t:for(;++r<o;){var l=t[r],f=e?e(l):l;if(l=n||0!==l?l:0,a&&f===f){for(var p=c.length;p--;)if(c[p]===f)continue t;e&&c.push(f),u.push(l)}else i(c,f,n)||(c!==u&&c.push(f),u.push(l))}return u}function yi(t,e){return e=Ei(e,t),t=Qo(t,e),null==t||delete t[ra(ka(e))]}function _i(t,e,n,r){return ci(t,e,n(cr(t,e)),r)}function bi(t,e,n,r){for(var i=t.length,o=r?i:-1;(r?o--:++o<i)&&e(t[o],o,t););return n?li(t,r?0:o,r?o+1:i):li(t,r?o+1:0,r?i:o)}function xi(t,e){var n=t;return n instanceof b&&(n=n.value()),m(e,function(t,e){return e.func.apply(e.thisArg,g([t],e.args))},n)}function wi(t,e,n){var r=t.length;if(r<2)return r?mi(t[0]):[];for(var i=-1,o=al(r);++i<r;)for(var a=t[i],u=-1;++u<r;)u!=i&&(o[i]=Yn(o[i]||a,t[u],e,n));return mi(er(o,1),e,n)}function Ci(t,e,n){for(var r=-1,i=t.length,o=e.length,a={};++r<i;){var u=r<o?e[r]:it;n(a,t[r],u)}return a}function Mi(t){return Zu(t)?t:[]}function ki(t){return\"function\"==typeof t?t:Ds}function Ei(t,e){return xp(t)?t:Bo(t,e)?[t]:Lf(Ac(t))}function Ti(t,e,n){var r=t.length;return n=n===it?r:n,!e&&n>=r?t:li(t,e,n)}function Si(t,e){if(e)return t.slice();var n=t.length,r=Nl?Nl(n):new t.constructor(n);return t.copy(r),r}function Pi(t){var e=new t.constructor(t.byteLength);return new Pl(e).set(new Pl(t)),e}function Ni(t,e){var n=e?Pi(t.buffer):t.buffer;return new t.constructor(n,t.byteOffset,t.byteLength)}function Ai(t,e,n){var r=e?n(Y(t),pt):Y(t);return m(r,o,new t.constructor)}function Oi(t){var e=new t.constructor(t.source,Ye.exec(t));return e.lastIndex=t.lastIndex,e}function Ii(t,e,n){var r=e?n($(t),pt):$(t);return m(r,a,new t.constructor)}function Di(t){return gf?fl(gf.call(t)):{}}function Ri(t,e){var n=e?Pi(t.buffer):t.buffer;return new t.constructor(n,t.byteOffset,t.length)}function Li(t,e){if(t!==e){var n=t!==it,r=null===t,i=t===t,o=bc(t),a=e!==it,u=null===e,c=e===e,s=bc(e);if(!u&&!s&&!o&&t>e||o&&a&&c&&!u&&!s||r&&a&&c||!n&&c||!i)return 1;if(!r&&!o&&!s&&t<e||s&&n&&i&&!r&&!o||u&&n&&i||!a&&i||!c)return-1}return 0}function Ui(t,e,n){for(var r=-1,i=t.criteria,o=e.criteria,a=i.length,u=n.length;++r<a;){var c=Li(i[r],o[r]);if(c){if(r>=u)return c;var s=n[r];return c*(\"desc\"==s?-1:1)}}return t.index-e.index}function Fi(t,e,n,r){for(var i=-1,o=t.length,a=n.length,u=-1,c=e.length,s=$l(o-a,0),l=al(c+s),f=!r;++u<c;)l[u]=e[u];for(;++i<a;)(f||i<o)&&(l[n[i]]=t[i]);for(;s--;)l[u++]=t[i++];return l}function ji(t,e,n,r){for(var i=-1,o=t.length,a=-1,u=n.length,c=-1,s=e.length,l=$l(o-u,0),f=al(l+s),p=!r;++i<l;)f[i]=t[i];for(var h=i;++c<s;)f[h+c]=e[c];for(;++a<u;)(p||i<o)&&(f[h+n[a]]=t[i++]);return f}function Bi(t,e){var n=-1,r=t.length;for(e||(e=al(r));++n<r;)e[n]=t[n];return e}function Wi(t,e,n,r){var i=!n;n||(n={});for(var o=-1,a=e.length;++o<a;){var u=e[o],c=r?r(n[u],t[u],u,n,t):it;c===it&&(c=t[u]),i?Un(n,u,c):On(n,u,c)}return n}function Vi(t,e){return Wi(t,Pf(t),e)}function zi(t,e){return Wi(t,Nf(t),e)}function Hi(t,e){return function(n,r){var i=xp(n)?c:Dn,o=e?e():{};return i(n,t,ko(r,2),o)}}function qi(t){return oi(function(e,n){var r=-1,i=n.length,o=i>1?n[i-1]:it,a=i>2?n[2]:it;for(o=t.length>3&&\"function\"==typeof o?(i--,o):it,a&&jo(n[0],n[1],a)&&(o=i<3?it:o,i=1),e=fl(e);++r<i;){var u=n[r];u&&t(e,u,r,o)}return e})}function Yi(t,e){return function(n,r){if(null==n)return n;if(!Xu(n))return t(n,r);for(var i=n.length,o=e?i:-1,a=fl(n);(e?o--:++o<i)&&r(a[o],o,a)!==!1;);return n}}function Ki(t){return function(e,n,r){for(var i=-1,o=fl(e),a=r(e),u=a.length;u--;){var c=a[t?u:++i];if(n(o[c],c,o)===!1)break}return e}}function Gi(t,e,n){function r(){var e=this&&this!==ur&&this instanceof r?o:t;return e.apply(i?n:this,arguments)}var i=e&mt,o=Zi(t);return r}function $i(t){return function(e){e=Ac(e);var n=z(e)?tt(e):it,r=n?n[0]:e.charAt(0),i=n?Ti(n,1).join(\"\"):e.slice(1);return r[t]()+i}}function Xi(t){return function(e){return m(Ps(ss(e).replace(zn,\"\")),t,\"\")}}function Zi(t){return function(){var e=arguments;switch(e.length){case 0:return new t;case 1:return new t(e[0]);case 2:return new t(e[0],e[1]);case 3:return new t(e[0],e[1],e[2]);case 4:return new t(e[0],e[1],e[2],e[3]);case 5:return new t(e[0],e[1],e[2],e[3],e[4]);case 6:return new t(e[0],e[1],e[2],e[3],e[4],e[5]);case 7:return new t(e[0],e[1],e[2],e[3],e[4],e[5],e[6])}var n=yf(t.prototype),r=t.apply(n,e);return cc(r)?r:n}}function Qi(t,e,n){function r(){for(var o=arguments.length,a=al(o),c=o,s=Mo(r);c--;)a[c]=arguments[c];var l=o<3&&a[0]!==s&&a[o-1]!==s?[]:G(a,s);if(o-=l.length,o<n)return so(t,e,eo,r.placeholder,it,a,l,it,it,n-o);var f=this&&this!==ur&&this instanceof r?i:t;return u(f,this,a)}var i=Zi(t);return r}function Ji(t){return function(e,n,r){var i=fl(e);if(!Xu(e)){var o=ko(n,3);e=Hc(e),n=function(t){return o(i[t],t,i)}}var a=t(e,n,r);return a>-1?i[o?e[a]:a]:it}}function to(t){return bo(function(e){var n=e.length,r=n,o=i.prototype.thru;for(t&&e.reverse();r--;){var a=e[r];if(\"function\"!=typeof a)throw new dl(ct);if(o&&!u&&\"wrapper\"==Co(a))var u=new i([],!0)}for(r=u?r:n;++r<n;){a=e[r];var c=Co(a),s=\"wrapper\"==c?Sf(a):it;u=s&&Vo(s[0])&&s[1]==(Mt|bt|wt|kt)&&!s[4].length&&1==s[9]?u[Co(s[0])].apply(u,s[3]):1==a.length&&Vo(a)?u[c]():u.thru(a)}return function(){var t=arguments,r=t[0];if(u&&1==t.length&&xp(r))return u.plant(r).value();for(var i=0,o=n?e[i].apply(this,t):r;++i<n;)o=e[i].call(this,o);return o}})}function eo(t,e,n,r,i,o,a,u,c,s){function l(){for(var m=arguments.length,y=al(m),_=m;_--;)y[_]=arguments[_];if(d)var b=Mo(l),x=B(y,b);if(r&&(y=Fi(y,r,i,d)),o&&(y=ji(y,o,a,d)),m-=x,d&&m<s){var w=G(y,b);return so(t,e,eo,l.placeholder,n,y,w,u,c,s-m)}var C=p?n:this,M=h?C[t]:t;return m=y.length,u?y=Jo(y,u):v&&m>1&&y.reverse(),f&&c<m&&(y.length=c),this&&this!==ur&&this instanceof l&&(M=g||Zi(M)),M.apply(C,y)}var f=e&Mt,p=e&mt,h=e&yt,d=e&(bt|xt),v=e&Et,g=h?it:Zi(t);return l}function no(t,e){return function(n,r){return Tr(n,t,e(r),{})}}function ro(t,e){return function(n,r){var i;if(n===it&&r===it)return e;if(n!==it&&(i=n),r!==it){if(i===it)return r;\"string\"==typeof n||\"string\"==typeof r?(n=gi(n),r=gi(r)):(n=vi(n),r=vi(r)),i=t(n,r)}return i}}function io(t){return bo(function(e){return e=v(e,R(ko())),oi(function(n){var r=this;return t(e,function(t){return u(t,r,n)})})})}function oo(t,e){e=e===it?\" \":gi(e);var n=e.length;if(n<2)return n?ii(e,t):e;var r=ii(e,Vl(t/J(e)));return z(e)?Ti(tt(r),0,t).join(\"\"):r.slice(0,t)}function ao(t,e,n,r){function i(){for(var e=-1,c=arguments.length,s=-1,l=r.length,f=al(l+c),p=this&&this!==ur&&this instanceof i?a:t;++s<l;)f[s]=r[s];for(;c--;)f[s++]=arguments[++e];return u(p,o?n:this,f)}var o=e&mt,a=Zi(t);return i}function uo(t){return function(e,n,r){return r&&\"number\"!=typeof r&&jo(e,n,r)&&(n=r=it),e=kc(e),n===it?(n=e,e=0):n=kc(n),r=r===it?e<n?1:-1:kc(r),ri(e,n,r,t)}}function co(t){return function(e,n){return\"string\"==typeof e&&\"string\"==typeof n||(e=Sc(e),n=Sc(n)),t(e,n)}}function so(t,e,n,r,i,o,a,u,c,s){var l=e&bt,f=l?a:it,p=l?it:a,h=l?o:it,d=l?it:o;e|=l?wt:Ct,e&=~(l?Ct:wt),e&_t||(e&=~(mt|yt));var v=[t,e,i,h,f,d,p,u,c,s],g=n.apply(it,v);return Vo(t)&&If(g,v),g.placeholder=r,ta(g,t,e)}function lo(t){var e=ll[t];return function(t,n){if(t=Sc(t),n=null==n?0:Xl(Ec(n),292)){var r=(Ac(t)+\"e\").split(\"e\"),i=e(r[0]+\"e\"+(+r[1]+n));return r=(Ac(i)+\"e\").split(\"e\"),+(r[0]+\"e\"+(+r[1]-n))}return e(t)}}function fo(t){return function(e){var n=Af(e);return n==Zt?Y(e):n==ie?X(e):D(e,t(e))}}function po(t,e,n,r,i,o,a,u){var c=e&yt;if(!c&&\"function\"!=typeof t)throw new dl(ct);var s=r?r.length:0;if(s||(e&=~(wt|Ct),r=i=it),a=a===it?a:$l(Ec(a),0),u=u===it?u:Ec(u),s-=i?i.length:0,e&Ct){var l=r,f=i;r=i=it}var p=c?it:Sf(t),h=[t,e,n,r,i,l,f,o,a,u];if(p&&Go(h,p),t=h[0],e=h[1],n=h[2],r=h[3],i=h[4],u=h[9]=h[9]===it?c?0:t.length:$l(h[9]-s,0),!u&&e&(bt|xt)&&(e&=~(bt|xt)),e&&e!=mt)d=e==bt||e==xt?Qi(t,e,u):e!=wt&&e!=(mt|wt)||i.length?eo.apply(it,h):ao(t,e,n,r);else var d=Gi(t,e,n);var v=p?Cf:If;return ta(v(d,h),t,e)}function ho(t,e,n,r){return t===it||$u(t,ml[n])&&!bl.call(r,n)?e:t}function vo(t,e,n,r,i,o){return cc(t)&&cc(e)&&(o.set(e,t),Kr(t,e,it,vo,o),o.delete(e)),t}function go(t){return mc(t)?it:t}function mo(t,e,n,r,i,o){var a=n&vt,u=t.length,c=e.length;if(u!=c&&!(a&&c>u))return!1;var s=o.get(t);if(s&&o.get(e))return s==e;var l=-1,f=!0,p=n&gt?new yn:it;for(o.set(t,e),o.set(e,t);++l<u;){var h=t[l],d=e[l];if(r)var v=a?r(d,h,l,e,t,o):r(h,d,l,t,e,o);if(v!==it){if(v)continue;f=!1;break}if(p){if(!_(e,function(t,e){if(!U(p,e)&&(h===t||i(h,t,n,r,o)))return p.push(e)})){f=!1;break}}else if(h!==d&&!i(h,d,n,r,o)){f=!1;break}}return o.delete(t),o.delete(e),f}function yo(t,e,n,r,i,o,a){switch(n){case fe:if(t.byteLength!=e.byteLength||t.byteOffset!=e.byteOffset)return!1;t=t.buffer,e=e.buffer;case le:return!(t.byteLength!=e.byteLength||!o(new Pl(t),new Pl(e)));case qt:case Yt:case Qt:return $u(+t,+e);case Gt:return t.name==e.name&&t.message==e.message;case re:case oe:return t==e+\"\";case Zt:var u=Y;case ie:var c=r&vt;if(u||(u=$),t.size!=e.size&&!c)return!1;var s=a.get(t);if(s)return s==e;r|=gt,a.set(t,e);var l=mo(u(t),u(e),r,i,o,a);return a.delete(t),l;case ae:if(gf)return gf.call(t)==gf.call(e)}return!1}function _o(t,e,n,r,i,o){var a=n&vt,u=xo(t),c=u.length,s=xo(e),l=s.length;if(c!=l&&!a)return!1;for(var f=c;f--;){var p=u[f];if(!(a?p in e:bl.call(e,p)))return!1}var h=o.get(t);if(h&&o.get(e))return h==e;var d=!0;o.set(t,e),o.set(e,t);for(var v=a;++f<c;){p=u[f];var g=t[p],m=e[p];if(r)var y=a?r(m,g,p,e,t,o):r(g,m,p,t,e,o);if(!(y===it?g===m||i(g,m,n,r,o):y)){d=!1;break}v||(v=\"constructor\"==p)}if(d&&!v){var _=t.constructor,b=e.constructor;_!=b&&\"constructor\"in t&&\"constructor\"in e&&!(\"function\"==typeof _&&_ instanceof _&&\"function\"==typeof b&&b instanceof b)&&(d=!1)}return o.delete(t),o.delete(e),d}function bo(t){return Rf(Zo(t,it,ma),t+\"\")}function xo(t){return sr(t,Hc,Pf)}function wo(t){return sr(t,qc,Nf)}function Co(t){for(var e=t.name+\"\",n=sf[e],r=bl.call(sf,e)?n.length:0;r--;){var i=n[r],o=i.func;if(null==o||o==t)return i.name}return e}function Mo(t){var e=bl.call(n,\"placeholder\")?n:t;return e.placeholder}function ko(){var t=n.iteratee||Rs;return t=t===Rs?Br:t,arguments.length?t(arguments[0],arguments[1]):t}function Eo(t,e){var n=t.__data__;return Wo(e)?n[\"string\"==typeof e?\"string\":\"hash\"]:n.map}function To(t){for(var e=Hc(t),n=e.length;n--;){var r=e[n],i=t[r];e[n]=[r,i,qo(i)]}return e}function So(t,e){var n=V(t,e);return Lr(n)?n:it}function Po(t){var e=bl.call(t,Ul),n=t[Ul];try{t[Ul]=it;var r=!0}catch(t){}var i=Cl.call(t);return r&&(e?t[Ul]=n:delete t[Ul]),i}function No(t,e,n){for(var r=-1,i=n.length;++r<i;){var o=n[r],a=o.size;switch(o.type){case\"drop\":t+=a;break;case\"dropRight\":e-=a;break;case\"take\":e=Xl(e,t+a);break;case\"takeRight\":t=$l(t,e-a)}}return{start:t,end:e}}function Ao(t){var e=t.match(We);return e?e[1].split(Ve):[]}function Oo(t,e,n){e=Ei(e,t);for(var r=-1,i=e.length,o=!1;++r<i;){var a=ra(e[r]);if(!(o=null!=t&&n(t,a)))break;t=t[a]}return o||++r!=i?o:(i=null==t?0:t.length,!!i&&uc(i)&&Fo(a,i)&&(xp(t)||bp(t)))}function Io(t){var e=t.length,n=t.constructor(e);return e&&\"string\"==typeof t[0]&&bl.call(t,\"index\")&&(n.index=t.index,n.input=t.input),n}function Do(t){return\"function\"!=typeof t.constructor||Ho(t)?{}:yf(Al(t))}function Ro(t,e,n,r){var i=t.constructor;switch(e){case le:return Pi(t);case qt:case Yt:return new i(+t);case fe:return Ni(t,r);case pe:case he:case de:case ve:case ge:case me:case ye:case _e:case be:return Ri(t,r);case Zt:return Ai(t,r,n);case Qt:case oe:return new i(t);case re:return Oi(t);case ie:return Ii(t,r,n);case ae:return Di(t)}}function Lo(t,e){var n=e.length;if(!n)return t;var r=n-1;return e[r]=(n>1?\"& \":\"\")+e[r],e=e.join(n>2?\", \":\" \"),t.replace(Be,\"{\\n/* [wrapped with \"+e+\"] */\\n\")}function Uo(t){return xp(t)||bp(t)||!!(Rl&&t&&t[Rl])}function Fo(t,e){return e=null==e?Rt:e,!!e&&(\"number\"==typeof t||Ze.test(t))&&t>-1&&t%1==0&&t<e}function jo(t,e,n){if(!cc(n))return!1;var r=typeof e;return!!(\"number\"==r?Xu(n)&&Fo(e,n.length):\"string\"==r&&e in n)&&$u(n[e],t)}function Bo(t,e){if(xp(t))return!1;var n=typeof t;return!(\"number\"!=n&&\"symbol\"!=n&&\"boolean\"!=n&&null!=t&&!bc(t))||(Oe.test(t)||!Ae.test(t)||null!=e&&t in fl(e))}function Wo(t){var e=typeof t;return\"string\"==e||\"number\"==e||\"symbol\"==e||\"boolean\"==e?\"__proto__\"!==t:null===t}function Vo(t){var e=Co(t),r=n[e];if(\"function\"!=typeof r||!(e in b.prototype))return!1;if(t===r)return!0;var i=Sf(r);return!!i&&t===i[0]}function zo(t){return!!wl&&wl in t}function Ho(t){var e=t&&t.constructor,n=\"function\"==typeof e&&e.prototype||ml;return t===n}function qo(t){return t===t&&!cc(t)}function Yo(t,e){return function(n){return null!=n&&(n[t]===e&&(e!==it||t in fl(n)))}}function Ko(t){var e=Ru(t,function(t){return n.size===lt&&n.clear(),t}),n=e.cache;return e}function Go(t,e){var n=t[1],r=e[1],i=n|r,o=i<(mt|yt|Mt),a=r==Mt&&n==bt||r==Mt&&n==kt&&t[7].length<=e[8]||r==(Mt|kt)&&e[7].length<=e[8]&&n==bt;if(!o&&!a)return t;r&mt&&(t[2]=e[2],i|=n&mt?0:_t);var u=e[3];if(u){var c=t[3];t[3]=c?Fi(c,u,e[4]):u,t[4]=c?G(t[3],ft):e[4]}return u=e[5],u&&(c=t[5],t[5]=c?ji(c,u,e[6]):u,t[6]=c?G(t[5],ft):e[6]),u=e[7],u&&(t[7]=u),r&Mt&&(t[8]=null==t[8]?e[8]:Xl(t[8],e[8])),null==t[9]&&(t[9]=e[9]),t[0]=e[0],t[1]=i,t}function $o(t){var e=[];if(null!=t)for(var n in fl(t))e.push(n);return e}function Xo(t){return Cl.call(t)}function Zo(t,e,n){return e=$l(e===it?t.length-1:e,0),function(){for(var r=arguments,i=-1,o=$l(r.length-e,0),a=al(o);++i<o;)a[i]=r[e+i];i=-1;for(var c=al(e+1);++i<e;)c[i]=r[i];return c[e]=n(a),u(t,this,c)}}function Qo(t,e){return e.length<2?t:cr(t,li(e,0,-1))}function Jo(t,e){for(var n=t.length,r=Xl(e.length,n),i=Bi(t);r--;){var o=e[r];t[r]=Fo(o,n)?i[o]:it}return t}function ta(t,e,n){var r=e+\"\";return Rf(t,Lo(r,oa(Ao(r),n)))}function ea(t){var e=0,n=0;return function(){var r=Zl(),i=Nt-(r-n);if(n=r,i>0){if(++e>=Pt)return arguments[0]}else e=0;return t.apply(it,arguments)}}function na(t,e){var n=-1,r=t.length,i=r-1;for(e=e===it?r:e;++n<e;){var o=ni(n,i),a=t[o];t[o]=t[n],t[n]=a}return t.length=e,t}function ra(t){if(\"string\"==typeof t||bc(t))return t;var e=t+\"\";return\"0\"==e&&1/t==-Dt?\"-0\":e}function ia(t){if(null!=t){try{return _l.call(t)}catch(t){}try{return t+\"\"}catch(t){}}return\"\"}function oa(t,e){return s(Wt,function(n){var r=\"_.\"+n[0];e&n[1]&&!h(t,r)&&t.push(r)}),t.sort()}function aa(t){if(t instanceof b)return t.clone();var e=new i(t.__wrapped__,t.__chain__);return e.__actions__=Bi(t.__actions__),e.__index__=t.__index__,e.__values__=t.__values__,e}function ua(t,e,n){e=(n?jo(t,e,n):e===it)?1:$l(Ec(e),0);var r=null==t?0:t.length;if(!r||e<1)return[];for(var i=0,o=0,a=al(Vl(r/e));i<r;)a[o++]=li(t,i,i+=e);return a}function ca(t){for(var e=-1,n=null==t?0:t.length,r=0,i=[];++e<n;){var o=t[e];o&&(i[r++]=o)}return i}function sa(){var t=arguments.length;if(!t)return[];for(var e=al(t-1),n=arguments[0],r=t;r--;)e[r-1]=arguments[r];return g(xp(n)?Bi(n):[n],er(e,1))}function la(t,e,n){var r=null==t?0:t.length;return r?(e=n||e===it?1:Ec(e),li(t,e<0?0:e,r)):[]}function fa(t,e,n){var r=null==t?0:t.length;return r?(e=n||e===it?1:Ec(e),e=r-e,li(t,0,e<0?0:e)):[]}function pa(t,e){return t&&t.length?bi(t,ko(e,3),!0,!0):[]}function ha(t,e){return t&&t.length?bi(t,ko(e,3),!0):[]}function da(t,e,n,r){var i=null==t?0:t.length;return i?(n&&\"number\"!=typeof n&&jo(t,e,n)&&(n=0,r=i),Jn(t,e,n,r)):[]}function va(t,e,n){var r=null==t?0:t.length;if(!r)return-1;var i=null==n?0:Ec(n);return i<0&&(i=$l(r+i,0)),C(t,ko(e,3),i)}function ga(t,e,n){var r=null==t?0:t.length;if(!r)return-1;var i=r-1;return n!==it&&(i=Ec(n),i=n<0?$l(r+i,0):Xl(i,r-1)),C(t,ko(e,3),i,!0)}function ma(t){var e=null==t?0:t.length;return e?er(t,1):[]}function ya(t){var e=null==t?0:t.length;return e?er(t,Dt):[]}function _a(t,e){var n=null==t?0:t.length;return n?(e=e===it?1:Ec(e),er(t,e)):[]}function ba(t){for(var e=-1,n=null==t?0:t.length,r={};++e<n;){var i=t[e];r[i[0]]=i[1]}return r}function xa(t){return t&&t.length?t[0]:it}function wa(t,e,n){var r=null==t?0:t.length;if(!r)return-1;var i=null==n?0:Ec(n);return i<0&&(i=$l(r+i,0)),M(t,e,i)}function Ca(t){var e=null==t?0:t.length;return e?li(t,0,-1):[]}function Ma(t,e){return null==t?\"\":Kl.call(t,e)}function ka(t){var e=null==t?0:t.length;return e?t[e-1]:it}function Ea(t,e,n){var r=null==t?0:t.length;if(!r)return-1;var i=r;return n!==it&&(i=Ec(n),i=i<0?$l(r+i,0):Xl(i,r-1)),e===e?Q(t,e,i):C(t,E,i,!0)}function Ta(t,e){return t&&t.length?$r(t,Ec(e)):it}function Sa(t,e){return t&&t.length&&e&&e.length?ti(t,e):t}function Pa(t,e,n){return t&&t.length&&e&&e.length?ti(t,e,ko(n,2)):t}function Na(t,e,n){return t&&t.length&&e&&e.length?ti(t,e,it,n):t}function Aa(t,e){var n=[];if(!t||!t.length)return n;var r=-1,i=[],o=t.length;for(e=ko(e,3);++r<o;){var a=t[r];e(a,r,t)&&(n.push(a),i.push(r))}return ei(t,i),n}function Oa(t){return null==t?t:tf.call(t)}function Ia(t,e,n){var r=null==t?0:t.length;return r?(n&&\"number\"!=typeof n&&jo(t,e,n)?(e=0,n=r):(e=null==e?0:Ec(e),n=n===it?r:Ec(n)),li(t,e,n)):[]}function Da(t,e){return pi(t,e)}function Ra(t,e,n){return hi(t,e,ko(n,2))}function La(t,e){var n=null==t?0:t.length;if(n){var r=pi(t,e);if(r<n&&$u(t[r],e))return r}return-1}function Ua(t,e){return pi(t,e,!0)}function Fa(t,e,n){return hi(t,e,ko(n,2),!0)}function ja(t,e){var n=null==t?0:t.length;if(n){var r=pi(t,e,!0)-1;if($u(t[r],e))return r}return-1}function Ba(t){return t&&t.length?di(t):[]}function Wa(t,e){return t&&t.length?di(t,ko(e,2)):[]}function Va(t){var e=null==t?0:t.length;return e?li(t,1,e):[]}function za(t,e,n){return t&&t.length?(e=n||e===it?1:Ec(e),li(t,0,e<0?0:e)):[]}function Ha(t,e,n){var r=null==t?0:t.length;return r?(e=n||e===it?1:Ec(e),e=r-e,li(t,e<0?0:e,r)):[]}function qa(t,e){return t&&t.length?bi(t,ko(e,3),!1,!0):[]}function Ya(t,e){return t&&t.length?bi(t,ko(e,3)):[]}function Ka(t){return t&&t.length?mi(t):[]}function Ga(t,e){return t&&t.length?mi(t,ko(e,2)):[]}function $a(t,e){return e=\"function\"==typeof e?e:it,t&&t.length?mi(t,it,e):[]}function Xa(t){if(!t||!t.length)return[];var e=0;return t=p(t,function(t){if(Zu(t))return e=$l(t.length,e),!0}),I(e,function(e){return v(t,S(e))})}function Za(t,e){if(!t||!t.length)return[];var n=Xa(t);return null==e?n:v(n,function(t){return u(e,it,t)})}function Qa(t,e){return Ci(t||[],e||[],On)}function Ja(t,e){return Ci(t||[],e||[],ci)}function tu(t){var e=n(t);return e.__chain__=!0,e}function eu(t,e){return e(t),t}function nu(t,e){return e(t)}function ru(){return tu(this)}function iu(){return new i(this.value(),this.__chain__)}function ou(){this.__values__===it&&(this.__values__=Mc(this.value()));var t=this.__index__>=this.__values__.length,e=t?it:this.__values__[this.__index__++];return{done:t,value:e}}function au(){return this}function uu(t){for(var e,n=this;n instanceof r;){var i=aa(n);i.__index__=0,i.__values__=it,e?o.__wrapped__=i:e=i;var o=i;n=n.__wrapped__}return o.__wrapped__=t,e}function cu(){var t=this.__wrapped__;if(t instanceof b){var e=t;return this.__actions__.length&&(e=new b(this)),e=e.reverse(),e.__actions__.push({func:nu,args:[Oa],thisArg:it}),new i(e,this.__chain__)}return this.thru(Oa)}function su(){return xi(this.__wrapped__,this.__actions__)}function lu(t,e,n){\n",
       "var r=xp(t)?f:Kn;return n&&jo(t,e,n)&&(e=it),r(t,ko(e,3))}function fu(t,e){var n=xp(t)?p:tr;return n(t,ko(e,3))}function pu(t,e){return er(yu(t,e),1)}function hu(t,e){return er(yu(t,e),Dt)}function du(t,e,n){return n=n===it?1:Ec(n),er(yu(t,e),n)}function vu(t,e){var n=xp(t)?s:_f;return n(t,ko(e,3))}function gu(t,e){var n=xp(t)?l:bf;return n(t,ko(e,3))}function mu(t,e,n,r){t=Xu(t)?t:rs(t),n=n&&!r?Ec(n):0;var i=t.length;return n<0&&(n=$l(i+n,0)),_c(t)?n<=i&&t.indexOf(e,n)>-1:!!i&&M(t,e,n)>-1}function yu(t,e){var n=xp(t)?v:Hr;return n(t,ko(e,3))}function _u(t,e,n,r){return null==t?[]:(xp(e)||(e=null==e?[]:[e]),n=r?it:n,xp(n)||(n=null==n?[]:[n]),Xr(t,e,n))}function bu(t,e,n){var r=xp(t)?m:N,i=arguments.length<3;return r(t,ko(e,4),n,i,_f)}function xu(t,e,n){var r=xp(t)?y:N,i=arguments.length<3;return r(t,ko(e,4),n,i,bf)}function wu(t,e){var n=xp(t)?p:tr;return n(t,Lu(ko(e,3)))}function Cu(t){var e=xp(t)?Sn:ai;return e(t)}function Mu(t,e,n){e=(n?jo(t,e,n):e===it)?1:Ec(e);var r=xp(t)?Pn:ui;return r(t,e)}function ku(t){var e=xp(t)?Nn:si;return e(t)}function Eu(t){if(null==t)return 0;if(Xu(t))return _c(t)?J(t):t.length;var e=Af(t);return e==Zt||e==ie?t.size:Wr(t).length}function Tu(t,e,n){var r=xp(t)?_:fi;return n&&jo(t,e,n)&&(e=it),r(t,ko(e,3))}function Su(t,e){if(\"function\"!=typeof e)throw new dl(ct);return t=Ec(t),function(){if(--t<1)return e.apply(this,arguments)}}function Pu(t,e,n){return e=n?it:e,e=t&&null==e?t.length:e,po(t,Mt,it,it,it,it,e)}function Nu(t,e){var n;if(\"function\"!=typeof e)throw new dl(ct);return t=Ec(t),function(){return--t>0&&(n=e.apply(this,arguments)),t<=1&&(e=it),n}}function Au(t,e,n){e=n?it:e;var r=po(t,bt,it,it,it,it,it,e);return r.placeholder=Au.placeholder,r}function Ou(t,e,n){e=n?it:e;var r=po(t,xt,it,it,it,it,it,e);return r.placeholder=Ou.placeholder,r}function Iu(t,e,n){function r(e){var n=p,r=h;return p=h=it,y=e,v=t.apply(r,n)}function i(t){return y=t,g=Df(u,e),_?r(t):v}function o(t){var n=t-m,r=t-y,i=e-n;return b?Xl(i,d-r):i}function a(t){var n=t-m,r=t-y;return m===it||n>=e||n<0||b&&r>=d}function u(){var t=sp();return a(t)?c(t):void(g=Df(u,o(t)))}function c(t){return g=it,x&&p?r(t):(p=h=it,v)}function s(){g!==it&&Ef(g),y=0,p=m=h=g=it}function l(){return g===it?v:c(sp())}function f(){var t=sp(),n=a(t);if(p=arguments,h=this,m=t,n){if(g===it)return i(m);if(b)return g=Df(u,e),r(m)}return g===it&&(g=Df(u,e)),v}var p,h,d,v,g,m,y=0,_=!1,b=!1,x=!0;if(\"function\"!=typeof t)throw new dl(ct);return e=Sc(e)||0,cc(n)&&(_=!!n.leading,b=\"maxWait\"in n,d=b?$l(Sc(n.maxWait)||0,e):d,x=\"trailing\"in n?!!n.trailing:x),f.cancel=s,f.flush=l,f}function Du(t){return po(t,Et)}function Ru(t,e){if(\"function\"!=typeof t||null!=e&&\"function\"!=typeof e)throw new dl(ct);var n=function(){var r=arguments,i=e?e.apply(this,r):r[0],o=n.cache;if(o.has(i))return o.get(i);var a=t.apply(this,r);return n.cache=o.set(i,a)||o,a};return n.cache=new(Ru.Cache||pn),n}function Lu(t){if(\"function\"!=typeof t)throw new dl(ct);return function(){var e=arguments;switch(e.length){case 0:return!t.call(this);case 1:return!t.call(this,e[0]);case 2:return!t.call(this,e[0],e[1]);case 3:return!t.call(this,e[0],e[1],e[2])}return!t.apply(this,e)}}function Uu(t){return Nu(2,t)}function Fu(t,e){if(\"function\"!=typeof t)throw new dl(ct);return e=e===it?e:Ec(e),oi(t,e)}function ju(t,e){if(\"function\"!=typeof t)throw new dl(ct);return e=null==e?0:$l(Ec(e),0),oi(function(n){var r=n[e],i=Ti(n,0,e);return r&&g(i,r),u(t,this,i)})}function Bu(t,e,n){var r=!0,i=!0;if(\"function\"!=typeof t)throw new dl(ct);return cc(n)&&(r=\"leading\"in n?!!n.leading:r,i=\"trailing\"in n?!!n.trailing:i),Iu(t,e,{leading:r,maxWait:e,trailing:i})}function Wu(t){return Pu(t,1)}function Vu(t,e){return vp(ki(e),t)}function zu(){if(!arguments.length)return[];var t=arguments[0];return xp(t)?t:[t]}function Hu(t){return Bn(t,dt)}function qu(t,e){return e=\"function\"==typeof e?e:it,Bn(t,dt,e)}function Yu(t){return Bn(t,pt|dt)}function Ku(t,e){return e=\"function\"==typeof e?e:it,Bn(t,pt|dt,e)}function Gu(t,e){return null==e||Vn(t,e,Hc(e))}function $u(t,e){return t===e||t!==t&&e!==e}function Xu(t){return null!=t&&uc(t.length)&&!oc(t)}function Zu(t){return sc(t)&&Xu(t)}function Qu(t){return t===!0||t===!1||sc(t)&&fr(t)==qt}function Ju(t){return sc(t)&&1===t.nodeType&&!mc(t)}function tc(t){if(null==t)return!0;if(Xu(t)&&(xp(t)||\"string\"==typeof t||\"function\"==typeof t.splice||Cp(t)||Sp(t)||bp(t)))return!t.length;var e=Af(t);if(e==Zt||e==ie)return!t.size;if(Ho(t))return!Wr(t).length;for(var n in t)if(bl.call(t,n))return!1;return!0}function ec(t,e){return Or(t,e)}function nc(t,e,n){n=\"function\"==typeof n?n:it;var r=n?n(t,e):it;return r===it?Or(t,e,it,n):!!r}function rc(t){if(!sc(t))return!1;var e=fr(t);return e==Gt||e==Kt||\"string\"==typeof t.message&&\"string\"==typeof t.name&&!mc(t)}function ic(t){return\"number\"==typeof t&&Yl(t)}function oc(t){if(!cc(t))return!1;var e=fr(t);return e==$t||e==Xt||e==Ht||e==ne}function ac(t){return\"number\"==typeof t&&t==Ec(t)}function uc(t){return\"number\"==typeof t&&t>-1&&t%1==0&&t<=Rt}function cc(t){var e=typeof t;return null!=t&&(\"object\"==e||\"function\"==e)}function sc(t){return null!=t&&\"object\"==typeof t}function lc(t,e){return t===e||Rr(t,e,To(e))}function fc(t,e,n){return n=\"function\"==typeof n?n:it,Rr(t,e,To(e),n)}function pc(t){return gc(t)&&t!=+t}function hc(t){if(Of(t))throw new cl(ut);return Lr(t)}function dc(t){return null===t}function vc(t){return null==t}function gc(t){return\"number\"==typeof t||sc(t)&&fr(t)==Qt}function mc(t){if(!sc(t)||fr(t)!=te)return!1;var e=Al(t);if(null===e)return!0;var n=bl.call(e,\"constructor\")&&e.constructor;return\"function\"==typeof n&&n instanceof n&&_l.call(n)==Ml}function yc(t){return ac(t)&&t>=-Rt&&t<=Rt}function _c(t){return\"string\"==typeof t||!xp(t)&&sc(t)&&fr(t)==oe}function bc(t){return\"symbol\"==typeof t||sc(t)&&fr(t)==ae}function xc(t){return t===it}function wc(t){return sc(t)&&Af(t)==ce}function Cc(t){return sc(t)&&fr(t)==se}function Mc(t){if(!t)return[];if(Xu(t))return _c(t)?tt(t):Bi(t);if(Ll&&t[Ll])return q(t[Ll]());var e=Af(t),n=e==Zt?Y:e==ie?$:rs;return n(t)}function kc(t){if(!t)return 0===t?t:0;if(t=Sc(t),t===Dt||t===-Dt){var e=t<0?-1:1;return e*Lt}return t===t?t:0}function Ec(t){var e=kc(t),n=e%1;return e===e?n?e-n:e:0}function Tc(t){return t?jn(Ec(t),0,Ft):0}function Sc(t){if(\"number\"==typeof t)return t;if(bc(t))return Ut;if(cc(t)){var e=\"function\"==typeof t.valueOf?t.valueOf():t;t=cc(e)?e+\"\":e}if(\"string\"!=typeof t)return 0===t?t:+t;t=t.replace(Ue,\"\");var n=Ge.test(t);return n||Xe.test(t)?ir(t.slice(2),n?2:8):Ke.test(t)?Ut:+t}function Pc(t){return Wi(t,qc(t))}function Nc(t){return t?jn(Ec(t),-Rt,Rt):0===t?t:0}function Ac(t){return null==t?\"\":gi(t)}function Oc(t,e){var n=yf(t);return null==e?n:Rn(n,e)}function Ic(t,e){return w(t,ko(e,3),nr)}function Dc(t,e){return w(t,ko(e,3),or)}function Rc(t,e){return null==t?t:xf(t,ko(e,3),qc)}function Lc(t,e){return null==t?t:wf(t,ko(e,3),qc)}function Uc(t,e){return t&&nr(t,ko(e,3))}function Fc(t,e){return t&&or(t,ko(e,3))}function jc(t){return null==t?[]:ar(t,Hc(t))}function Bc(t){return null==t?[]:ar(t,qc(t))}function Wc(t,e,n){var r=null==t?it:cr(t,e);return r===it?n:r}function Vc(t,e){return null!=t&&Oo(t,e,_r)}function zc(t,e){return null!=t&&Oo(t,e,Cr)}function Hc(t){return Xu(t)?Tn(t):Wr(t)}function qc(t){return Xu(t)?Tn(t,!0):Vr(t)}function Yc(t,e){var n={};return e=ko(e,3),nr(t,function(t,r,i){Un(n,e(t,r,i),t)}),n}function Kc(t,e){var n={};return e=ko(e,3),nr(t,function(t,r,i){Un(n,r,e(t,r,i))}),n}function Gc(t,e){return $c(t,Lu(ko(e)))}function $c(t,e){if(null==t)return{};var n=v(wo(t),function(t){return[t]});return e=ko(e),Qr(t,n,function(t,n){return e(t,n[0])})}function Xc(t,e,n){e=Ei(e,t);var r=-1,i=e.length;for(i||(i=1,t=it);++r<i;){var o=null==t?it:t[ra(e[r])];o===it&&(r=i,o=n),t=oc(o)?o.call(t):o}return t}function Zc(t,e,n){return null==t?t:ci(t,e,n)}function Qc(t,e,n,r){return r=\"function\"==typeof r?r:it,null==t?t:ci(t,e,n,r)}function Jc(t,e,n){var r=xp(t),i=r||Cp(t)||Sp(t);if(e=ko(e,4),null==n){var o=t&&t.constructor;n=i?r?new o:[]:cc(t)&&oc(o)?yf(Al(t)):{}}return(i?s:nr)(t,function(t,r,i){return e(n,t,r,i)}),n}function ts(t,e){return null==t||yi(t,e)}function es(t,e,n){return null==t?t:_i(t,e,ki(n))}function ns(t,e,n,r){return r=\"function\"==typeof r?r:it,null==t?t:_i(t,e,ki(n),r)}function rs(t){return null==t?[]:L(t,Hc(t))}function is(t){return null==t?[]:L(t,qc(t))}function os(t,e,n){return n===it&&(n=e,e=it),n!==it&&(n=Sc(n),n=n===n?n:0),e!==it&&(e=Sc(e),e=e===e?e:0),jn(Sc(t),e,n)}function as(t,e,n){return e=kc(e),n===it?(n=e,e=0):n=kc(n),t=Sc(t),kr(t,e,n)}function us(t,e,n){if(n&&\"boolean\"!=typeof n&&jo(t,e,n)&&(e=n=it),n===it&&(\"boolean\"==typeof e?(n=e,e=it):\"boolean\"==typeof t&&(n=t,t=it)),t===it&&e===it?(t=0,e=1):(t=kc(t),e===it?(e=t,t=0):e=kc(e)),t>e){var r=t;t=e,e=r}if(n||t%1||e%1){var i=Jl();return Xl(t+i*(e-t+rr(\"1e-\"+((i+\"\").length-1))),e)}return ni(t,e)}function cs(t){return th(Ac(t).toLowerCase())}function ss(t){return t=Ac(t),t&&t.replace(Qe,br).replace(Hn,\"\")}function ls(t,e,n){t=Ac(t),e=gi(e);var r=t.length;n=n===it?r:jn(Ec(n),0,r);var i=n;return n-=e.length,n>=0&&t.slice(n,i)==e}function fs(t){return t=Ac(t),t&&Te.test(t)?t.replace(ke,xr):t}function ps(t){return t=Ac(t),t&&Le.test(t)?t.replace(Re,\"\\\\$&\"):t}function hs(t,e,n){t=Ac(t),e=Ec(e);var r=e?J(t):0;if(!e||r>=e)return t;var i=(e-r)/2;return oo(zl(i),n)+t+oo(Vl(i),n)}function ds(t,e,n){t=Ac(t),e=Ec(e);var r=e?J(t):0;return e&&r<e?t+oo(e-r,n):t}function vs(t,e,n){t=Ac(t),e=Ec(e);var r=e?J(t):0;return e&&r<e?oo(e-r,n)+t:t}function gs(t,e,n){return n||null==e?e=0:e&&(e=+e),Ql(Ac(t).replace(Fe,\"\"),e||0)}function ms(t,e,n){return e=(n?jo(t,e,n):e===it)?1:Ec(e),ii(Ac(t),e)}function ys(){var t=arguments,e=Ac(t[0]);return t.length<3?e:e.replace(t[1],t[2])}function _s(t,e,n){return n&&\"number\"!=typeof n&&jo(t,e,n)&&(e=n=it),(n=n===it?Ft:n>>>0)?(t=Ac(t),t&&(\"string\"==typeof e||null!=e&&!Ep(e))&&(e=gi(e),!e&&z(t))?Ti(tt(t),0,n):t.split(e,n)):[]}function bs(t,e,n){return t=Ac(t),n=null==n?0:jn(Ec(n),0,t.length),e=gi(e),t.slice(n,n+e.length)==e}function xs(t,e,r){var i=n.templateSettings;r&&jo(t,e,r)&&(e=it),t=Ac(t),e=Ip({},e,i,ho);var o,a,u=Ip({},e.imports,i.imports,ho),c=Hc(u),s=L(u,c),l=0,f=e.interpolate||Je,p=\"__p += '\",h=pl((e.escape||Je).source+\"|\"+f.source+\"|\"+(f===Ne?qe:Je).source+\"|\"+(e.evaluate||Je).source+\"|$\",\"g\"),d=\"//# sourceURL=\"+(\"sourceURL\"in e?e.sourceURL:\"lodash.templateSources[\"+ ++Xn+\"]\")+\"\\n\";t.replace(h,function(e,n,r,i,u,c){return r||(r=i),p+=t.slice(l,c).replace(tn,W),n&&(o=!0,p+=\"' +\\n__e(\"+n+\") +\\n'\"),u&&(a=!0,p+=\"';\\n\"+u+\";\\n__p += '\"),r&&(p+=\"' +\\n((__t = (\"+r+\")) == null ? '' : __t) +\\n'\"),l=c+e.length,e}),p+=\"';\\n\";var v=e.variable;v||(p=\"with (obj) {\\n\"+p+\"\\n}\\n\"),p=(a?p.replace(xe,\"\"):p).replace(we,\"$1\").replace(Ce,\"$1;\"),p=\"function(\"+(v||\"obj\")+\") {\\n\"+(v?\"\":\"obj || (obj = {});\\n\")+\"var __t, __p = ''\"+(o?\", __e = _.escape\":\"\")+(a?\", __j = Array.prototype.join;\\nfunction print() { __p += __j.call(arguments, '') }\\n\":\";\\n\")+p+\"return __p\\n}\";var g=eh(function(){return sl(c,d+\"return \"+p).apply(it,s)});if(g.source=p,rc(g))throw g;return g}function ws(t){return Ac(t).toLowerCase()}function Cs(t){return Ac(t).toUpperCase()}function Ms(t,e,n){if(t=Ac(t),t&&(n||e===it))return t.replace(Ue,\"\");if(!t||!(e=gi(e)))return t;var r=tt(t),i=tt(e),o=F(r,i),a=j(r,i)+1;return Ti(r,o,a).join(\"\")}function ks(t,e,n){if(t=Ac(t),t&&(n||e===it))return t.replace(je,\"\");if(!t||!(e=gi(e)))return t;var r=tt(t),i=j(r,tt(e))+1;return Ti(r,0,i).join(\"\")}function Es(t,e,n){if(t=Ac(t),t&&(n||e===it))return t.replace(Fe,\"\");if(!t||!(e=gi(e)))return t;var r=tt(t),i=F(r,tt(e));return Ti(r,i).join(\"\")}function Ts(t,e){var n=Tt,r=St;if(cc(e)){var i=\"separator\"in e?e.separator:i;n=\"length\"in e?Ec(e.length):n,r=\"omission\"in e?gi(e.omission):r}t=Ac(t);var o=t.length;if(z(t)){var a=tt(t);o=a.length}if(n>=o)return t;var u=n-J(r);if(u<1)return r;var c=a?Ti(a,0,u).join(\"\"):t.slice(0,u);if(i===it)return c+r;if(a&&(u+=c.length-u),Ep(i)){if(t.slice(u).search(i)){var s,l=c;for(i.global||(i=pl(i.source,Ac(Ye.exec(i))+\"g\")),i.lastIndex=0;s=i.exec(l);)var f=s.index;c=c.slice(0,f===it?u:f)}}else if(t.indexOf(gi(i),u)!=u){var p=c.lastIndexOf(i);p>-1&&(c=c.slice(0,p))}return c+r}function Ss(t){return t=Ac(t),t&&Ee.test(t)?t.replace(Me,wr):t}function Ps(t,e,n){return t=Ac(t),e=n?it:e,e===it?H(t)?rt(t):x(t):t.match(e)||[]}function Ns(t){var e=null==t?0:t.length,n=ko();return t=e?v(t,function(t){if(\"function\"!=typeof t[1])throw new dl(ct);return[n(t[0]),t[1]]}):[],oi(function(n){for(var r=-1;++r<e;){var i=t[r];if(u(i[0],this,n))return u(i[1],this,n)}})}function As(t){return Wn(Bn(t,pt))}function Os(t){return function(){return t}}function Is(t,e){return null==t||t!==t?e:t}function Ds(t){return t}function Rs(t){return Br(\"function\"==typeof t?t:Bn(t,pt))}function Ls(t){return qr(Bn(t,pt))}function Us(t,e){return Yr(t,Bn(e,pt))}function Fs(t,e,n){var r=Hc(e),i=ar(e,r);null!=n||cc(e)&&(i.length||!r.length)||(n=e,e=t,t=this,i=ar(e,Hc(e)));var o=!(cc(n)&&\"chain\"in n&&!n.chain),a=oc(t);return s(i,function(n){var r=e[n];t[n]=r,a&&(t.prototype[n]=function(){var e=this.__chain__;if(o||e){var n=t(this.__wrapped__),i=n.__actions__=Bi(this.__actions__);return i.push({func:r,args:arguments,thisArg:t}),n.__chain__=e,n}return r.apply(t,g([this.value()],arguments))})}),t}function js(){return ur._===this&&(ur._=kl),this}function Bs(){}function Ws(t){return t=Ec(t),oi(function(e){return $r(e,t)})}function Vs(t){return Bo(t)?S(ra(t)):Jr(t)}function zs(t){return function(e){return null==t?it:cr(t,e)}}function Hs(){return[]}function qs(){return!1}function Ys(){return{}}function Ks(){return\"\"}function Gs(){return!0}function $s(t,e){if(t=Ec(t),t<1||t>Rt)return[];var n=Ft,r=Xl(t,Ft);e=ko(e),t-=Ft;for(var i=I(r,e);++n<t;)e(n);return i}function Xs(t){return xp(t)?v(t,ra):bc(t)?[t]:Bi(Lf(Ac(t)))}function Zs(t){var e=++xl;return Ac(t)+e}function Qs(t){return t&&t.length?Gn(t,Ds,pr):it}function Js(t,e){return t&&t.length?Gn(t,ko(e,2),pr):it}function tl(t){return T(t,Ds)}function el(t,e){return T(t,ko(e,2))}function nl(t){return t&&t.length?Gn(t,Ds,zr):it}function rl(t,e){return t&&t.length?Gn(t,ko(e,2),zr):it}function il(t){return t&&t.length?O(t,Ds):0}function ol(t,e){return t&&t.length?O(t,ko(e,2)):0}e=null==e?ur:Mr.defaults(ur.Object(),e,Mr.pick(ur,$n));var al=e.Array,ul=e.Date,cl=e.Error,sl=e.Function,ll=e.Math,fl=e.Object,pl=e.RegExp,hl=e.String,dl=e.TypeError,vl=al.prototype,gl=sl.prototype,ml=fl.prototype,yl=e[\"__core-js_shared__\"],_l=gl.toString,bl=ml.hasOwnProperty,xl=0,wl=function(){var t=/[^.]+$/.exec(yl&&yl.keys&&yl.keys.IE_PROTO||\"\");return t?\"Symbol(src)_1.\"+t:\"\"}(),Cl=ml.toString,Ml=_l.call(fl),kl=ur._,El=pl(\"^\"+_l.call(bl).replace(Re,\"\\\\$&\").replace(/hasOwnProperty|(function).*?(?=\\\\\\()| for .+?(?=\\\\\\])/g,\"$1.*?\")+\"$\"),Tl=lr?e.Buffer:it,Sl=e.Symbol,Pl=e.Uint8Array,Nl=Tl?Tl.allocUnsafe:it,Al=K(fl.getPrototypeOf,fl),Ol=fl.create,Il=ml.propertyIsEnumerable,Dl=vl.splice,Rl=Sl?Sl.isConcatSpreadable:it,Ll=Sl?Sl.iterator:it,Ul=Sl?Sl.toStringTag:it,Fl=function(){try{var t=So(fl,\"defineProperty\");return t({},\"\",{}),t}catch(t){}}(),jl=e.clearTimeout!==ur.clearTimeout&&e.clearTimeout,Bl=ul&&ul.now!==ur.Date.now&&ul.now,Wl=e.setTimeout!==ur.setTimeout&&e.setTimeout,Vl=ll.ceil,zl=ll.floor,Hl=fl.getOwnPropertySymbols,ql=Tl?Tl.isBuffer:it,Yl=e.isFinite,Kl=vl.join,Gl=K(fl.keys,fl),$l=ll.max,Xl=ll.min,Zl=ul.now,Ql=e.parseInt,Jl=ll.random,tf=vl.reverse,ef=So(e,\"DataView\"),nf=So(e,\"Map\"),rf=So(e,\"Promise\"),of=So(e,\"Set\"),af=So(e,\"WeakMap\"),uf=So(fl,\"create\"),cf=af&&new af,sf={},lf=ia(ef),ff=ia(nf),pf=ia(rf),hf=ia(of),df=ia(af),vf=Sl?Sl.prototype:it,gf=vf?vf.valueOf:it,mf=vf?vf.toString:it,yf=function(){function t(){}return function(e){if(!cc(e))return{};if(Ol)return Ol(e);t.prototype=e;var n=new t;return t.prototype=it,n}}();n.templateSettings={escape:Se,evaluate:Pe,interpolate:Ne,variable:\"\",imports:{_:n}},n.prototype=r.prototype,n.prototype.constructor=n,i.prototype=yf(r.prototype),i.prototype.constructor=i,b.prototype=yf(r.prototype),b.prototype.constructor=b,nt.prototype.clear=ze,nt.prototype.delete=en,nt.prototype.get=nn,nt.prototype.has=rn,nt.prototype.set=on,an.prototype.clear=un,an.prototype.delete=cn,an.prototype.get=sn,an.prototype.has=ln,an.prototype.set=fn,pn.prototype.clear=hn,pn.prototype.delete=dn,pn.prototype.get=vn,pn.prototype.has=gn,pn.prototype.set=mn,yn.prototype.add=yn.prototype.push=_n,yn.prototype.has=bn,xn.prototype.clear=wn,xn.prototype.delete=Cn,xn.prototype.get=Mn,xn.prototype.has=kn,xn.prototype.set=En;var _f=Yi(nr),bf=Yi(or,!0),xf=Ki(),wf=Ki(!0),Cf=cf?function(t,e){return cf.set(t,e),t}:Ds,Mf=Fl?function(t,e){return Fl(t,\"toString\",{configurable:!0,enumerable:!1,value:Os(e),writable:!0})}:Ds,kf=oi,Ef=jl||function(t){return ur.clearTimeout(t)},Tf=of&&1/$(new of([,-0]))[1]==Dt?function(t){return new of(t)}:Bs,Sf=cf?function(t){return cf.get(t)}:Bs,Pf=Hl?function(t){return null==t?[]:(t=fl(t),p(Hl(t),function(e){return Il.call(t,e)}))}:Hs,Nf=Hl?function(t){for(var e=[];t;)g(e,Pf(t)),t=Al(t);return e}:Hs,Af=fr;(ef&&Af(new ef(new ArrayBuffer(1)))!=fe||nf&&Af(new nf)!=Zt||rf&&Af(rf.resolve())!=ee||of&&Af(new of)!=ie||af&&Af(new af)!=ce)&&(Af=function(t){var e=fr(t),n=e==te?t.constructor:it,r=n?ia(n):\"\";if(r)switch(r){case lf:return fe;case ff:return Zt;case pf:return ee;case hf:return ie;case df:return ce}return e});var Of=yl?oc:qs,If=ea(Cf),Df=Wl||function(t,e){return ur.setTimeout(t,e)},Rf=ea(Mf),Lf=Ko(function(t){var e=[];return Ie.test(t)&&e.push(\"\"),t.replace(De,function(t,n,r,i){e.push(r?i.replace(He,\"$1\"):n||t)}),e}),Uf=oi(function(t,e){return Zu(t)?Yn(t,er(e,1,Zu,!0)):[]}),Ff=oi(function(t,e){var n=ka(e);return Zu(n)&&(n=it),Zu(t)?Yn(t,er(e,1,Zu,!0),ko(n,2)):[]}),jf=oi(function(t,e){var n=ka(e);return Zu(n)&&(n=it),Zu(t)?Yn(t,er(e,1,Zu,!0),it,n):[]}),Bf=oi(function(t){var e=v(t,Mi);return e.length&&e[0]===t[0]?Er(e):[]}),Wf=oi(function(t){var e=ka(t),n=v(t,Mi);return e===ka(n)?e=it:n.pop(),n.length&&n[0]===t[0]?Er(n,ko(e,2)):[]}),Vf=oi(function(t){var e=ka(t),n=v(t,Mi);return e=\"function\"==typeof e?e:it,e&&n.pop(),n.length&&n[0]===t[0]?Er(n,it,e):[]}),zf=oi(Sa),Hf=bo(function(t,e){var n=null==t?0:t.length,r=Fn(t,e);return ei(t,v(e,function(t){return Fo(t,n)?+t:t}).sort(Li)),r}),qf=oi(function(t){return mi(er(t,1,Zu,!0))}),Yf=oi(function(t){var e=ka(t);return Zu(e)&&(e=it),mi(er(t,1,Zu,!0),ko(e,2))}),Kf=oi(function(t){var e=ka(t);return e=\"function\"==typeof e?e:it,mi(er(t,1,Zu,!0),it,e)}),Gf=oi(function(t,e){return Zu(t)?Yn(t,e):[]}),$f=oi(function(t){return wi(p(t,Zu))}),Xf=oi(function(t){var e=ka(t);return Zu(e)&&(e=it),wi(p(t,Zu),ko(e,2))}),Zf=oi(function(t){var e=ka(t);return e=\"function\"==typeof e?e:it,wi(p(t,Zu),it,e)}),Qf=oi(Xa),Jf=oi(function(t){var e=t.length,n=e>1?t[e-1]:it;return n=\"function\"==typeof n?(t.pop(),n):it,Za(t,n)}),tp=bo(function(t){var e=t.length,n=e?t[0]:0,r=this.__wrapped__,o=function(e){return Fn(e,t)};return!(e>1||this.__actions__.length)&&r instanceof b&&Fo(n)?(r=r.slice(n,+n+(e?1:0)),r.__actions__.push({func:nu,args:[o],thisArg:it}),new i(r,this.__chain__).thru(function(t){return e&&!t.length&&t.push(it),t})):this.thru(o)}),ep=Hi(function(t,e,n){bl.call(t,n)?++t[n]:Un(t,n,1)}),np=Ji(va),rp=Ji(ga),ip=Hi(function(t,e,n){bl.call(t,n)?t[n].push(e):Un(t,n,[e])}),op=oi(function(t,e,n){var r=-1,i=\"function\"==typeof e,o=Xu(t)?al(t.length):[];return _f(t,function(t){o[++r]=i?u(e,t,n):Sr(t,e,n)}),o}),ap=Hi(function(t,e,n){Un(t,n,e)}),up=Hi(function(t,e,n){t[n?0:1].push(e)},function(){return[[],[]]}),cp=oi(function(t,e){if(null==t)return[];var n=e.length;return n>1&&jo(t,e[0],e[1])?e=[]:n>2&&jo(e[0],e[1],e[2])&&(e=[e[0]]),Xr(t,er(e,1),[])}),sp=Bl||function(){return ur.Date.now()},lp=oi(function(t,e,n){var r=mt;if(n.length){var i=G(n,Mo(lp));r|=wt}return po(t,r,e,n,i)}),fp=oi(function(t,e,n){var r=mt|yt;if(n.length){var i=G(n,Mo(fp));r|=wt}return po(e,r,t,n,i)}),pp=oi(function(t,e){return qn(t,1,e)}),hp=oi(function(t,e,n){return qn(t,Sc(e)||0,n)});Ru.Cache=pn;var dp=kf(function(t,e){e=1==e.length&&xp(e[0])?v(e[0],R(ko())):v(er(e,1),R(ko()));var n=e.length;return oi(function(r){for(var i=-1,o=Xl(r.length,n);++i<o;)r[i]=e[i].call(this,r[i]);return u(t,this,r)})}),vp=oi(function(t,e){var n=G(e,Mo(vp));return po(t,wt,it,e,n)}),gp=oi(function(t,e){var n=G(e,Mo(gp));return po(t,Ct,it,e,n)}),mp=bo(function(t,e){return po(t,kt,it,it,it,e)}),yp=co(pr),_p=co(function(t,e){return t>=e}),bp=Pr(function(){return arguments}())?Pr:function(t){return sc(t)&&bl.call(t,\"callee\")&&!Il.call(t,\"callee\")},xp=al.isArray,wp=hr?R(hr):Nr,Cp=ql||qs,Mp=dr?R(dr):Ar,kp=vr?R(vr):Dr,Ep=gr?R(gr):Ur,Tp=mr?R(mr):Fr,Sp=yr?R(yr):jr,Pp=co(zr),Np=co(function(t,e){return t<=e}),Ap=qi(function(t,e){if(Ho(e)||Xu(e))return void Wi(e,Hc(e),t);for(var n in e)bl.call(e,n)&&On(t,n,e[n])}),Op=qi(function(t,e){Wi(e,qc(e),t)}),Ip=qi(function(t,e,n,r){Wi(e,qc(e),t,r)}),Dp=qi(function(t,e,n,r){Wi(e,Hc(e),t,r)}),Rp=bo(Fn),Lp=oi(function(t){return t.push(it,ho),u(Ip,it,t)}),Up=oi(function(t){return t.push(it,vo),u(Vp,it,t)}),Fp=no(function(t,e,n){t[e]=n},Os(Ds)),jp=no(function(t,e,n){bl.call(t,e)?t[e].push(n):t[e]=[n]},ko),Bp=oi(Sr),Wp=qi(function(t,e,n){Kr(t,e,n)}),Vp=qi(function(t,e,n,r){Kr(t,e,n,r)}),zp=bo(function(t,e){var n={};if(null==t)return n;var r=!1;e=v(e,function(e){return e=Ei(e,t),r||(r=e.length>1),e}),Wi(t,wo(t),n),r&&(n=Bn(n,pt|ht|dt,go));for(var i=e.length;i--;)yi(n,e[i]);return n}),Hp=bo(function(t,e){return null==t?{}:Zr(t,e)}),qp=fo(Hc),Yp=fo(qc),Kp=Xi(function(t,e,n){return e=e.toLowerCase(),t+(n?cs(e):e)}),Gp=Xi(function(t,e,n){return t+(n?\"-\":\"\")+e.toLowerCase()}),$p=Xi(function(t,e,n){return t+(n?\" \":\"\")+e.toLowerCase()}),Xp=$i(\"toLowerCase\"),Zp=Xi(function(t,e,n){return t+(n?\"_\":\"\")+e.toLowerCase()}),Qp=Xi(function(t,e,n){return t+(n?\" \":\"\")+th(e)}),Jp=Xi(function(t,e,n){return t+(n?\" \":\"\")+e.toUpperCase()}),th=$i(\"toUpperCase\"),eh=oi(function(t,e){try{return u(t,it,e)}catch(t){return rc(t)?t:new cl(t)}}),nh=bo(function(t,e){return s(e,function(e){e=ra(e),Un(t,e,lp(t[e],t))}),t}),rh=to(),ih=to(!0),oh=oi(function(t,e){return function(n){return Sr(n,t,e)}}),ah=oi(function(t,e){return function(n){return Sr(t,n,e)}}),uh=io(v),ch=io(f),sh=io(_),lh=uo(),fh=uo(!0),ph=ro(function(t,e){return t+e},0),hh=lo(\"ceil\"),dh=ro(function(t,e){return t/e},1),vh=lo(\"floor\"),gh=ro(function(t,e){return t*e},1),mh=lo(\"round\"),yh=ro(function(t,e){return t-e},0);return n.after=Su,n.ary=Pu,n.assign=Ap,n.assignIn=Op,n.assignInWith=Ip,n.assignWith=Dp,n.at=Rp,n.before=Nu,n.bind=lp,n.bindAll=nh,n.bindKey=fp,n.castArray=zu,n.chain=tu,n.chunk=ua,n.compact=ca,n.concat=sa,n.cond=Ns,n.conforms=As,n.constant=Os,n.countBy=ep,n.create=Oc,n.curry=Au,n.curryRight=Ou,n.debounce=Iu,n.defaults=Lp,n.defaultsDeep=Up,n.defer=pp,n.delay=hp,n.difference=Uf,n.differenceBy=Ff,n.differenceWith=jf,n.drop=la,n.dropRight=fa,n.dropRightWhile=pa,n.dropWhile=ha,n.fill=da,n.filter=fu,n.flatMap=pu,n.flatMapDeep=hu,n.flatMapDepth=du,n.flatten=ma,n.flattenDeep=ya,n.flattenDepth=_a,n.flip=Du,n.flow=rh,n.flowRight=ih,n.fromPairs=ba,n.functions=jc,n.functionsIn=Bc,n.groupBy=ip,n.initial=Ca,n.intersection=Bf,n.intersectionBy=Wf,n.intersectionWith=Vf,n.invert=Fp,n.invertBy=jp,n.invokeMap=op,n.iteratee=Rs,n.keyBy=ap,n.keys=Hc,n.keysIn=qc,n.map=yu,n.mapKeys=Yc,n.mapValues=Kc,n.matches=Ls,n.matchesProperty=Us,n.memoize=Ru,n.merge=Wp,n.mergeWith=Vp,n.method=oh,n.methodOf=ah,n.mixin=Fs,n.negate=Lu,n.nthArg=Ws,n.omit=zp,n.omitBy=Gc,n.once=Uu,n.orderBy=_u,n.over=uh,n.overArgs=dp,n.overEvery=ch,n.overSome=sh,n.partial=vp,n.partialRight=gp,n.partition=up,n.pick=Hp,n.pickBy=$c,n.property=Vs,n.propertyOf=zs,n.pull=zf,n.pullAll=Sa,n.pullAllBy=Pa,n.pullAllWith=Na,n.pullAt=Hf,n.range=lh,n.rangeRight=fh,n.rearg=mp,n.reject=wu,n.remove=Aa,n.rest=Fu,n.reverse=Oa,n.sampleSize=Mu,n.set=Zc,n.setWith=Qc,n.shuffle=ku,n.slice=Ia,n.sortBy=cp,n.sortedUniq=Ba,n.sortedUniqBy=Wa,n.split=_s,n.spread=ju,n.tail=Va,n.take=za,n.takeRight=Ha,n.takeRightWhile=qa,n.takeWhile=Ya,n.tap=eu,n.throttle=Bu,n.thru=nu,n.toArray=Mc,n.toPairs=qp,n.toPairsIn=Yp,n.toPath=Xs,n.toPlainObject=Pc,n.transform=Jc,n.unary=Wu,n.union=qf,n.unionBy=Yf,n.unionWith=Kf,n.uniq=Ka,n.uniqBy=Ga,n.uniqWith=$a,n.unset=ts,n.unzip=Xa,n.unzipWith=Za,n.update=es,n.updateWith=ns,n.values=rs,n.valuesIn=is,n.without=Gf,n.words=Ps,n.wrap=Vu,n.xor=$f,n.xorBy=Xf,n.xorWith=Zf,n.zip=Qf,n.zipObject=Qa,n.zipObjectDeep=Ja,n.zipWith=Jf,n.entries=qp,n.entriesIn=Yp,n.extend=Op,n.extendWith=Ip,Fs(n,n),n.add=ph,n.attempt=eh,n.camelCase=Kp,n.capitalize=cs,n.ceil=hh,n.clamp=os,n.clone=Hu,n.cloneDeep=Yu,n.cloneDeepWith=Ku,n.cloneWith=qu,n.conformsTo=Gu,n.deburr=ss,n.defaultTo=Is,n.divide=dh,n.endsWith=ls,n.eq=$u,n.escape=fs,n.escapeRegExp=ps,n.every=lu,n.find=np,n.findIndex=va,n.findKey=Ic,n.findLast=rp,n.findLastIndex=ga,n.findLastKey=Dc,n.floor=vh,n.forEach=vu,n.forEachRight=gu,n.forIn=Rc,n.forInRight=Lc,n.forOwn=Uc,n.forOwnRight=Fc,n.get=Wc,n.gt=yp,n.gte=_p,n.has=Vc,n.hasIn=zc,n.head=xa,n.identity=Ds,n.includes=mu,n.indexOf=wa,n.inRange=as,n.invoke=Bp,n.isArguments=bp,n.isArray=xp,n.isArrayBuffer=wp,n.isArrayLike=Xu,n.isArrayLikeObject=Zu,n.isBoolean=Qu,n.isBuffer=Cp,n.isDate=Mp,n.isElement=Ju,n.isEmpty=tc,n.isEqual=ec,n.isEqualWith=nc,n.isError=rc,n.isFinite=ic,n.isFunction=oc,n.isInteger=ac,n.isLength=uc,n.isMap=kp,n.isMatch=lc,n.isMatchWith=fc,n.isNaN=pc,n.isNative=hc,n.isNil=vc,n.isNull=dc,n.isNumber=gc,n.isObject=cc,n.isObjectLike=sc,n.isPlainObject=mc,n.isRegExp=Ep,n.isSafeInteger=yc,n.isSet=Tp,n.isString=_c,n.isSymbol=bc,n.isTypedArray=Sp,n.isUndefined=xc,n.isWeakMap=wc,n.isWeakSet=Cc,n.join=Ma,n.kebabCase=Gp,n.last=ka,n.lastIndexOf=Ea,n.lowerCase=$p,n.lowerFirst=Xp,n.lt=Pp,n.lte=Np,n.max=Qs,n.maxBy=Js,n.mean=tl,n.meanBy=el,n.min=nl,n.minBy=rl,n.stubArray=Hs,n.stubFalse=qs,n.stubObject=Ys,n.stubString=Ks,n.stubTrue=Gs,n.multiply=gh,n.nth=Ta,n.noConflict=js,n.noop=Bs,n.now=sp,n.pad=hs,n.padEnd=ds,n.padStart=vs,n.parseInt=gs,n.random=us,n.reduce=bu,n.reduceRight=xu,n.repeat=ms,n.replace=ys,n.result=Xc,n.round=mh,n.runInContext=t,n.sample=Cu,n.size=Eu,n.snakeCase=Zp,n.some=Tu,n.sortedIndex=Da,n.sortedIndexBy=Ra,n.sortedIndexOf=La,n.sortedLastIndex=Ua,n.sortedLastIndexBy=Fa,n.sortedLastIndexOf=ja,n.startCase=Qp,n.startsWith=bs,n.subtract=yh,n.sum=il,n.sumBy=ol,n.template=xs,n.times=$s,n.toFinite=kc,n.toInteger=Ec,n.toLength=Tc,n.toLower=ws,n.toNumber=Sc,n.toSafeInteger=Nc,n.toString=Ac,n.toUpper=Cs,n.trim=Ms,n.trimEnd=ks,n.trimStart=Es,n.truncate=Ts,n.unescape=Ss,n.uniqueId=Zs,n.upperCase=Jp,n.upperFirst=th,n.each=vu,n.eachRight=gu,n.first=xa,Fs(n,function(){var t={};return nr(n,function(e,r){bl.call(n.prototype,r)||(t[r]=e)}),t}(),{chain:!1}),n.VERSION=ot,s([\"bind\",\"bindKey\",\"curry\",\"curryRight\",\"partial\",\"partialRight\"],function(t){n[t].placeholder=n}),s([\"drop\",\"take\"],function(t,e){b.prototype[t]=function(n){n=n===it?1:$l(Ec(n),0);var r=this.__filtered__&&!e?new b(this):this.clone();return r.__filtered__?r.__takeCount__=Xl(n,r.__takeCount__):r.__views__.push({size:Xl(n,Ft),type:t+(r.__dir__<0?\"Right\":\"\")}),r},b.prototype[t+\"Right\"]=function(e){return this.reverse()[t](e).reverse()}}),s([\"filter\",\"map\",\"takeWhile\"],function(t,e){var n=e+1,r=n==At||n==It;b.prototype[t]=function(t){var e=this.clone();return e.__iteratees__.push({iteratee:ko(t,3),type:n}),e.__filtered__=e.__filtered__||r,e}}),s([\"head\",\"last\"],function(t,e){var n=\"take\"+(e?\"Right\":\"\");b.prototype[t]=function(){return this[n](1).value()[0]}}),s([\"initial\",\"tail\"],function(t,e){var n=\"drop\"+(e?\"\":\"Right\");b.prototype[t]=function(){return this.__filtered__?new b(this):this[n](1)}}),b.prototype.compact=function(){return this.filter(Ds)},b.prototype.find=function(t){return this.filter(t).head()},b.prototype.findLast=function(t){return this.reverse().find(t)},b.prototype.invokeMap=oi(function(t,e){return\"function\"==typeof t?new b(this):this.map(function(n){return Sr(n,t,e)})}),b.prototype.reject=function(t){return this.filter(Lu(ko(t)))},b.prototype.slice=function(t,e){t=Ec(t);var n=this;return n.__filtered__&&(t>0||e<0)?new b(n):(t<0?n=n.takeRight(-t):t&&(n=n.drop(t)),e!==it&&(e=Ec(e),n=e<0?n.dropRight(-e):n.take(e-t)),n)},b.prototype.takeRightWhile=function(t){return this.reverse().takeWhile(t).reverse()},b.prototype.toArray=function(){return this.take(Ft)},nr(b.prototype,function(t,e){var r=/^(?:filter|find|map|reject)|While$/.test(e),o=/^(?:head|last)$/.test(e),a=n[o?\"take\"+(\"last\"==e?\"Right\":\"\"):e],u=o||/^find/.test(e);a&&(n.prototype[e]=function(){var e=this.__wrapped__,c=o?[1]:arguments,s=e instanceof b,l=c[0],f=s||xp(e),p=function(t){var e=a.apply(n,g([t],c));return o&&h?e[0]:e};f&&r&&\"function\"==typeof l&&1!=l.length&&(s=f=!1);var h=this.__chain__,d=!!this.__actions__.length,v=u&&!h,m=s&&!d;if(!u&&f){e=m?e:new b(this);var y=t.apply(e,c);return y.__actions__.push({func:nu,args:[p],thisArg:it}),new i(y,h)}return v&&m?t.apply(this,c):(y=this.thru(p),v?o?y.value()[0]:y.value():y)})}),s([\"pop\",\"push\",\"shift\",\"sort\",\"splice\",\"unshift\"],function(t){var e=vl[t],r=/^(?:push|sort|unshift)$/.test(t)?\"tap\":\"thru\",i=/^(?:pop|shift)$/.test(t);n.prototype[t]=function(){var t=arguments;if(i&&!this.__chain__){var n=this.value();return e.apply(xp(n)?n:[],t)}return this[r](function(n){return e.apply(xp(n)?n:[],t)})}}),nr(b.prototype,function(t,e){var r=n[e];if(r){var i=r.name+\"\",o=sf[i]||(sf[i]=[]);o.push({name:e,func:r})}}),sf[eo(it,yt).name]=[{name:\"wrapper\",func:it}],b.prototype.clone=P,b.prototype.reverse=Z,b.prototype.value=et,n.prototype.at=tp,n.prototype.chain=ru,n.prototype.commit=iu,n.prototype.next=ou,n.prototype.plant=uu,n.prototype.reverse=cu,n.prototype.toJSON=n.prototype.valueOf=n.prototype.value=su,n.prototype.first=n.prototype.head,Ll&&(n.prototype[Ll]=au),n},Mr=Cr();ur._=Mr,i=function(){return Mr}.call(e,n,e,r),!(i!==it&&(r.exports=i))}).call(this)}).call(e,n(99),n(100)(t))},function(t,e,n){\"use strict\";var r={remove:function(t){t._reactInternalInstance=void 0},get:function(t){return t._reactInternalInstance},has:function(t){return void 0!==t._reactInternalInstance},set:function(t,e){t._reactInternalInstance=e}};t.exports=r},function(t,e,n){\"use strict\";t.exports=n(26)},function(t,e,n){\"use strict\";var r=n(61);e.a=function(t){return t=n.i(r.a)(Math.abs(t)),t?t[1]:NaN}},function(t,e,n){\"use strict\";e.a=function(t,e){return t=+t,e-=t,function(n){return t+e*n}}},function(t,e,n){\"use strict\";var r=n(228);n.d(e,\"a\",function(){return r.a})},function(t,e,n){\"use strict\";function r(t,e){return(e-=t=+t)?function(n){return(n-t)/e}:n.i(h.a)(e)}function i(t){return function(e,n){var r=t(e=+e,n=+n);return function(t){return t<=e?0:t>=n?1:r(t)}}}function o(t){return function(e,n){var r=t(e=+e,n=+n);return function(t){return t<=0?e:t>=1?n:r(t)}}}function a(t,e,n,r){var i=t[0],o=t[1],a=e[0],u=e[1];return o<i?(i=n(o,i),a=r(u,a)):(i=n(i,o),a=r(a,u)),function(t){return a(i(t))}}function u(t,e,r,i){var o=Math.min(t.length,e.length)-1,a=new Array(o),u=new Array(o),c=-1;for(t[o]<t[0]&&(t=t.slice().reverse(),e=e.slice().reverse());++c<o;)a[c]=r(t[c],t[c+1]),u[c]=i(e[c],e[c+1]);return function(e){var r=n.i(l.c)(t,e,1,o)-1;return u[r](a[r](e))}}function c(t,e){return e.domain(t.domain()).range(t.range()).interpolate(t.interpolate()).clamp(t.clamp())}function s(t,e){function n(){return s=Math.min(g.length,m.length)>2?u:a,l=h=null,c}function c(e){return(l||(l=s(g,m,_?i(t):t,y)))(+e)}var s,l,h,g=v,m=v,y=f.b,_=!1;return c.invert=function(t){return(h||(h=s(m,g,r,_?o(e):e)))(+t)},c.domain=function(t){return arguments.length?(g=p.a.call(t,d.a),n()):g.slice()},c.range=function(t){return arguments.length?(m=p.b.call(t),n()):m.slice()},c.rangeRound=function(t){return m=p.b.call(t),y=f.c,n()},c.clamp=function(t){return arguments.length?(_=!!t,n()):_},c.interpolate=function(t){return arguments.length?(y=t,n()):y},n()}var l=n(12),f=n(31),p=n(16),h=n(65),d=n(126);e.b=r,e.c=c,e.a=s;var v=[0,1]},function(t,e,n){\"use strict\";function r(t,e,n){t._context.bezierCurveTo((2*t._x0+t._x1)/3,(2*t._y0+t._y1)/3,(t._x0+2*t._x1)/3,(t._y0+2*t._y1)/3,(t._x0+4*t._x1+e)/6,(t._y0+4*t._y1+n)/6)}function i(t){this._context=t}e.c=r,e.b=i,i.prototype={\n",
       "areaStart:function(){this._line=0},areaEnd:function(){this._line=NaN},lineStart:function(){this._x0=this._x1=this._y0=this._y1=NaN,this._point=0},lineEnd:function(){switch(this._point){case 3:r(this,this._x1,this._y1);case 2:this._context.lineTo(this._x1,this._y1)}(this._line||0!==this._line&&1===this._point)&&this._context.closePath(),this._line=1-this._line},point:function(t,e){switch(t=+t,e=+e,this._point){case 0:this._point=1,this._line?this._context.lineTo(t,e):this._context.moveTo(t,e);break;case 1:this._point=2;break;case 2:this._point=3,this._context.lineTo((5*this._x0+this._x1)/6,(5*this._y0+this._y1)/6);default:r(this,t,e)}this._x0=this._x1,this._x1=t,this._y0=this._y1,this._y1=e}},e.a=function(t){return new i(t)}},function(t,e,n){\"use strict\";function r(t,e,n){t._context.bezierCurveTo(t._x1+t._k*(t._x2-t._x0),t._y1+t._k*(t._y2-t._y0),t._x2+t._k*(t._x1-e),t._y2+t._k*(t._y1-n),t._x2,t._y2)}function i(t,e){this._context=t,this._k=(1-e)/6}e.c=r,e.b=i,i.prototype={areaStart:function(){this._line=0},areaEnd:function(){this._line=NaN},lineStart:function(){this._x0=this._x1=this._x2=this._y0=this._y1=this._y2=NaN,this._point=0},lineEnd:function(){switch(this._point){case 2:this._context.lineTo(this._x2,this._y2);break;case 3:r(this,this._x1,this._y1)}(this._line||0!==this._line&&1===this._point)&&this._context.closePath(),this._line=1-this._line},point:function(t,e){switch(t=+t,e=+e,this._point){case 0:this._point=1,this._line?this._context.lineTo(t,e):this._context.moveTo(t,e);break;case 1:this._point=2,this._x1=t,this._y1=e;break;case 2:this._point=3;default:r(this,t,e)}this._x0=this._x1,this._x1=this._x2,this._x2=t,this._y0=this._y1,this._y1=this._y2,this._y2=e}},e.a=function t(e){function n(t){return new i(t,e)}return n.tension=function(e){return t(+e)},n}(0)},function(t,e,n){\"use strict\";function r(t){this._context=t}r.prototype={areaStart:function(){this._line=0},areaEnd:function(){this._line=NaN},lineStart:function(){this._point=0},lineEnd:function(){(this._line||0!==this._line&&1===this._point)&&this._context.closePath(),this._line=1-this._line},point:function(t,e){switch(t=+t,e=+e,this._point){case 0:this._point=1,this._line?this._context.lineTo(t,e):this._context.moveTo(t,e);break;case 1:this._point=2;default:this._context.lineTo(t,e)}}},e.a=function(t){return new r(t)}},function(t,e,n){\"use strict\";e.a=function(){}},function(t,e,n){\"use strict\";function r(t){return\"topMouseUp\"===t||\"topTouchEnd\"===t||\"topTouchCancel\"===t}function i(t){return\"topMouseMove\"===t||\"topTouchMove\"===t}function o(t){return\"topMouseDown\"===t||\"topTouchStart\"===t}function a(t,e,n,r){var i=t.type||\"unknown-event\";t.currentTarget=m.getNodeFromInstance(r),e?v.invokeGuardedCallbackWithCatch(i,n,t):v.invokeGuardedCallback(i,n,t),t.currentTarget=null}function u(t,e){var n=t._dispatchListeners,r=t._dispatchInstances;if(Array.isArray(n))for(var i=0;i<n.length&&!t.isPropagationStopped();i++)a(t,e,n[i],r[i]);else n&&a(t,e,n,r);t._dispatchListeners=null,t._dispatchInstances=null}function c(t){var e=t._dispatchListeners,n=t._dispatchInstances;if(Array.isArray(e)){for(var r=0;r<e.length&&!t.isPropagationStopped();r++)if(e[r](t,n[r]))return n[r]}else if(e&&e(t,n))return n;return null}function s(t){var e=c(t);return t._dispatchInstances=null,t._dispatchListeners=null,e}function l(t){var e=t._dispatchListeners,n=t._dispatchInstances;Array.isArray(e)?d(\"103\"):void 0,t.currentTarget=e?m.getNodeFromInstance(n):null;var r=e?e(t):null;return t.currentTarget=null,t._dispatchListeners=null,t._dispatchInstances=null,r}function f(t){return!!t._dispatchListeners}var p,h,d=n(2),v=n(87),g=(n(0),n(1),{injectComponentTree:function(t){p=t},injectTreeTraversal:function(t){h=t}}),m={isEndish:r,isMoveish:i,isStartish:o,executeDirectDispatch:l,executeDispatchesInOrder:u,executeDispatchesInOrderStopAtTrue:s,hasDispatches:f,getInstanceFromNode:function(t){return p.getInstanceFromNode(t)},getNodeFromInstance:function(t){return p.getNodeFromInstance(t)},isAncestor:function(t,e){return h.isAncestor(t,e)},getLowestCommonAncestor:function(t,e){return h.getLowestCommonAncestor(t,e)},getParentInstance:function(t){return h.getParentInstance(t)},traverseTwoPhase:function(t,e,n){return h.traverseTwoPhase(t,e,n)},traverseEnterLeave:function(t,e,n,r,i){return h.traverseEnterLeave(t,e,n,r,i)},injection:g};t.exports=m},function(t,e,n){\"use strict\";function r(t){return Object.prototype.hasOwnProperty.call(t,v)||(t[v]=h++,f[t[v]]={}),f[t[v]]}var i,o=n(3),a=n(83),u=n(360),c=n(89),s=n(393),l=n(94),f={},p=!1,h=0,d={topAbort:\"abort\",topAnimationEnd:s(\"animationend\")||\"animationend\",topAnimationIteration:s(\"animationiteration\")||\"animationiteration\",topAnimationStart:s(\"animationstart\")||\"animationstart\",topBlur:\"blur\",topCanPlay:\"canplay\",topCanPlayThrough:\"canplaythrough\",topChange:\"change\",topClick:\"click\",topCompositionEnd:\"compositionend\",topCompositionStart:\"compositionstart\",topCompositionUpdate:\"compositionupdate\",topContextMenu:\"contextmenu\",topCopy:\"copy\",topCut:\"cut\",topDoubleClick:\"dblclick\",topDrag:\"drag\",topDragEnd:\"dragend\",topDragEnter:\"dragenter\",topDragExit:\"dragexit\",topDragLeave:\"dragleave\",topDragOver:\"dragover\",topDragStart:\"dragstart\",topDrop:\"drop\",topDurationChange:\"durationchange\",topEmptied:\"emptied\",topEncrypted:\"encrypted\",topEnded:\"ended\",topError:\"error\",topFocus:\"focus\",topInput:\"input\",topKeyDown:\"keydown\",topKeyPress:\"keypress\",topKeyUp:\"keyup\",topLoadedData:\"loadeddata\",topLoadedMetadata:\"loadedmetadata\",topLoadStart:\"loadstart\",topMouseDown:\"mousedown\",topMouseMove:\"mousemove\",topMouseOut:\"mouseout\",topMouseOver:\"mouseover\",topMouseUp:\"mouseup\",topPaste:\"paste\",topPause:\"pause\",topPlay:\"play\",topPlaying:\"playing\",topProgress:\"progress\",topRateChange:\"ratechange\",topScroll:\"scroll\",topSeeked:\"seeked\",topSeeking:\"seeking\",topSelectionChange:\"selectionchange\",topStalled:\"stalled\",topSuspend:\"suspend\",topTextInput:\"textInput\",topTimeUpdate:\"timeupdate\",topTouchCancel:\"touchcancel\",topTouchEnd:\"touchend\",topTouchMove:\"touchmove\",topTouchStart:\"touchstart\",topTransitionEnd:s(\"transitionend\")||\"transitionend\",topVolumeChange:\"volumechange\",topWaiting:\"waiting\",topWheel:\"wheel\"},v=\"_reactListenersID\"+String(Math.random()).slice(2),g=o({},u,{ReactEventListener:null,injection:{injectReactEventListener:function(t){t.setHandleTopLevel(g.handleTopLevel),g.ReactEventListener=t}},setEnabled:function(t){g.ReactEventListener&&g.ReactEventListener.setEnabled(t)},isEnabled:function(){return!(!g.ReactEventListener||!g.ReactEventListener.isEnabled())},listenTo:function(t,e){for(var n=e,i=r(n),o=a.registrationNameDependencies[t],u=0;u<o.length;u++){var c=o[u];i.hasOwnProperty(c)&&i[c]||(\"topWheel\"===c?l(\"wheel\")?g.ReactEventListener.trapBubbledEvent(\"topWheel\",\"wheel\",n):l(\"mousewheel\")?g.ReactEventListener.trapBubbledEvent(\"topWheel\",\"mousewheel\",n):g.ReactEventListener.trapBubbledEvent(\"topWheel\",\"DOMMouseScroll\",n):\"topScroll\"===c?l(\"scroll\",!0)?g.ReactEventListener.trapCapturedEvent(\"topScroll\",\"scroll\",n):g.ReactEventListener.trapBubbledEvent(\"topScroll\",\"scroll\",g.ReactEventListener.WINDOW_HANDLE):\"topFocus\"===c||\"topBlur\"===c?(l(\"focus\",!0)?(g.ReactEventListener.trapCapturedEvent(\"topFocus\",\"focus\",n),g.ReactEventListener.trapCapturedEvent(\"topBlur\",\"blur\",n)):l(\"focusin\")&&(g.ReactEventListener.trapBubbledEvent(\"topFocus\",\"focusin\",n),g.ReactEventListener.trapBubbledEvent(\"topBlur\",\"focusout\",n)),i.topBlur=!0,i.topFocus=!0):d.hasOwnProperty(c)&&g.ReactEventListener.trapBubbledEvent(c,d[c],n),i[c]=!0)}},trapBubbledEvent:function(t,e,n){return g.ReactEventListener.trapBubbledEvent(t,e,n)},trapCapturedEvent:function(t,e,n){return g.ReactEventListener.trapCapturedEvent(t,e,n)},supportsEventPageXY:function(){if(!document.createEvent)return!1;var t=document.createEvent(\"MouseEvent\");return null!=t&&\"pageX\"in t},ensureScrollValueMonitoring:function(){if(void 0===i&&(i=g.supportsEventPageXY()),!i&&!p){var t=c.refreshScrollValues;g.ReactEventListener.monitorScrollValue(t),p=!0}}});t.exports=g},function(t,e,n){\"use strict\";function r(t,e,n,r){return i.call(this,t,e,n,r)}var i=n(25),o=n(89),a=n(92),u={screenX:null,screenY:null,clientX:null,clientY:null,ctrlKey:null,shiftKey:null,altKey:null,metaKey:null,getModifierState:a,button:function(t){var e=t.button;return\"which\"in t?e:2===e?2:4===e?1:0},buttons:null,relatedTarget:function(t){return t.relatedTarget||(t.fromElement===t.srcElement?t.toElement:t.fromElement)},pageX:function(t){return\"pageX\"in t?t.pageX:t.clientX+o.currentScrollLeft},pageY:function(t){return\"pageY\"in t?t.pageY:t.clientY+o.currentScrollTop}};i.augmentClass(r,u),t.exports=r},function(t,e,n){\"use strict\";var r=n(2),i=(n(0),{}),o={reinitializeTransaction:function(){this.transactionWrappers=this.getTransactionWrappers(),this.wrapperInitData?this.wrapperInitData.length=0:this.wrapperInitData=[],this._isInTransaction=!1},_isInTransaction:!1,getTransactionWrappers:null,isInTransaction:function(){return!!this._isInTransaction},perform:function(t,e,n,i,o,a,u,c){this.isInTransaction()?r(\"27\"):void 0;var s,l;try{this._isInTransaction=!0,s=!0,this.initializeAll(0),l=t.call(e,n,i,o,a,u,c),s=!1}finally{try{if(s)try{this.closeAll(0)}catch(t){}else this.closeAll(0)}finally{this._isInTransaction=!1}}return l},initializeAll:function(t){for(var e=this.transactionWrappers,n=t;n<e.length;n++){var r=e[n];try{this.wrapperInitData[n]=i,this.wrapperInitData[n]=r.initialize?r.initialize.call(this):null}finally{if(this.wrapperInitData[n]===i)try{this.initializeAll(n+1)}catch(t){}}}},closeAll:function(t){this.isInTransaction()?void 0:r(\"28\");for(var e=this.transactionWrappers,n=t;n<e.length;n++){var o,a=e[n],u=this.wrapperInitData[n];try{o=!0,u!==i&&a.close&&a.close.call(this,u),o=!1}finally{if(o)try{this.closeAll(n+1)}catch(t){}}}this.wrapperInitData.length=0}};t.exports=o},function(t,e,n){\"use strict\";function r(t){var e=\"\"+t,n=o.exec(e);if(!n)return e;var r,i=\"\",a=0,u=0;for(a=n.index;a<e.length;a++){switch(e.charCodeAt(a)){case 34:r=\"&quot;\";break;case 38:r=\"&amp;\";break;case 39:r=\"&#x27;\";break;case 60:r=\"&lt;\";break;case 62:r=\"&gt;\";break;default:continue}u!==a&&(i+=e.substring(u,a)),u=a+1,i+=r}return u!==a?i+e.substring(u,a):i}function i(t){return\"boolean\"==typeof t||\"number\"==typeof t?\"\"+t:r(t)}var o=/[\"'&<>]/;t.exports=i},function(t,e,n){\"use strict\";var r,i=n(6),o=n(82),a=/^[ \\r\\n\\t\\f]/,u=/<(!--|link|noscript|meta|script|style)[ \\r\\n\\t\\f\\/>]/,c=n(90),s=c(function(t,e){if(t.namespaceURI!==o.svg||\"innerHTML\"in t)t.innerHTML=e;else{r=r||document.createElement(\"div\"),r.innerHTML=\"<svg>\"+e+\"</svg>\";for(var n=r.firstChild;n.firstChild;)t.appendChild(n.firstChild)}});if(i.canUseDOM){var l=document.createElement(\"div\");l.innerHTML=\" \",\"\"===l.innerHTML&&(s=function(t,e){if(t.parentNode&&t.parentNode.replaceChild(t,t),a.test(e)||\"<\"===e[0]&&u.test(e)){t.innerHTML=String.fromCharCode(65279)+e;var n=t.firstChild;1===n.data.length?t.removeChild(n):n.deleteData(0,1)}else t.innerHTML=e}),l=null}t.exports=s},function(t,e,n){\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.default={colors:{RdBu:[\"rgb(255, 13, 87)\",\"rgb(30, 136, 229)\"],GnPR:[\"rgb(24, 196, 93)\",\"rgb(124, 82, 255)\"],CyPU:[\"#0099C6\",\"#990099\"],PkYg:[\"#DD4477\",\"#66AA00\"],DrDb:[\"#B82E2E\",\"#316395\"],LpLb:[\"#994499\",\"#22AA99\"],YlDp:[\"#AAAA11\",\"#6633CC\"],OrId:[\"#E67300\",\"#3E0099\"]},gray:\"#777\"}},function(t,e,n){\"use strict\";var r=n(29);e.a=function(t,e,n){if(null==n&&(n=r.a),i=t.length){if((e=+e)<=0||i<2)return+n(t[0],0,t);if(e>=1)return+n(t[i-1],i-1,t);var i,o=(i-1)*e,a=Math.floor(o),u=+n(t[a],a,t),c=+n(t[a+1],a+1,t);return u+(c-u)*(o-a)}}},function(t,e,n){\"use strict\";function r(){}function i(t,e){var n=new r;if(t instanceof r)t.each(function(t,e){n.set(e,t)});else if(Array.isArray(t)){var i,o=-1,a=t.length;if(null==e)for(;++o<a;)n.set(o,t[o]);else for(;++o<a;)n.set(e(i=t[o],o,t),i)}else if(t)for(var u in t)n.set(u,t[u]);return n}n.d(e,\"b\",function(){return o});var o=\"$\";r.prototype=i.prototype={constructor:r,has:function(t){return o+t in this},get:function(t){return this[o+t]},set:function(t,e){return this[o+t]=e,this},remove:function(t){var e=o+t;return e in this&&delete this[e]},clear:function(){for(var t in this)t[0]===o&&delete this[t]},keys:function(){var t=[];for(var e in this)e[0]===o&&t.push(e.slice(1));return t},values:function(){var t=[];for(var e in this)e[0]===o&&t.push(this[e]);return t},entries:function(){var t=[];for(var e in this)e[0]===o&&t.push({key:e.slice(1),value:this[e]});return t},size:function(){var t=0;for(var e in this)e[0]===o&&++t;return t},empty:function(){for(var t in this)if(t[0]===o)return!1;return!0},each:function(t){for(var e in this)e[0]===o&&t(this[e],e.slice(1),this)}},e.a=i},function(t,e,n){\"use strict\";function r(){}function i(t){var e;return t=(t+\"\").trim().toLowerCase(),(e=x.exec(t))?(e=parseInt(e[1],16),new s(e>>8&15|e>>4&240,e>>4&15|240&e,(15&e)<<4|15&e,1)):(e=w.exec(t))?o(parseInt(e[1],16)):(e=C.exec(t))?new s(e[1],e[2],e[3],1):(e=M.exec(t))?new s(255*e[1]/100,255*e[2]/100,255*e[3]/100,1):(e=k.exec(t))?a(e[1],e[2],e[3],e[4]):(e=E.exec(t))?a(255*e[1]/100,255*e[2]/100,255*e[3]/100,e[4]):(e=T.exec(t))?l(e[1],e[2]/100,e[3]/100,1):(e=S.exec(t))?l(e[1],e[2]/100,e[3]/100,e[4]):P.hasOwnProperty(t)?o(P[t]):\"transparent\"===t?new s(NaN,NaN,NaN,0):null}function o(t){return new s(t>>16&255,t>>8&255,255&t,1)}function a(t,e,n,r){return r<=0&&(t=e=n=NaN),new s(t,e,n,r)}function u(t){return t instanceof r||(t=i(t)),t?(t=t.rgb(),new s(t.r,t.g,t.b,t.opacity)):new s}function c(t,e,n,r){return 1===arguments.length?u(t):new s(t,e,n,null==r?1:r)}function s(t,e,n,r){this.r=+t,this.g=+e,this.b=+n,this.opacity=+r}function l(t,e,n,r){return r<=0?t=e=n=NaN:n<=0||n>=1?t=e=NaN:e<=0&&(t=NaN),new h(t,e,n,r)}function f(t){if(t instanceof h)return new h(t.h,t.s,t.l,t.opacity);if(t instanceof r||(t=i(t)),!t)return new h;if(t instanceof h)return t;t=t.rgb();var e=t.r/255,n=t.g/255,o=t.b/255,a=Math.min(e,n,o),u=Math.max(e,n,o),c=NaN,s=u-a,l=(u+a)/2;return s?(c=e===u?(n-o)/s+6*(n<o):n===u?(o-e)/s+2:(e-n)/s+4,s/=l<.5?u+a:2-u-a,c*=60):s=l>0&&l<1?0:c,new h(c,s,l,t.opacity)}function p(t,e,n,r){return 1===arguments.length?f(t):new h(t,e,n,null==r?1:r)}function h(t,e,n,r){this.h=+t,this.s=+e,this.l=+n,this.opacity=+r}function d(t,e,n){return 255*(t<60?e+(n-e)*t/60:t<180?n:t<240?e+(n-e)*(240-t)/60:e)}var v=n(60);e.f=r,n.d(e,\"h\",function(){return g}),n.d(e,\"g\",function(){return m}),e.a=i,e.e=u,e.b=c,e.d=s,e.c=p;var g=.7,m=1/g,y=\"\\\\s*([+-]?\\\\d+)\\\\s*\",_=\"\\\\s*([+-]?\\\\d*\\\\.?\\\\d+(?:[eE][+-]?\\\\d+)?)\\\\s*\",b=\"\\\\s*([+-]?\\\\d*\\\\.?\\\\d+(?:[eE][+-]?\\\\d+)?)%\\\\s*\",x=/^#([0-9a-f]{3})$/,w=/^#([0-9a-f]{6})$/,C=new RegExp(\"^rgb\\\\(\"+[y,y,y]+\"\\\\)$\"),M=new RegExp(\"^rgb\\\\(\"+[b,b,b]+\"\\\\)$\"),k=new RegExp(\"^rgba\\\\(\"+[y,y,y,_]+\"\\\\)$\"),E=new RegExp(\"^rgba\\\\(\"+[b,b,b,_]+\"\\\\)$\"),T=new RegExp(\"^hsl\\\\(\"+[_,b,b]+\"\\\\)$\"),S=new RegExp(\"^hsla\\\\(\"+[_,b,b,_]+\"\\\\)$\"),P={aliceblue:15792383,antiquewhite:16444375,aqua:65535,aquamarine:8388564,azure:15794175,beige:16119260,bisque:16770244,black:0,blanchedalmond:16772045,blue:255,blueviolet:9055202,brown:10824234,burlywood:14596231,cadetblue:6266528,chartreuse:8388352,chocolate:13789470,coral:16744272,cornflowerblue:6591981,cornsilk:16775388,crimson:14423100,cyan:65535,darkblue:139,darkcyan:35723,darkgoldenrod:12092939,darkgray:11119017,darkgreen:25600,darkgrey:11119017,darkkhaki:12433259,darkmagenta:9109643,darkolivegreen:5597999,darkorange:16747520,darkorchid:10040012,darkred:9109504,darksalmon:15308410,darkseagreen:9419919,darkslateblue:4734347,darkslategray:3100495,darkslategrey:3100495,darkturquoise:52945,darkviolet:9699539,deeppink:16716947,deepskyblue:49151,dimgray:6908265,dimgrey:6908265,dodgerblue:2003199,firebrick:11674146,floralwhite:16775920,forestgreen:2263842,fuchsia:16711935,gainsboro:14474460,ghostwhite:16316671,gold:16766720,goldenrod:14329120,gray:8421504,green:32768,greenyellow:11403055,grey:8421504,honeydew:15794160,hotpink:16738740,indianred:13458524,indigo:4915330,ivory:16777200,khaki:15787660,lavender:15132410,lavenderblush:16773365,lawngreen:8190976,lemonchiffon:16775885,lightblue:11393254,lightcoral:15761536,lightcyan:14745599,lightgoldenrodyellow:16448210,lightgray:13882323,lightgreen:9498256,lightgrey:13882323,lightpink:16758465,lightsalmon:16752762,lightseagreen:2142890,lightskyblue:8900346,lightslategray:7833753,lightslategrey:7833753,lightsteelblue:11584734,lightyellow:16777184,lime:65280,limegreen:3329330,linen:16445670,magenta:16711935,maroon:8388608,mediumaquamarine:6737322,mediumblue:205,mediumorchid:12211667,mediumpurple:9662683,mediumseagreen:3978097,mediumslateblue:8087790,mediumspringgreen:64154,mediumturquoise:4772300,mediumvioletred:13047173,midnightblue:1644912,mintcream:16121850,mistyrose:16770273,moccasin:16770229,navajowhite:16768685,navy:128,oldlace:16643558,olive:8421376,olivedrab:7048739,orange:16753920,orangered:16729344,orchid:14315734,palegoldenrod:15657130,palegreen:10025880,paleturquoise:11529966,palevioletred:14381203,papayawhip:16773077,peachpuff:16767673,peru:13468991,pink:16761035,plum:14524637,powderblue:11591910,purple:8388736,rebeccapurple:6697881,red:16711680,rosybrown:12357519,royalblue:4286945,saddlebrown:9127187,salmon:16416882,sandybrown:16032864,seagreen:3050327,seashell:16774638,sienna:10506797,silver:12632256,skyblue:8900331,slateblue:6970061,slategray:7372944,slategrey:7372944,snow:16775930,springgreen:65407,steelblue:4620980,tan:13808780,teal:32896,thistle:14204888,tomato:16737095,turquoise:4251856,violet:15631086,wheat:16113331,white:16777215,whitesmoke:16119285,yellow:16776960,yellowgreen:10145074};n.i(v.a)(r,i,{displayable:function(){return this.rgb().displayable()},toString:function(){return this.rgb()+\"\"}}),n.i(v.a)(s,c,n.i(v.b)(r,{brighter:function(t){return t=null==t?m:Math.pow(m,t),new s(this.r*t,this.g*t,this.b*t,this.opacity)},darker:function(t){return t=null==t?g:Math.pow(g,t),new s(this.r*t,this.g*t,this.b*t,this.opacity)},rgb:function(){return this},displayable:function(){return 0<=this.r&&this.r<=255&&0<=this.g&&this.g<=255&&0<=this.b&&this.b<=255&&0<=this.opacity&&this.opacity<=1},toString:function(){var t=this.opacity;return t=isNaN(t)?1:Math.max(0,Math.min(1,t)),(1===t?\"rgb(\":\"rgba(\")+Math.max(0,Math.min(255,Math.round(this.r)||0))+\", \"+Math.max(0,Math.min(255,Math.round(this.g)||0))+\", \"+Math.max(0,Math.min(255,Math.round(this.b)||0))+(1===t?\")\":\", \"+t+\")\")}})),n.i(v.a)(h,p,n.i(v.b)(r,{brighter:function(t){return t=null==t?m:Math.pow(m,t),new h(this.h,this.s,this.l*t,this.opacity)},darker:function(t){return t=null==t?g:Math.pow(g,t),new h(this.h,this.s,this.l*t,this.opacity)},rgb:function(){var t=this.h%360+360*(this.h<0),e=isNaN(t)||isNaN(this.s)?0:this.s,n=this.l,r=n+(n<.5?n:1-n)*e,i=2*n-r;return new s(d(t>=240?t-240:t+120,i,r),d(t,i,r),d(t<120?t+240:t-120,i,r),this.opacity)},displayable:function(){return(0<=this.s&&this.s<=1||isNaN(this.s))&&0<=this.l&&this.l<=1&&0<=this.opacity&&this.opacity<=1}}))},function(t,e,n){\"use strict\";function r(t,e){var n=Object.create(t.prototype);for(var r in e)n[r]=e[r];return n}e.b=r,e.a=function(t,e,n){t.prototype=e.prototype=n,n.constructor=t}},function(t,e,n){\"use strict\";e.a=function(t,e){if((n=(t=e?t.toExponential(e-1):t.toExponential()).indexOf(\"e\"))<0)return null;var n,r=t.slice(0,n);return[r.length>1?r[0]+r.slice(2):r,+t.slice(n+1)]}},function(t,e,n){\"use strict\";function r(t,e,n,r,i){var o=t*t,a=o*t;return((1-3*t+3*o-a)*e+(4-6*o+3*a)*n+(1+3*t+3*o-3*a)*r+a*i)/6}e.b=r,e.a=function(t){var e=t.length-1;return function(n){var i=n<=0?n=0:n>=1?(n=1,e-1):Math.floor(n*e),o=t[i],a=t[i+1],u=i>0?t[i-1]:2*o-a,c=i<e-1?t[i+2]:2*a-o;return r((n-i/e)*e,u,o,a,c)}}},function(t,e,n){\"use strict\";var r=n(10),i=n(123),o=n(118),a=n(121),u=n(43),c=n(122),s=n(124),l=n(120);e.a=function(t,e){var f,p=typeof e;return null==e||\"boolean\"===p?n.i(l.a)(e):(\"number\"===p?u.a:\"string\"===p?(f=n.i(r.color)(e))?(e=f,i.a):s.a:e instanceof r.color?i.a:e instanceof Date?a.a:Array.isArray(e)?o.a:isNaN(e)?c.a:u.a)(t,e)}},function(t,e,n){\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0});var r=n(229);n.d(e,\"scaleBand\",function(){return r.a}),n.d(e,\"scalePoint\",function(){return r.b});var i=n(235);n.d(e,\"scaleIdentity\",function(){return i.a});var o=n(34);n.d(e,\"scaleLinear\",function(){return o.a});var a=n(236);n.d(e,\"scaleLog\",function(){return a.a});var u=n(127);n.d(e,\"scaleOrdinal\",function(){return u.a}),n.d(e,\"scaleImplicit\",function(){return u.b});var c=n(237);n.d(e,\"scalePow\",function(){return c.a}),n.d(e,\"scaleSqrt\",function(){return c.b});var s=n(238);n.d(e,\"scaleQuantile\",function(){return s.a});var l=n(239);n.d(e,\"scaleQuantize\",function(){return l.a});var f=n(242);n.d(e,\"scaleThreshold\",function(){return f.a});var p=n(128);n.d(e,\"scaleTime\",function(){return p.a});var h=n(244);n.d(e,\"scaleUtc\",function(){return h.a});var d=n(230);n.d(e,\"schemeCategory10\",function(){return d.a});var v=n(232);n.d(e,\"schemeCategory20b\",function(){return v.a});var g=n(233);n.d(e,\"schemeCategory20c\",function(){return g.a});var m=n(231);n.d(e,\"schemeCategory20\",function(){return m.a});var y=n(234);n.d(e,\"interpolateCubehelixDefault\",function(){return y.a});var _=n(240);n.d(e,\"interpolateRainbow\",function(){return _.a}),n.d(e,\"interpolateWarm\",function(){return _.b}),n.d(e,\"interpolateCool\",function(){return _.c});var b=n(245);n.d(e,\"interpolateViridis\",function(){return b.a}),n.d(e,\"interpolateMagma\",function(){return b.b}),n.d(e,\"interpolateInferno\",function(){return b.c}),n.d(e,\"interpolatePlasma\",function(){return b.d});var x=n(241);n.d(e,\"scaleSequential\",function(){return x.a})},function(t,e,n){\"use strict\";e.a=function(t){return function(){return t}}},function(t,e,n){\"use strict\";function r(t){return function(){var e=this.ownerDocument,n=this.namespaceURI;return n===a.b&&e.documentElement.namespaceURI===a.b?e.createElement(t):e.createElementNS(n,t)}}function i(t){return function(){return this.ownerDocument.createElementNS(t.space,t.local)}}var o=n(67),a=n(68);e.a=function(t){var e=n.i(o.a)(t);return(e.local?i:r)(e)}},function(t,e,n){\"use strict\";var r=n(68);e.a=function(t){var e=t+=\"\",n=e.indexOf(\":\");return n>=0&&\"xmlns\"!==(e=t.slice(0,n))&&(t=t.slice(n+1)),r.a.hasOwnProperty(e)?{space:r.a[e],local:t}:t}},function(t,e,n){\"use strict\";n.d(e,\"b\",function(){return r});var r=\"http://www.w3.org/1999/xhtml\";e.a={svg:\"http://www.w3.org/2000/svg\",xhtml:r,xlink:\"http://www.w3.org/1999/xlink\",xml:\"http://www.w3.org/XML/1998/namespace\",xmlns:\"http://www.w3.org/2000/xmlns/\"}},function(t,e,n){\"use strict\";e.a=function(t,e){var n=t.ownerSVGElement||t;if(n.createSVGPoint){var r=n.createSVGPoint();return r.x=e.clientX,r.y=e.clientY,r=r.matrixTransform(t.getScreenCTM().inverse()),[r.x,r.y]}var i=t.getBoundingClientRect();return[e.clientX-i.left-t.clientLeft,e.clientY-i.top-t.clientTop]}},function(t,e,n){\"use strict\";function r(t,e,n){return t=i(t,e,n),function(e){var n=e.relatedTarget;n&&(n===this||8&n.compareDocumentPosition(this))||t.call(this,e)}}function i(t,e,n){return function(r){var i=l;l=r;try{t.call(this,this.__data__,e,n)}finally{l=i}}}function o(t){return t.trim().split(/^|\\s+/).map(function(t){var e=\"\",n=t.indexOf(\".\");return n>=0&&(e=t.slice(n+1),t=t.slice(0,n)),{type:t,name:e}})}function a(t){return function(){var e=this.__on;if(e){for(var n,r=0,i=-1,o=e.length;r<o;++r)n=e[r],t.type&&n.type!==t.type||n.name!==t.name?e[++i]=n:this.removeEventListener(n.type,n.listener,n.capture);++i?e.length=i:delete this.__on}}}function u(t,e,n){var o=s.hasOwnProperty(t.type)?r:i;return function(r,i,a){var u,c=this.__on,s=o(e,i,a);if(c)for(var l=0,f=c.length;l<f;++l)if((u=c[l]).type===t.type&&u.name===t.name)return this.removeEventListener(u.type,u.listener,u.capture),this.addEventListener(u.type,u.listener=s,u.capture=n),void(u.value=e);this.addEventListener(t.type,s,n),u={type:t.type,name:t.name,value:e,listener:s,capture:n},c?c.push(u):this.__on=[u]}}function c(t,e,n,r){var i=l;t.sourceEvent=l,l=t;try{return e.apply(n,r)}finally{l=i}}n.d(e,\"a\",function(){return l}),e.b=c;var s={},l=null;if(\"undefined\"!=typeof document){var f=document.documentElement;\"onmouseenter\"in f||(s={mouseenter:\"mouseover\",mouseleave:\"mouseout\"})}e.c=function(t,e,n){var r,i,c=o(t+\"\"),s=c.length;{if(!(arguments.length<2)){for(l=e?u:a,null==n&&(n=!1),r=0;r<s;++r)this.each(l(c[r],e,n));return this}var l=this.node().__on;if(l)for(var f,p=0,h=l.length;p<h;++p)for(r=0,f=l[p];r<s;++r)if((i=c[r]).type===f.type&&i.name===f.name)return f.value}}},function(t,e,n){\"use strict\";function r(){}e.a=function(t){return null==t?r:function(){return this.querySelector(t)}}},function(t,e,n){\"use strict\";var r=n(70);e.a=function(){for(var t,e=r.a;t=e.sourceEvent;)e=t;return e}},function(t,e,n){\"use strict\";e.a=function(t){return t.ownerDocument&&t.ownerDocument.defaultView||t.document&&t||t.defaultView}},function(t,e,n){\"use strict\";function r(t,e,n){var r=t._x1,i=t._y1,a=t._x2,u=t._y2;if(t._l01_a>o.a){var c=2*t._l01_2a+3*t._l01_a*t._l12_a+t._l12_2a,s=3*t._l01_a*(t._l01_a+t._l12_a);r=(r*c-t._x0*t._l12_2a+t._x2*t._l01_2a)/s,i=(i*c-t._y0*t._l12_2a+t._y2*t._l01_2a)/s}if(t._l23_a>o.a){var l=2*t._l23_2a+3*t._l23_a*t._l12_a+t._l12_2a,f=3*t._l23_a*(t._l23_a+t._l12_a);a=(a*l+t._x1*t._l23_2a-e*t._l12_2a)/f,u=(u*l+t._y1*t._l23_2a-n*t._l12_2a)/f}t._context.bezierCurveTo(r,i,a,u,t._x2,t._y2)}function i(t,e){this._context=t,this._alpha=e}var o=n(35),a=n(47);e.b=r,i.prototype={areaStart:function(){this._line=0},areaEnd:function(){this._line=NaN},lineStart:function(){this._x0=this._x1=this._x2=this._y0=this._y1=this._y2=NaN,this._l01_a=this._l12_a=this._l23_a=this._l01_2a=this._l12_2a=this._l23_2a=this._point=0},lineEnd:function(){switch(this._point){case 2:this._context.lineTo(this._x2,this._y2);break;case 3:this.point(this._x2,this._y2)}(this._line||0!==this._line&&1===this._point)&&this._context.closePath(),this._line=1-this._line},point:function(t,e){if(t=+t,e=+e,this._point){var n=this._x2-t,i=this._y2-e;this._l23_a=Math.sqrt(this._l23_2a=Math.pow(n*n+i*i,this._alpha))}switch(this._point){case 0:this._point=1,this._line?this._context.lineTo(t,e):this._context.moveTo(t,e);break;case 1:this._point=2;break;case 2:this._point=3;default:r(this,t,e)}this._l01_a=this._l12_a,this._l12_a=this._l23_a,this._l01_2a=this._l12_2a,this._l12_2a=this._l23_2a,this._x0=this._x1,this._x1=this._x2,this._x2=t,this._y0=this._y1,this._y1=this._y2,this._y2=e}},e.a=function t(e){function n(t){return e?new i(t,e):new a.b(t,0)}return n.alpha=function(e){return t(+e)},n}(.5)},function(t,e,n){\"use strict\";var r=n(44),i=n(19),o=n(48),a=n(139);e.a=function(){function t(t){var i,o,a,p=t.length,h=!1;for(null==s&&(f=l(a=n.i(r.a)())),i=0;i<=p;++i)!(i<p&&c(o=t[i],i,t))===h&&((h=!h)?f.lineStart():f.lineEnd()),h&&f.point(+e(o,i,t),+u(o,i,t));if(a)return f=null,a+\"\"||null}var e=a.a,u=a.b,c=n.i(i.a)(!0),s=null,l=o.a,f=null;return t.x=function(r){return arguments.length?(e=\"function\"==typeof r?r:n.i(i.a)(+r),t):e},t.y=function(e){return arguments.length?(u=\"function\"==typeof e?e:n.i(i.a)(+e),t):u},t.defined=function(e){return arguments.length?(c=\"function\"==typeof e?e:n.i(i.a)(!!e),t):c},t.curve=function(e){return arguments.length?(l=e,null!=s&&(f=l(s)),t):l},t.context=function(e){return arguments.length?(null==e?s=f=null:f=l(s=e),t):s},t}},function(t,e,n){\"use strict\";function r(t){for(var e,n=0,r=-1,i=t.length;++r<i;)(e=+t[r][1])&&(n+=e);return n}var i=n(37);e.b=r,e.a=function(t){var e=t.map(r);return n.i(i.a)(t).sort(function(t,n){return e[t]-e[n]})}},function(t,e,n){\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0});var r=n(78);n.d(e,\"timeFormatDefaultLocale\",function(){return r.a}),n.d(e,\"timeFormat\",function(){return r.b}),n.d(e,\"timeParse\",function(){return r.c}),n.d(e,\"utcFormat\",function(){return r.d}),n.d(e,\"utcParse\",function(){return r.e});var i=n(149);n.d(e,\"timeFormatLocale\",function(){return i.a});var o=n(148);n.d(e,\"isoFormat\",function(){return o.a});var a=n(303);n.d(e,\"isoParse\",function(){return a.a})},function(t,e,n){\"use strict\";function r(t){return o=n.i(i.a)(t),a=o.format,u=o.parse,c=o.utcFormat,s=o.utcParse,o}var i=n(149);n.d(e,\"b\",function(){return a}),n.d(e,\"c\",function(){return u}),n.d(e,\"d\",function(){return c}),n.d(e,\"e\",function(){return s}),e.a=r;var o,a,u,c,s;r({dateTime:\"%x, %X\",date:\"%-m/%-d/%Y\",time:\"%-I:%M:%S %p\",periods:[\"AM\",\"PM\"],days:[\"Sunday\",\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\"],shortDays:[\"Sun\",\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Fri\",\"Sat\"],months:[\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"],shortMonths:[\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"]})},function(t,e,n){\"use strict\";var r=(n(5),n(306));n.d(e,\"t\",function(){return r.a}),n.d(e,\"n\",function(){return r.a});var i=n(309);n.d(e,\"s\",function(){return i.a}),n.d(e,\"m\",function(){return i.a});var o=n(307);n.d(e,\"r\",function(){return o.a});var a=n(305);n.d(e,\"q\",function(){return a.a});var u=n(304);n.d(e,\"a\",function(){return u.a});var c=n(316);n.d(e,\"p\",function(){return c.a}),n.d(e,\"c\",function(){return c.a}),n.d(e,\"d\",function(){return c.b});var s=n(308);n.d(e,\"o\",function(){return s.a});var l=n(317);n.d(e,\"b\",function(){return l.a});var f=n(312);n.d(e,\"l\",function(){return f.a});var p=n(311);n.d(e,\"k\",function(){return p.a});var h=n(310);n.d(e,\"e\",function(){return h.a});var d=n(314);n.d(e,\"j\",function(){return d.a}),n.d(e,\"g\",function(){return d.a}),n.d(e,\"h\",function(){return d.b});var v=n(313);n.d(e,\"i\",function(){return v.a});var g=n(315);n.d(e,\"f\",function(){return g.a})},function(t,e,n){\"use strict\";function r(t,e){return t===e?0!==t||0!==e||1/t===1/e:t!==t&&e!==e}function i(t,e){if(r(t,e))return!0;if(\"object\"!=typeof t||null===t||\"object\"!=typeof e||null===e)return!1;var n=Object.keys(t),i=Object.keys(e);if(n.length!==i.length)return!1;for(var a=0;a<n.length;a++)if(!o.call(e,n[a])||!r(t[n[a]],e[n[a]]))return!1;return!0}var o=Object.prototype.hasOwnProperty;t.exports=i},function(t,e,n){\"use strict\";function r(t,e){return Array.isArray(e)&&(e=e[1]),e?e.nextSibling:t.firstChild}function i(t,e,n){l.insertTreeBefore(t,e,n)}function o(t,e,n){Array.isArray(e)?u(t,e[0],e[1],n):v(t,e,n)}function a(t,e){if(Array.isArray(e)){var n=e[1];e=e[0],c(t,e,n),t.removeChild(n)}t.removeChild(e)}function u(t,e,n,r){for(var i=e;;){var o=i.nextSibling;if(v(t,i,r),i===n)break;i=o}}function c(t,e,n){for(;;){var r=e.nextSibling;if(r===n)break;t.removeChild(r)}}function s(t,e,n){var r=t.parentNode,i=t.nextSibling;i===e?n&&v(r,document.createTextNode(n),i):n?(d(i,n),c(r,i,e)):c(r,t,e)}var l=n(20),f=n(336),p=(n(4),n(9),n(90)),h=n(55),d=n(171),v=p(function(t,e,n){t.insertBefore(e,n)}),g=f.dangerouslyReplaceNodeWithMarkup,m={dangerouslyReplaceNodeWithMarkup:g,replaceDelimitedText:s,processUpdates:function(t,e){for(var n=0;n<e.length;n++){var u=e[n];switch(u.type){case\"INSERT_MARKUP\":i(t,u.content,r(t,u.afterNode));break;case\"MOVE_EXISTING\":o(t,u.fromNode,r(t,u.afterNode));break;case\"SET_MARKUP\":h(t,u.content);break;case\"TEXT_CONTENT\":d(t,u.content);break;case\"REMOVE_NODE\":a(t,u.fromNode)}}}};t.exports=m},function(t,e,n){\"use strict\";var r={html:\"http://www.w3.org/1999/xhtml\",mathml:\"http://www.w3.org/1998/Math/MathML\",svg:\"http://www.w3.org/2000/svg\"};t.exports=r},function(t,e,n){\"use strict\";function r(){if(u)for(var t in c){var e=c[t],n=u.indexOf(t);if(n>-1?void 0:a(\"96\",t),!s.plugins[n]){e.extractEvents?void 0:a(\"97\",t),s.plugins[n]=e;var r=e.eventTypes;for(var o in r)i(r[o],e,o)?void 0:a(\"98\",o,t)}}}function i(t,e,n){s.eventNameDispatchConfigs.hasOwnProperty(n)?a(\"99\",n):void 0,s.eventNameDispatchConfigs[n]=t;var r=t.phasedRegistrationNames;if(r){for(var i in r)if(r.hasOwnProperty(i)){var u=r[i];o(u,e,n)}return!0}return!!t.registrationName&&(o(t.registrationName,e,n),!0)}function o(t,e,n){s.registrationNameModules[t]?a(\"100\",t):void 0,s.registrationNameModules[t]=e,s.registrationNameDependencies[t]=e.eventTypes[n].dependencies}var a=n(2),u=(n(0),null),c={},s={plugins:[],eventNameDispatchConfigs:{},registrationNameModules:{},registrationNameDependencies:{},possibleRegistrationNames:null,injectEventPluginOrder:function(t){\n",
       "u?a(\"101\"):void 0,u=Array.prototype.slice.call(t),r()},injectEventPluginsByName:function(t){var e=!1;for(var n in t)if(t.hasOwnProperty(n)){var i=t[n];c.hasOwnProperty(n)&&c[n]===i||(c[n]?a(\"102\",n):void 0,c[n]=i,e=!0)}e&&r()},getPluginModuleForEvent:function(t){var e=t.dispatchConfig;if(e.registrationName)return s.registrationNameModules[e.registrationName]||null;if(void 0!==e.phasedRegistrationNames){var n=e.phasedRegistrationNames;for(var r in n)if(n.hasOwnProperty(r)){var i=s.registrationNameModules[n[r]];if(i)return i}}return null},_resetEventPlugins:function(){u=null;for(var t in c)c.hasOwnProperty(t)&&delete c[t];s.plugins.length=0;var e=s.eventNameDispatchConfigs;for(var n in e)e.hasOwnProperty(n)&&delete e[n];var r=s.registrationNameModules;for(var i in r)r.hasOwnProperty(i)&&delete r[i]}};t.exports=s},function(t,e,n){\"use strict\";function r(t){var e=/[=:]/g,n={\"=\":\"=0\",\":\":\"=2\"},r=(\"\"+t).replace(e,function(t){return n[t]});return\"$\"+r}function i(t){var e=/(=0|=2)/g,n={\"=0\":\"=\",\"=2\":\":\"},r=\".\"===t[0]&&\"$\"===t[1]?t.substring(2):t.substring(1);return(\"\"+r).replace(e,function(t){return n[t]})}var o={escape:r,unescape:i};t.exports=o},function(t,e,n){\"use strict\";function r(t){null!=t.checkedLink&&null!=t.valueLink?u(\"87\"):void 0}function i(t){r(t),null!=t.value||null!=t.onChange?u(\"88\"):void 0}function o(t){r(t),null!=t.checked||null!=t.onChange?u(\"89\"):void 0}function a(t){if(t){var e=t.getName();if(e)return\" Check the render method of `\"+e+\"`.\"}return\"\"}var u=n(2),c=n(26),s=n(366),l=(n(0),n(1),{button:!0,checkbox:!0,image:!0,hidden:!0,radio:!0,reset:!0,submit:!0}),f={value:function(t,e,n){return!t[e]||l[t.type]||t.onChange||t.readOnly||t.disabled?null:new Error(\"You provided a `value` prop to a form field without an `onChange` handler. This will render a read-only field. If the field should be mutable use `defaultValue`. Otherwise, set either `onChange` or `readOnly`.\")},checked:function(t,e,n){return!t[e]||t.onChange||t.readOnly||t.disabled?null:new Error(\"You provided a `checked` prop to a form field without an `onChange` handler. This will render a read-only field. If the field should be mutable use `defaultChecked`. Otherwise, set either `onChange` or `readOnly`.\")},onChange:c.PropTypes.func},p={},h={checkPropTypes:function(t,e,n){for(var r in f){if(f.hasOwnProperty(r))var i=f[r](e,r,t,\"prop\",null,s);if(i instanceof Error&&!(i.message in p)){p[i.message]=!0;a(n)}}},getValue:function(t){return t.valueLink?(i(t),t.valueLink.value):t.value},getChecked:function(t){return t.checkedLink?(o(t),t.checkedLink.value):t.checked},executeOnChange:function(t,e){return t.valueLink?(i(t),t.valueLink.requestChange(e.target.value)):t.checkedLink?(o(t),t.checkedLink.requestChange(e.target.checked)):t.onChange?t.onChange.call(void 0,e):void 0}};t.exports=h},function(t,e,n){\"use strict\";var r=n(2),i=(n(0),!1),o={replaceNodeWithMarkup:null,processChildrenUpdates:null,injection:{injectEnvironment:function(t){i?r(\"104\"):void 0,o.replaceNodeWithMarkup=t.replaceNodeWithMarkup,o.processChildrenUpdates=t.processChildrenUpdates,i=!0}}};t.exports=o},function(t,e,n){\"use strict\";function r(t,e,n){try{e(n)}catch(t){null===i&&(i=t)}}var i=null,o={invokeGuardedCallback:r,invokeGuardedCallbackWithCatch:r,rethrowCaughtError:function(){if(i){var t=i;throw i=null,t}}};t.exports=o},function(t,e,n){\"use strict\";function r(t){c.enqueueUpdate(t)}function i(t){var e=typeof t;if(\"object\"!==e)return e;var n=t.constructor&&t.constructor.name||e,r=Object.keys(t);return r.length>0&&r.length<20?n+\" (keys: \"+r.join(\", \")+\")\":n}function o(t,e){var n=u.get(t);if(!n){return null}return n}var a=n(2),u=(n(15),n(40)),c=(n(9),n(11)),s=(n(0),n(1),{isMounted:function(t){var e=u.get(t);return!!e&&!!e._renderedComponent},enqueueCallback:function(t,e,n){s.validateCallback(e,n);var i=o(t);return i?(i._pendingCallbacks?i._pendingCallbacks.push(e):i._pendingCallbacks=[e],void r(i)):null},enqueueCallbackInternal:function(t,e){t._pendingCallbacks?t._pendingCallbacks.push(e):t._pendingCallbacks=[e],r(t)},enqueueForceUpdate:function(t){var e=o(t,\"forceUpdate\");e&&(e._pendingForceUpdate=!0,r(e))},enqueueReplaceState:function(t,e){var n=o(t,\"replaceState\");n&&(n._pendingStateQueue=[e],n._pendingReplaceState=!0,r(n))},enqueueSetState:function(t,e){var n=o(t,\"setState\");if(n){var i=n._pendingStateQueue||(n._pendingStateQueue=[]);i.push(e),r(n)}},enqueueElementInternal:function(t,e,n){t._pendingElement=e,t._context=n,r(t)},validateCallback:function(t,e){t&&\"function\"!=typeof t?a(\"122\",e,i(t)):void 0}});t.exports=s},function(t,e,n){\"use strict\";var r={currentScrollLeft:0,currentScrollTop:0,refreshScrollValues:function(t){r.currentScrollLeft=t.x,r.currentScrollTop=t.y}};t.exports=r},function(t,e,n){\"use strict\";var r=function(t){return\"undefined\"!=typeof MSApp&&MSApp.execUnsafeLocalFunction?function(e,n,r,i){MSApp.execUnsafeLocalFunction(function(){return t(e,n,r,i)})}:t};t.exports=r},function(t,e,n){\"use strict\";function r(t){var e,n=t.keyCode;return\"charCode\"in t?(e=t.charCode,0===e&&13===n&&(e=13)):e=n,e>=32||13===e?e:0}t.exports=r},function(t,e,n){\"use strict\";function r(t){var e=this,n=e.nativeEvent;if(n.getModifierState)return n.getModifierState(t);var r=o[t];return!!r&&!!n[r]}function i(t){return r}var o={Alt:\"altKey\",Control:\"ctrlKey\",Meta:\"metaKey\",Shift:\"shiftKey\"};t.exports=i},function(t,e,n){\"use strict\";function r(t){var e=t.target||t.srcElement||window;return e.correspondingUseElement&&(e=e.correspondingUseElement),3===e.nodeType?e.parentNode:e}t.exports=r},function(t,e,n){\"use strict\";/**\n",
       " * Checks if an event is supported in the current execution environment.\n",
       " *\n",
       " * NOTE: This will not work correctly for non-generic events such as `change`,\n",
       " * `reset`, `load`, `error`, and `select`.\n",
       " *\n",
       " * Borrows from Modernizr.\n",
       " *\n",
       " * @param {string} eventNameSuffix Event name, e.g. \"click\".\n",
       " * @param {?boolean} capture Check if the capture phase is supported.\n",
       " * @return {boolean} True if the event is supported.\n",
       " * @internal\n",
       " * @license Modernizr 3.0.0pre (Custom Build) | MIT\n",
       " */\n",
       "function r(t,e){if(!o.canUseDOM||e&&!(\"addEventListener\"in document))return!1;var n=\"on\"+t,r=n in document;if(!r){var a=document.createElement(\"div\");a.setAttribute(n,\"return;\"),r=\"function\"==typeof a[n]}return!r&&i&&\"wheel\"===t&&(r=document.implementation.hasFeature(\"Events.wheel\",\"3.0\")),r}var i,o=n(6);o.canUseDOM&&(i=document.implementation&&document.implementation.hasFeature&&document.implementation.hasFeature(\"\",\"\")!==!0),t.exports=r},function(t,e,n){\"use strict\";function r(t,e){var n=null===t||t===!1,r=null===e||e===!1;if(n||r)return n===r;var i=typeof t,o=typeof e;return\"string\"===i||\"number\"===i?\"string\"===o||\"number\"===o:\"object\"===o&&t.type===e.type&&t.key===e.key}t.exports=r},function(t,e,n){\"use strict\";var r=(n(3),n(8)),i=(n(1),r);t.exports=i},function(t,e,n){\"use strict\";function r(t,e,n){this.props=t,this.context=e,this.refs=a,this.updater=n||o}var i=n(28),o=n(98),a=(n(176),n(38));n(0),n(1);r.prototype.isReactComponent={},r.prototype.setState=function(t,e){\"object\"!=typeof t&&\"function\"!=typeof t&&null!=t?i(\"85\"):void 0,this.updater.enqueueSetState(this,t),e&&this.updater.enqueueCallback(this,e,\"setState\")},r.prototype.forceUpdate=function(t){this.updater.enqueueForceUpdate(this),t&&this.updater.enqueueCallback(this,t,\"forceUpdate\")};t.exports=r},function(t,e,n){\"use strict\";function r(t,e){}var i=(n(1),{isMounted:function(t){return!1},enqueueCallback:function(t,e){},enqueueForceUpdate:function(t){r(t,\"forceUpdate\")},enqueueReplaceState:function(t,e){r(t,\"replaceState\")},enqueueSetState:function(t,e){r(t,\"setState\")}});t.exports=i},function(t,e){var n;n=function(){return this}();try{n=n||Function(\"return this\")()||(0,eval)(\"this\")}catch(t){\"object\"==typeof window&&(n=window)}t.exports=n},function(t,e){t.exports=function(t){return t.webpackPolyfill||(t.deprecate=function(){},t.paths=[],t.children||(t.children=[]),Object.defineProperty(t,\"loaded\",{enumerable:!0,get:function(){return t.l}}),Object.defineProperty(t,\"id\",{enumerable:!0,get:function(){return t.i}}),t.webpackPolyfill=1),t}},function(t,e,n){\"use strict\";n.d(e,\"b\",function(){return i}),n.d(e,\"a\",function(){return o});var r=Array.prototype,i=r.slice,o=r.map},function(t,e,n){\"use strict\";var r=n(18),i=n(103),o=n.i(i.a)(r.a),a=o.right;o.left;e.a=a},function(t,e,n){\"use strict\";function r(t){return function(e,r){return n.i(i.a)(t(e),r)}}var i=n(18);e.a=function(t){return 1===t.length&&(t=r(t)),{left:function(e,n,r,i){for(null==r&&(r=0),null==i&&(i=e.length);r<i;){var o=r+i>>>1;t(e[o],n)<0?r=o+1:i=o}return r},right:function(e,n,r,i){for(null==r&&(r=0),null==i&&(i=e.length);r<i;){var o=r+i>>>1;t(e[o],n)>0?i=o:r=o+1}return r}}}},function(t,e,n){\"use strict\";var r=n(111);e.a=function(t,e){var i=n.i(r.a)(t,e);return i?Math.sqrt(i):i}},function(t,e,n){\"use strict\";e.a=function(t,e){var n,r,i,o=-1,a=t.length;if(null==e){for(;++o<a;)if(null!=(r=t[o])&&r>=r){n=i=r;break}for(;++o<a;)null!=(r=t[o])&&(n>r&&(n=r),i<r&&(i=r))}else{for(;++o<a;)if(null!=(r=e(t[o],o,t))&&r>=r){n=i=r;break}for(;++o<a;)null!=(r=e(t[o],o,t))&&(n>r&&(n=r),i<r&&(i=r))}return[n,i]}},function(t,e,n){\"use strict\";e.a=function(t,e){var n,r,i=-1,o=t.length;if(null==e){for(;++i<o;)if(null!=(r=t[i])&&r>=r){n=r;break}for(;++i<o;)null!=(r=t[i])&&n>r&&(n=r)}else{for(;++i<o;)if(null!=(r=e(t[i],i,t))&&r>=r){n=r;break}for(;++i<o;)null!=(r=e(t[i],i,t))&&n>r&&(n=r)}return n}},function(t,e,n){\"use strict\";e.a=function(t,e,n){t=+t,e=+e,n=(i=arguments.length)<2?(e=t,t=0,1):i<3?1:+n;for(var r=-1,i=0|Math.max(0,Math.ceil((e-t)/n)),o=new Array(i);++r<i;)o[r]=t+r*n;return o}},function(t,e,n){\"use strict\";e.a=function(t){return Math.ceil(Math.log(t.length)/Math.LN2)+1}},function(t,e,n){\"use strict\";function r(t,e,n){var r=Math.abs(e-t)/Math.max(0,n),i=Math.pow(10,Math.floor(Math.log(r)/Math.LN10)),c=r/i;return c>=o?i*=10:c>=a?i*=5:c>=u&&(i*=2),e<t?-i:i}var i=n(107);e.b=r;var o=Math.sqrt(50),a=Math.sqrt(10),u=Math.sqrt(2);e.a=function(t,e,o){var a=r(t,e,o);return n.i(i.a)(Math.ceil(t/a)*a,Math.floor(e/a)*a+a/2,a)}},function(t,e,n){\"use strict\";function r(t){return t.length}var i=n(106);e.a=function(t){if(!(u=t.length))return[];for(var e=-1,o=n.i(i.a)(t,r),a=new Array(o);++e<o;)for(var u,c=-1,s=a[e]=new Array(u);++c<u;)s[c]=t[c][e];return a}},function(t,e,n){\"use strict\";var r=n(29);e.a=function(t,e){var i,o,a=t.length,u=0,c=0,s=-1,l=0;if(null==e)for(;++s<a;)isNaN(i=n.i(r.a)(t[s]))||(o=i-u,u+=o/++l,c+=o*(i-u));else for(;++s<a;)isNaN(i=n.i(r.a)(e(t[s],s,t)))||(o=i-u,u+=o/++l,c+=o*(i-u));if(l>1)return c/(l-1)}},function(t,e,n){\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0});var r=n(201);n.d(e,\"axisTop\",function(){return r.a}),n.d(e,\"axisRight\",function(){return r.b}),n.d(e,\"axisBottom\",function(){return r.c}),n.d(e,\"axisLeft\",function(){return r.d})},function(t,e,n){\"use strict\";n.d(e,\"b\",function(){return r}),n.d(e,\"a\",function(){return i});var r=Math.PI/180,i=180/Math.PI},function(t,e,n){\"use strict\";var r=n(61);n.d(e,\"b\",function(){return i});var i;e.a=function(t,e){var o=n.i(r.a)(t,e);if(!o)return t+\"\";var a=o[0],u=o[1],c=u-(i=3*Math.max(-8,Math.min(8,Math.floor(u/3))))+1,s=a.length;return c===s?a:c>s?a+new Array(c-s+1).join(\"0\"):c>0?a.slice(0,c)+\".\"+a.slice(c):\"0.\"+new Array(1-c).join(\"0\")+n.i(r.a)(t,Math.max(0,e+c-1))[0]}},function(t,e,n){\"use strict\";function r(t){if(!(e=o.exec(t)))throw new Error(\"invalid format: \"+t);var e,n=e[1]||\" \",r=e[2]||\">\",a=e[3]||\"-\",u=e[4]||\"\",c=!!e[5],s=e[6]&&+e[6],l=!!e[7],f=e[8]&&+e[8].slice(1),p=e[9]||\"\";\"n\"===p?(l=!0,p=\"g\"):i.a[p]||(p=\"\"),(c||\"0\"===n&&\"=\"===r)&&(c=!0,n=\"0\",r=\"=\"),this.fill=n,this.align=r,this.sign=a,this.symbol=u,this.zero=c,this.width=s,this.comma=l,this.precision=f,this.type=p}var i=n(116),o=/^(?:(.)?([<>=^]))?([+\\-\\( ])?([$#])?(0)?(\\d+)?(,)?(\\.\\d+)?([a-z%])?$/i;e.a=function(t){return new r(t)},r.prototype.toString=function(){return this.fill+this.align+this.sign+this.symbol+(this.zero?\"0\":\"\")+(null==this.width?\"\":Math.max(1,0|this.width))+(this.comma?\",\":\"\")+(null==this.precision?\"\":\".\"+Math.max(0,0|this.precision))+this.type}},function(t,e,n){\"use strict\";var r=n(212),i=n(114),o=n(214);e.a={\"\":r.a,\"%\":function(t,e){return(100*t).toFixed(e)},b:function(t){return Math.round(t).toString(2)},c:function(t){return t+\"\"},d:function(t){return Math.round(t).toString(10)},e:function(t,e){return t.toExponential(e)},f:function(t,e){return t.toFixed(e)},g:function(t,e){return t.toPrecision(e)},o:function(t){return Math.round(t).toString(8)},p:function(t,e){return n.i(o.a)(100*t,e)},r:o.a,s:i.a,X:function(t){return Math.round(t).toString(16).toUpperCase()},x:function(t){return Math.round(t).toString(16)}}},function(t,e,n){\"use strict\";function r(t){return t}var i=n(42),o=n(213),a=n(115),u=n(116),c=n(114),s=[\"y\",\"z\",\"a\",\"f\",\"p\",\"n\",\"µ\",\"m\",\"\",\"k\",\"M\",\"G\",\"T\",\"P\",\"E\",\"Z\",\"Y\"];e.a=function(t){function e(t){function e(t){var e,n,a,u=_,l=b;if(\"c\"===y)l=x(t)+l,t=\"\";else{t=+t;var p=(t<0||1/t<0)&&(t*=-1,!0);if(t=x(t,m),p)for(e=-1,n=t.length,p=!1;++e<n;)if(a=t.charCodeAt(e),48<a&&a<58||\"x\"===y&&96<a&&a<103||\"X\"===y&&64<a&&a<71){p=!0;break}if(u=(p?\"(\"===o?o:\"-\":\"-\"===o||\"(\"===o?\"\":o)+u,l=l+(\"s\"===y?s[8+c.b/3]:\"\")+(p&&\"(\"===o?\")\":\"\"),w)for(e=-1,n=t.length;++e<n;)if(a=t.charCodeAt(e),48>a||a>57){l=(46===a?h+t.slice(e+1):t.slice(e))+l,t=t.slice(0,e);break}}g&&!d&&(t=f(t,1/0));var C=u.length+t.length+l.length,M=C<v?new Array(v-C+1).join(r):\"\";switch(g&&d&&(t=f(M+t,M.length?v-l.length:1/0),M=\"\"),i){case\"<\":return u+t+l+M;case\"=\":return u+M+t+l;case\"^\":return M.slice(0,C=M.length>>1)+u+t+l+M.slice(C)}return M+u+t+l}t=n.i(a.a)(t);var r=t.fill,i=t.align,o=t.sign,l=t.symbol,d=t.zero,v=t.width,g=t.comma,m=t.precision,y=t.type,_=\"$\"===l?p[0]:\"#\"===l&&/[boxX]/.test(y)?\"0\"+y.toLowerCase():\"\",b=\"$\"===l?p[1]:/[%p]/.test(y)?\"%\":\"\",x=u.a[y],w=!y||/[defgprs%]/.test(y);return m=null==m?y?6:12:/[gprs]/.test(y)?Math.max(1,Math.min(21,m)):Math.max(0,Math.min(20,m)),e.toString=function(){return t+\"\"},e}function l(t,r){var o=e((t=n.i(a.a)(t),t.type=\"f\",t)),u=3*Math.max(-8,Math.min(8,Math.floor(n.i(i.a)(r)/3))),c=Math.pow(10,-u),l=s[8+u/3];return function(t){return o(c*t)+l}}var f=t.grouping&&t.thousands?n.i(o.a)(t.grouping,t.thousands):r,p=t.currency,h=t.decimal;return{format:e,formatPrefix:l}}},function(t,e,n){\"use strict\";var r=n(63);e.a=function(t,e){var i,o=e?e.length:0,a=t?Math.min(o,t.length):0,u=new Array(o),c=new Array(o);for(i=0;i<a;++i)u[i]=n.i(r.a)(t[i],e[i]);for(;i<o;++i)c[i]=e[i];return function(t){for(i=0;i<a;++i)c[i]=u[i](t);return c}}},function(t,e,n){\"use strict\";var r=n(62);e.a=function(t){var e=t.length;return function(i){var o=Math.floor(((i%=1)<0?++i:i)*e),a=t[(o+e-1)%e],u=t[o%e],c=t[(o+1)%e],s=t[(o+2)%e];return n.i(r.b)((i-o/e)*e,a,u,c,s)}}},function(t,e,n){\"use strict\";e.a=function(t){return function(){return t}}},function(t,e,n){\"use strict\";e.a=function(t,e){var n=new Date;return t=+t,e-=t,function(r){return n.setTime(t+e*r),n}}},function(t,e,n){\"use strict\";var r=n(63);e.a=function(t,e){var i,o={},a={};null!==t&&\"object\"==typeof t||(t={}),null!==e&&\"object\"==typeof e||(e={});for(i in e)i in t?o[i]=n.i(r.a)(t[i],e[i]):a[i]=e[i];return function(t){for(i in o)a[i]=o[i](t);return a}}},function(t,e,n){\"use strict\";function r(t){return function(e){var r,o,a=e.length,u=new Array(a),c=new Array(a),s=new Array(a);for(r=0;r<a;++r)o=n.i(i.rgb)(e[r]),u[r]=o.r||0,c[r]=o.g||0,s[r]=o.b||0;return u=t(u),c=t(c),s=t(s),o.opacity=1,function(t){return o.r=u(t),o.g=c(t),o.b=s(t),o+\"\"}}}var i=n(10),o=n(62),a=n(119),u=n(32);e.a=function t(e){function r(t,e){var r=o((t=n.i(i.rgb)(t)).r,(e=n.i(i.rgb)(e)).r),a=o(t.g,e.g),c=o(t.b,e.b),s=n.i(u.a)(t.opacity,e.opacity);return function(e){return t.r=r(e),t.g=a(e),t.b=c(e),t.opacity=s(e),t+\"\"}}var o=n.i(u.c)(e);return r.gamma=t,r}(1);r(o.a),r(a.a)},function(t,e,n){\"use strict\";function r(t){return function(){return t}}function i(t){return function(e){return t(e)+\"\"}}var o=n(43),a=/[-+]?(?:\\d+\\.?\\d*|\\.?\\d+)(?:[eE][-+]?\\d+)?/g,u=new RegExp(a.source,\"g\");e.a=function(t,e){var c,s,l,f=a.lastIndex=u.lastIndex=0,p=-1,h=[],d=[];for(t+=\"\",e+=\"\";(c=a.exec(t))&&(s=u.exec(e));)(l=s.index)>f&&(l=e.slice(f,l),h[p]?h[p]+=l:h[++p]=l),(c=c[0])===(s=s[0])?h[p]?h[p]+=s:h[++p]=s:(h[++p]=null,d.push({i:p,x:n.i(o.a)(c,s)})),f=u.lastIndex;return f<e.length&&(l=e.slice(f),h[p]?h[p]+=l:h[++p]=l),h.length<2?d[0]?i(d[0].x):r(e):(e=d.length,function(t){for(var n,r=0;r<e;++r)h[(n=d[r]).i]=n.x(t);return h.join(\"\")})}},function(t,e,n){\"use strict\";e.a=function(t,e){t=t.slice();var n,r=0,i=t.length-1,o=t[r],a=t[i];return a<o&&(n=r,r=i,i=n,n=o,o=a,a=n),t[r]=e.floor(o),t[i]=e.ceil(a),t}},function(t,e,n){\"use strict\";e.a=function(t){return+t}},function(t,e,n){\"use strict\";function r(t){function e(e){var n=e+\"\",r=u.get(n);if(!r){if(s!==a)return s;u.set(n,r=c.push(e))}return t[(r-1)%t.length]}var u=n.i(i.a)(),c=[],s=a;return t=null==t?[]:o.b.call(t),e.domain=function(t){if(!arguments.length)return c.slice();c=[],u=n.i(i.a)();for(var r,o,a=-1,s=t.length;++a<s;)u.has(o=(r=t[a])+\"\")||u.set(o,c.push(r));return e},e.range=function(n){return arguments.length?(t=o.b.call(n),e):t.slice()},e.unknown=function(t){return arguments.length?(s=t,e):s},e.copy=function(){return r().domain(c).range(t).unknown(s)},e}var i=n(203),o=n(16);n.d(e,\"b\",function(){return a}),e.a=r;var a={name:\"implicit\"}},function(t,e,n){\"use strict\";function r(t){return new Date(t)}function i(t){return t instanceof Date?+t:+new Date(+t)}function o(t,e,c,s,b,x,w,C,M){function k(n){return(w(n)<n?N:x(n)<n?A:b(n)<n?O:s(n)<n?I:e(n)<n?c(n)<n?D:R:t(n)<n?L:U)(n)}function E(e,r,i,o){if(null==e&&(e=10),\"number\"==typeof e){var u=Math.abs(i-r)/e,c=n.i(a.d)(function(t){return t[2]}).right(F,u);c===F.length?(o=n.i(a.b)(r/_,i/_,e),e=t):c?(c=F[u/F[c-1][2]<F[c][2]/u?c-1:c],o=c[1],e=c[0]):(o=n.i(a.b)(r,i,e),e=C)}return null==o?e:e.every(o)}var T=n.i(f.a)(f.b,u.a),S=T.invert,P=T.domain,N=M(\".%L\"),A=M(\":%S\"),O=M(\"%I:%M\"),I=M(\"%I %p\"),D=M(\"%a %d\"),R=M(\"%b %d\"),L=M(\"%B\"),U=M(\"%Y\"),F=[[w,1,h],[w,5,5*h],[w,15,15*h],[w,30,30*h],[x,1,d],[x,5,5*d],[x,15,15*d],[x,30,30*d],[b,1,v],[b,3,3*v],[b,6,6*v],[b,12,12*v],[s,1,g],[s,2,2*g],[c,1,m],[e,1,y],[e,3,3*y],[t,1,_]];return T.invert=function(t){return new Date(S(t))},T.domain=function(t){return arguments.length?P(l.a.call(t,i)):P().map(r)},T.ticks=function(t,e){var n,r=P(),i=r[0],o=r[r.length-1],a=o<i;return a&&(n=i,i=o,o=n),n=E(t,i,o,e),n=n?n.range(i,o+1):[],a?n.reverse():n},T.tickFormat=function(t,e){return null==e?k:M(e)},T.nice=function(t,e){var r=P();return(t=E(t,r[0],r[r.length-1],e))?P(n.i(p.a)(r,t)):T},T.copy=function(){return n.i(f.c)(T,o(t,e,c,s,b,x,w,C,M))},T}var a=n(12),u=n(31),c=n(79),s=n(77),l=n(16),f=n(45),p=n(125);e.b=o;var h=1e3,d=60*h,v=60*d,g=24*v,m=7*g,y=30*g,_=365*g;e.a=function(){return o(c.b,c.o,c.p,c.a,c.q,c.r,c.s,c.t,s.timeFormat).domain([new Date(2e3,0,1),new Date(2e3,0,2)])}},function(t,e,n){\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0});var r=n(66);n.d(e,\"creator\",function(){return r.a});var i=n(247);n.d(e,\"local\",function(){return i.a});var o=n(130);n.d(e,\"matcher\",function(){return o.a});var a=n(248);n.d(e,\"mouse\",function(){return a.a});var u=n(67);n.d(e,\"namespace\",function(){return u.a});var c=n(68);n.d(e,\"namespaces\",function(){return c.a});var s=n(249);n.d(e,\"select\",function(){return s.a});var l=n(250);n.d(e,\"selectAll\",function(){return l.a});var f=n(7);n.d(e,\"selection\",function(){return f.a});var p=n(71);n.d(e,\"selector\",function(){return p.a});var h=n(133);n.d(e,\"selectorAll\",function(){return h.a});var d=n(278);n.d(e,\"touch\",function(){return d.a});var v=n(279);n.d(e,\"touches\",function(){return v.a});var g=n(73);n.d(e,\"window\",function(){return g.a});var m=n(70);n.d(e,\"event\",function(){return m.a}),n.d(e,\"customEvent\",function(){return m.b})},function(t,e,n){\"use strict\";var r=function(t){return function(){return this.matches(t)}};if(\"undefined\"!=typeof document){var i=document.documentElement;if(!i.matches){var o=i.webkitMatchesSelector||i.msMatchesSelector||i.mozMatchesSelector||i.oMatchesSelector;r=function(t){return function(){return o.call(this,t)}}}}e.a=r},function(t,e,n){\"use strict\";function r(t,e){this.ownerDocument=t.ownerDocument,this.namespaceURI=t.namespaceURI,this._next=null,this._parent=t,this.__data__=e}var i=n(132),o=n(7);e.b=r,e.a=function(){return new o.b(this._enter||this._groups.map(i.a),this._parents)},r.prototype={constructor:r,appendChild:function(t){return this._parent.insertBefore(t,this._next)},insertBefore:function(t,e){return this._parent.insertBefore(t,e)},querySelector:function(t){return this._parent.querySelector(t)},querySelectorAll:function(t){return this._parent.querySelectorAll(t)}}},function(t,e,n){\"use strict\";e.a=function(t){return new Array(t.length)}},function(t,e,n){\"use strict\";function r(){return[]}e.a=function(t){return null==t?r:function(){return this.querySelectorAll(t)}}},function(t,e,n){\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0});var r=n(280);n.d(e,\"arc\",function(){return r.a});var i=n(135);n.d(e,\"area\",function(){return i.a});var o=n(75);n.d(e,\"line\",function(){return o.a});var a=n(299);n.d(e,\"pie\",function(){return a.a});var u=n(300);n.d(e,\"radialArea\",function(){return u.a});var c=n(140);n.d(e,\"radialLine\",function(){return c.a});var s=n(302);n.d(e,\"symbol\",function(){return s.a}),n.d(e,\"symbols\",function(){return s.b});var l=n(141);n.d(e,\"symbolCircle\",function(){return l.a});var f=n(142);n.d(e,\"symbolCross\",function(){return f.a});var p=n(143);n.d(e,\"symbolDiamond\",function(){return p.a});var h=n(144);n.d(e,\"symbolSquare\",function(){return h.a});var d=n(145);n.d(e,\"symbolStar\",function(){return d.a});var v=n(146);n.d(e,\"symbolTriangle\",function(){return v.a});var g=n(147);n.d(e,\"symbolWye\",function(){return g.a});var m=n(282);n.d(e,\"curveBasisClosed\",function(){return m.a});var y=n(283);n.d(e,\"curveBasisOpen\",function(){return y.a});var _=n(46);n.d(e,\"curveBasis\",function(){return _.a});var b=n(284);n.d(e,\"curveBundle\",function(){return b.a});var x=n(136);n.d(e,\"curveCardinalClosed\",function(){return x.a});var w=n(137);n.d(e,\"curveCardinalOpen\",function(){return w.a});var C=n(47);n.d(e,\"curveCardinal\",function(){return C.a});var M=n(285);n.d(e,\"curveCatmullRomClosed\",function(){return M.a});var k=n(286);n.d(e,\"curveCatmullRomOpen\",function(){return k.a});var E=n(74);n.d(e,\"curveCatmullRom\",function(){return E.a});var T=n(287);n.d(e,\"curveLinearClosed\",function(){return T.a});var S=n(48);n.d(e,\"curveLinear\",function(){return S.a});var P=n(288);n.d(e,\"curveMonotoneX\",function(){return P.a}),n.d(e,\"curveMonotoneY\",function(){return P.b});var N=n(289);n.d(e,\"curveNatural\",function(){return N.a});var A=n(290);n.d(e,\"curveStep\",function(){return A.a}),n.d(e,\"curveStepAfter\",function(){return A.b}),n.d(e,\"curveStepBefore\",function(){return A.c});var O=n(301);n.d(e,\"stack\",function(){return O.a});var I=n(293);n.d(e,\"stackOffsetExpand\",function(){return I.a});var D=n(36);n.d(e,\"stackOffsetNone\",function(){return D.a});var R=n(294);n.d(e,\"stackOffsetSilhouette\",function(){return R.a});var L=n(295);n.d(e,\"stackOffsetWiggle\",function(){return L.a});var U=n(76);n.d(e,\"stackOrderAscending\",function(){return U.a});var F=n(296);n.d(e,\"stackOrderDescending\",function(){return F.a});var j=n(297);n.d(e,\"stackOrderInsideOut\",function(){return j.a});var B=n(37);n.d(e,\"stackOrderNone\",function(){return B.a});var W=n(298);n.d(e,\"stackOrderReverse\",function(){return W.a})},function(t,e,n){\"use strict\";var r=n(44),i=n(19),o=n(48),a=n(75),u=n(139);e.a=function(){function t(t){var e,i,o,a,u,g=t.length,m=!1,y=new Array(g),_=new Array(g);for(null==h&&(v=d(u=n.i(r.a)())),e=0;e<=g;++e){if(!(e<g&&p(a=t[e],e,t))===m)if(m=!m)i=e,v.areaStart(),v.lineStart();else{for(v.lineEnd(),v.lineStart(),o=e-1;o>=i;--o)v.point(y[o],_[o]);v.lineEnd(),v.areaEnd()}m&&(y[e]=+c(a,e,t),_[e]=+l(a,e,t),v.point(s?+s(a,e,t):y[e],f?+f(a,e,t):_[e]))}if(u)return v=null,u+\"\"||null}function e(){return n.i(a.a)().defined(p).curve(d).context(h)}var c=u.a,s=null,l=n.i(i.a)(0),f=u.b,p=n.i(i.a)(!0),h=null,d=o.a,v=null;return t.x=function(e){return arguments.length?(c=\"function\"==typeof e?e:n.i(i.a)(+e),s=null,t):c},t.x0=function(e){return arguments.length?(c=\"function\"==typeof e?e:n.i(i.a)(+e),t):c},t.x1=function(e){return arguments.length?(s=null==e?null:\"function\"==typeof e?e:n.i(i.a)(+e),t):s},t.y=function(e){return arguments.length?(l=\"function\"==typeof e?e:n.i(i.a)(+e),f=null,t):l},t.y0=function(e){return arguments.length?(l=\"function\"==typeof e?e:n.i(i.a)(+e),t):l},t.y1=function(e){return arguments.length?(f=null==e?null:\"function\"==typeof e?e:n.i(i.a)(+e),t):f},t.lineX0=t.lineY0=function(){return e().x(c).y(l)},t.lineY1=function(){return e().x(c).y(f)},t.lineX1=function(){return e().x(s).y(l)},t.defined=function(e){return arguments.length?(p=\"function\"==typeof e?e:n.i(i.a)(!!e),t):p},t.curve=function(e){return arguments.length?(d=e,null!=h&&(v=d(h)),t):d},t.context=function(e){return arguments.length?(null==e?h=v=null:v=d(h=e),t):h},t}},function(t,e,n){\"use strict\";function r(t,e){this._context=t,this._k=(1-e)/6}var i=n(49),o=n(47);e.b=r,r.prototype={areaStart:i.a,areaEnd:i.a,lineStart:function(){this._x0=this._x1=this._x2=this._x3=this._x4=this._x5=this._y0=this._y1=this._y2=this._y3=this._y4=this._y5=NaN,this._point=0},lineEnd:function(){switch(this._point){case 1:this._context.moveTo(this._x3,this._y3),this._context.closePath();break;case 2:this._context.lineTo(this._x3,this._y3),this._context.closePath();break;case 3:this.point(this._x3,this._y3),this.point(this._x4,this._y4),this.point(this._x5,this._y5)}},point:function(t,e){switch(t=+t,e=+e,this._point){case 0:this._point=1,this._x3=t,this._y3=e;break;case 1:this._point=2,this._context.moveTo(this._x4=t,this._y4=e);break;case 2:this._point=3,this._x5=t,this._y5=e;break;default:n.i(o.c)(this,t,e)}this._x0=this._x1,this._x1=this._x2,this._x2=t,this._y0=this._y1,this._y1=this._y2,this._y2=e}},e.a=function t(e){function n(t){return new r(t,e)}return n.tension=function(e){return t(+e)},n}(0)},function(t,e,n){\"use strict\";function r(t,e){this._context=t,this._k=(1-e)/6}var i=n(47);e.b=r,r.prototype={areaStart:function(){this._line=0},areaEnd:function(){this._line=NaN},lineStart:function(){this._x0=this._x1=this._x2=this._y0=this._y1=this._y2=NaN,this._point=0},lineEnd:function(){(this._line||0!==this._line&&3===this._point)&&this._context.closePath(),this._line=1-this._line},point:function(t,e){switch(t=+t,e=+e,this._point){case 0:this._point=1;break;case 1:this._point=2;break;case 2:this._point=3,this._line?this._context.lineTo(this._x2,this._y2):this._context.moveTo(this._x2,this._y2);break;case 3:this._point=4;default:n.i(i.c)(this,t,e)}this._x0=this._x1,this._x1=this._x2,this._x2=t,this._y0=this._y1,this._y1=this._y2,this._y2=e}},e.a=function t(e){function n(t){return new r(t,e)}return n.tension=function(e){return t(+e)},n}(0)},function(t,e,n){\"use strict\";function r(t){this._curve=t}function i(t){function e(e){return new r(t(e))}return e._curve=t,e}var o=n(48);n.d(e,\"b\",function(){return a}),e.a=i;var a=i(o.a);r.prototype={areaStart:function(){this._curve.areaStart()},areaEnd:function(){this._curve.areaEnd()},lineStart:function(){this._curve.lineStart()},lineEnd:function(){this._curve.lineEnd()},point:function(t,e){this._curve.point(e*Math.sin(t),e*-Math.cos(t))}}},function(t,e,n){\"use strict\";function r(t){return t[0]}function i(t){return t[1]}e.a=r,e.b=i},function(t,e,n){\"use strict\";function r(t){var e=t.curve;return t.angle=t.x,delete t.x,t.radius=t.y,delete t.y,t.curve=function(t){return arguments.length?e(n.i(i.a)(t)):e()._curve},t}var i=n(138),o=n(75);e.b=r,e.a=function(){return r(n.i(o.a)().curve(i.b))}},function(t,e,n){\"use strict\";var r=n(35);e.a={draw:function(t,e){var n=Math.sqrt(e/r.b);t.moveTo(n,0),t.arc(0,0,n,0,r.c)}}},function(t,e,n){\"use strict\";e.a={draw:function(t,e){var n=Math.sqrt(e/5)/2;t.moveTo(-3*n,-n),t.lineTo(-n,-n),t.lineTo(-n,-3*n),t.lineTo(n,-3*n),t.lineTo(n,-n),t.lineTo(3*n,-n),t.lineTo(3*n,n),t.lineTo(n,n),t.lineTo(n,3*n),t.lineTo(-n,3*n),t.lineTo(-n,n),t.lineTo(-3*n,n),t.closePath()}}},function(t,e,n){\"use strict\";var r=Math.sqrt(1/3),i=2*r;e.a={draw:function(t,e){var n=Math.sqrt(e/i),o=n*r;t.moveTo(0,-n),t.lineTo(o,0),t.lineTo(0,n),t.lineTo(-o,0),t.closePath()}}},function(t,e,n){\"use strict\";e.a={draw:function(t,e){var n=Math.sqrt(e),r=-n/2;t.rect(r,r,n,n)}}},function(t,e,n){\"use strict\";var r=n(35),i=.8908130915292852,o=Math.sin(r.b/10)/Math.sin(7*r.b/10),a=Math.sin(r.c/10)*o,u=-Math.cos(r.c/10)*o;e.a={draw:function(t,e){var n=Math.sqrt(e*i),o=a*n,c=u*n;t.moveTo(0,-n),t.lineTo(o,c);for(var s=1;s<5;++s){var l=r.c*s/5,f=Math.cos(l),p=Math.sin(l);t.lineTo(p*n,-f*n),t.lineTo(f*o-p*c,p*o+f*c)}t.closePath()}}},function(t,e,n){\"use strict\";var r=Math.sqrt(3);e.a={draw:function(t,e){var n=-Math.sqrt(e/(3*r));t.moveTo(0,2*n),t.lineTo(-r*n,-n),t.lineTo(r*n,-n),t.closePath()}}},function(t,e,n){\"use strict\";var r=-.5,i=Math.sqrt(3)/2,o=1/Math.sqrt(12),a=3*(o/2+1);e.a={draw:function(t,e){var n=Math.sqrt(e/a),u=n/2,c=n*o,s=u,l=n*o+n,f=-s,p=l;t.moveTo(u,c),t.lineTo(s,l),t.lineTo(f,p),t.lineTo(r*u-i*c,i*u+r*c),t.lineTo(r*s-i*l,i*s+r*l),t.lineTo(r*f-i*p,i*f+r*p),t.lineTo(r*u+i*c,r*c-i*u),t.lineTo(r*s+i*l,r*l-i*s),t.lineTo(r*f+i*p,r*p-i*f),t.closePath()}}},function(t,e,n){\"use strict\";function r(t){return t.toISOString()}var i=n(78);n.d(e,\"b\",function(){return o});var o=\"%Y-%m-%dT%H:%M:%S.%LZ\",a=Date.prototype.toISOString?r:n.i(i.d)(o);e.a=a},function(t,e,n){\"use strict\";function r(t){if(0<=t.y&&t.y<100){var e=new Date(-1,t.m,t.d,t.H,t.M,t.S,t.L);return e.setFullYear(t.y),e}return new Date(t.y,t.m,t.d,t.H,t.M,t.S,t.L)}function i(t){if(0<=t.y&&t.y<100){var e=new Date(Date.UTC(-1,t.m,t.d,t.H,t.M,t.S,t.L));return e.setUTCFullYear(t.y),e}return new Date(Date.UTC(t.y,t.m,t.d,t.H,t.M,t.S,t.L))}function o(t){return{y:t,m:0,d:1,H:0,M:0,S:0,L:0}}function a(t){function e(t,e){return function(n){var r,i,o,a=[],u=-1,c=0,s=t.length;for(n instanceof Date||(n=new Date(+n));++u<s;)37===t.charCodeAt(u)&&(a.push(t.slice(c,u)),null!=(i=et[r=t.charAt(++u)])?r=t.charAt(++u):i=\"e\"===r?\" \":\"0\",(o=e[r])&&(r=o(n,i)),a.push(r),c=u+1);return a.push(t.slice(c,u)),a.join(\"\")}}function n(t,e){return function(n){var r=o(1900),u=a(r,t,n+=\"\",0);if(u!=n.length)return null;if(\"p\"in r&&(r.H=r.H%12+12*r.p),\"W\"in r||\"U\"in r){\"w\"in r||(r.w=\"W\"in r?1:0);var c=\"Z\"in r?i(o(r.y)).getUTCDay():e(o(r.y)).getDay();r.m=0,r.d=\"W\"in r?(r.w+6)%7+7*r.W-(c+5)%7:r.w+7*r.U-(c+6)%7}return\"Z\"in r?(r.H+=r.Z/100|0,r.M+=r.Z%100,i(r)):e(r)}}function a(t,e,n,r){for(var i,o,a=0,u=e.length,c=n.length;a<u;){if(r>=c)return-1;if(i=e.charCodeAt(a++),37===i){if(i=e.charAt(a++),o=Ut[i in et?e.charAt(a++):i],!o||(r=o(t,n,r))<0)return-1}else if(i!=n.charCodeAt(r++))return-1}return r}function u(t,e,n){var r=kt.exec(e.slice(n));return r?(t.p=Et[r[0].toLowerCase()],n+r[0].length):-1}function c(t,e,n){var r=Pt.exec(e.slice(n));return r?(t.w=Nt[r[0].toLowerCase()],n+r[0].length):-1}function tt(t,e,n){var r=Tt.exec(e.slice(n));return r?(t.w=St[r[0].toLowerCase()],n+r[0].length):-1}function nt(t,e,n){var r=It.exec(e.slice(n));return r?(t.m=Dt[r[0].toLowerCase()],n+r[0].length):-1}function rt(t,e,n){var r=At.exec(e.slice(n));return r?(t.m=Ot[r[0].toLowerCase()],n+r[0].length):-1}function it(t,e,n){return a(t,mt,e,n)}function ot(t,e,n){return a(t,yt,e,n)}function at(t,e,n){return a(t,_t,e,n)}function ut(t){return wt[t.getDay()]}function ct(t){return xt[t.getDay()]}function st(t){return Mt[t.getMonth()]}function lt(t){return Ct[t.getMonth()]}function ft(t){return bt[+(t.getHours()>=12)]}function pt(t){return wt[t.getUTCDay()]}function ht(t){return xt[t.getUTCDay()]}function dt(t){return Mt[t.getUTCMonth()]}function vt(t){return Ct[t.getUTCMonth()]}function gt(t){return bt[+(t.getUTCHours()>=12)]}var mt=t.dateTime,yt=t.date,_t=t.time,bt=t.periods,xt=t.days,wt=t.shortDays,Ct=t.months,Mt=t.shortMonths,kt=s(bt),Et=l(bt),Tt=s(xt),St=l(xt),Pt=s(wt),Nt=l(wt),At=s(Ct),Ot=l(Ct),It=s(Mt),Dt=l(Mt),Rt={a:ut,A:ct,b:st,B:lt,c:null,d:k,e:k,H:E,I:T,j:S,L:P,m:N,M:A,p:ft,S:O,U:I,w:D,W:R,x:null,X:null,y:L,Y:U,Z:F,\"%\":J},Lt={a:pt,A:ht,b:dt,B:vt,c:null,d:j,e:j,H:B,I:W,j:V,L:z,m:H,M:q,p:gt,S:Y,U:K,w:G,W:$,x:null,X:null,y:X,Y:Z,Z:Q,\"%\":J},Ut={a:c,A:tt,b:nt,B:rt,c:it,d:y,e:y,H:b,I:b,j:_,L:C,m:m,M:x,p:u,S:w,U:p,w:f,W:h,x:ot,X:at,y:v,Y:d,Z:g,\"%\":M};return Rt.x=e(yt,Rt),Rt.X=e(_t,Rt),Rt.c=e(mt,Rt),Lt.x=e(yt,Lt),Lt.X=e(_t,Lt),Lt.c=e(mt,Lt),{format:function(t){var n=e(t+=\"\",Rt);return n.toString=function(){return t},n},parse:function(t){var e=n(t+=\"\",r);return e.toString=function(){return t},e},utcFormat:function(t){var n=e(t+=\"\",Lt);return n.toString=function(){return t},n},utcParse:function(t){var e=n(t,i);return e.toString=function(){return t},e}}}function u(t,e,n){var r=t<0?\"-\":\"\",i=(r?-t:t)+\"\",o=i.length;return r+(o<n?new Array(n-o+1).join(e)+i:i)}function c(t){return t.replace(it,\"\\\\$&\")}function s(t){return new RegExp(\"^(?:\"+t.map(c).join(\"|\")+\")\",\"i\")}function l(t){for(var e={},n=-1,r=t.length;++n<r;)e[t[n].toLowerCase()]=n;return e}function f(t,e,n){var r=nt.exec(e.slice(n,n+1));return r?(t.w=+r[0],n+r[0].length):-1}function p(t,e,n){var r=nt.exec(e.slice(n));return r?(t.U=+r[0],n+r[0].length):-1}function h(t,e,n){var r=nt.exec(e.slice(n));return r?(t.W=+r[0],n+r[0].length):-1}function d(t,e,n){var r=nt.exec(e.slice(n,n+4));return r?(t.y=+r[0],n+r[0].length):-1}function v(t,e,n){var r=nt.exec(e.slice(n,n+2));return r?(t.y=+r[0]+(+r[0]>68?1900:2e3),n+r[0].length):-1}function g(t,e,n){var r=/^(Z)|([+-]\\d\\d)(?:\\:?(\\d\\d))?/.exec(e.slice(n,n+6));return r?(t.Z=r[1]?0:-(r[2]+(r[3]||\"00\")),n+r[0].length):-1}function m(t,e,n){var r=nt.exec(e.slice(n,n+2));return r?(t.m=r[0]-1,n+r[0].length):-1}function y(t,e,n){var r=nt.exec(e.slice(n,n+2));return r?(t.d=+r[0],n+r[0].length):-1}function _(t,e,n){var r=nt.exec(e.slice(n,n+3));return r?(t.m=0,t.d=+r[0],n+r[0].length):-1}function b(t,e,n){var r=nt.exec(e.slice(n,n+2));return r?(t.H=+r[0],n+r[0].length):-1}function x(t,e,n){var r=nt.exec(e.slice(n,n+2));return r?(t.M=+r[0],n+r[0].length):-1}function w(t,e,n){var r=nt.exec(e.slice(n,n+2));return r?(t.S=+r[0],n+r[0].length):-1}function C(t,e,n){var r=nt.exec(e.slice(n,n+3));return r?(t.L=+r[0],n+r[0].length):-1}function M(t,e,n){var r=rt.exec(e.slice(n,n+1));return r?n+r[0].length:-1}function k(t,e){return u(t.getDate(),e,2)}function E(t,e){return u(t.getHours(),e,2)}function T(t,e){return u(t.getHours()%12||12,e,2)}function S(t,e){return u(1+tt.a.count(n.i(tt.b)(t),t),e,3)}function P(t,e){return u(t.getMilliseconds(),e,3)}function N(t,e){return u(t.getMonth()+1,e,2)}function A(t,e){return u(t.getMinutes(),e,2)}function O(t,e){return u(t.getSeconds(),e,2)}function I(t,e){return u(tt.c.count(n.i(tt.b)(t),t),e,2)}function D(t){return t.getDay()}function R(t,e){return u(tt.d.count(n.i(tt.b)(t),t),e,2)}function L(t,e){return u(t.getFullYear()%100,e,2)}function U(t,e){return u(t.getFullYear()%1e4,e,4)}function F(t){var e=t.getTimezoneOffset();return(e>0?\"-\":(e*=-1,\"+\"))+u(e/60|0,\"0\",2)+u(e%60,\"0\",2)}function j(t,e){return u(t.getUTCDate(),e,2)}function B(t,e){return u(t.getUTCHours(),e,2)}function W(t,e){return u(t.getUTCHours()%12||12,e,2)}function V(t,e){return u(1+tt.e.count(n.i(tt.f)(t),t),e,3)}function z(t,e){return u(t.getUTCMilliseconds(),e,3)}function H(t,e){return u(t.getUTCMonth()+1,e,2)}function q(t,e){return u(t.getUTCMinutes(),e,2)}function Y(t,e){return u(t.getUTCSeconds(),e,2)}function K(t,e){return u(tt.g.count(n.i(tt.f)(t),t),e,2)}function G(t){return t.getUTCDay()}function $(t,e){return u(tt.h.count(n.i(tt.f)(t),t),e,2)}function X(t,e){return u(t.getUTCFullYear()%100,e,2)}function Z(t,e){return u(t.getUTCFullYear()%1e4,e,4)}function Q(){return\"+0000\"}function J(){return\"%\"}var tt=n(79);e.a=a;var et={\"-\":\"\",_:\" \",0:\"0\"},nt=/^\\s*\\d+/,rt=/^%/,it=/[\\\\\\^\\$\\*\\+\\?\\|\\[\\]\\(\\)\\.\\{\\}]/g},function(t,e,n){\"use strict\";var r=n(8),i={listen:function(t,e,n){return t.addEventListener?(t.addEventListener(e,n,!1),{remove:function(){t.removeEventListener(e,n,!1)}}):t.attachEvent?(t.attachEvent(\"on\"+e,n),{remove:function(){t.detachEvent(\"on\"+e,n)}}):void 0},capture:function(t,e,n){return t.addEventListener?(t.addEventListener(e,n,!0),{remove:function(){t.removeEventListener(e,n,!0)}}):{remove:r}},registerDefault:function(){}};t.exports=i},function(t,e,n){\"use strict\";function r(t){try{t.focus()}catch(t){}}t.exports=r},function(t,e,n){\"use strict\";function r(){if(\"undefined\"==typeof document)return null;try{return document.activeElement||document.body}catch(t){return document.body}}t.exports=r},function(t,e){function n(){throw new Error(\"setTimeout has not been defined\")}function r(){throw new Error(\"clearTimeout has not been defined\")}function i(t){if(l===setTimeout)return setTimeout(t,0);if((l===n||!l)&&setTimeout)return l=setTimeout,setTimeout(t,0);try{return l(t,0)}catch(e){try{return l.call(null,t,0)}catch(e){return l.call(this,t,0)}}}function o(t){if(f===clearTimeout)return clearTimeout(t);if((f===r||!f)&&clearTimeout)return f=clearTimeout,clearTimeout(t);try{return f(t)}catch(e){try{return f.call(null,t)}catch(e){return f.call(this,t)}}}function a(){v&&h&&(v=!1,h.length?d=h.concat(d):g=-1,d.length&&u())}function u(){if(!v){var t=i(a);v=!0;for(var e=d.length;e;){for(h=d,d=[];++g<e;)h&&h[g].run();g=-1,e=d.length}h=null,v=!1,o(t)}}function c(t,e){this.fun=t,this.array=e}function s(){}var l,f,p=t.exports={};!function(){try{l=\"function\"==typeof setTimeout?setTimeout:n}catch(t){l=n}try{f=\"function\"==typeof clearTimeout?clearTimeout:r}catch(t){f=r}}();var h,d=[],v=!1,g=-1;p.nextTick=function(t){var e=new Array(arguments.length-1);if(arguments.length>1)for(var n=1;n<arguments.length;n++)e[n-1]=arguments[n];d.push(new c(t,e)),1!==d.length||v||i(u)},c.prototype.run=function(){this.fun.apply(null,this.array)},p.title=\"browser\",p.browser=!0,p.env={},p.argv=[],p.version=\"\",p.versions={},p.on=s,p.addListener=s,p.once=s,p.off=s,p.removeListener=s,p.removeAllListeners=s,p.emit=s,p.binding=function(t){throw new Error(\"process.binding is not supported\")},p.cwd=function(){return\"/\"},p.chdir=function(t){throw new Error(\"process.chdir is not supported\")},p.umask=function(){\n",
       "return 0}},function(t,e,n){\"use strict\";function r(t,e){return t+e.charAt(0).toUpperCase()+e.substring(1)}var i={animationIterationCount:!0,borderImageOutset:!0,borderImageSlice:!0,borderImageWidth:!0,boxFlex:!0,boxFlexGroup:!0,boxOrdinalGroup:!0,columnCount:!0,flex:!0,flexGrow:!0,flexPositive:!0,flexShrink:!0,flexNegative:!0,flexOrder:!0,gridRow:!0,gridColumn:!0,fontWeight:!0,lineClamp:!0,lineHeight:!0,opacity:!0,order:!0,orphans:!0,tabSize:!0,widows:!0,zIndex:!0,zoom:!0,fillOpacity:!0,floodOpacity:!0,stopOpacity:!0,strokeDasharray:!0,strokeDashoffset:!0,strokeMiterlimit:!0,strokeOpacity:!0,strokeWidth:!0},o=[\"Webkit\",\"ms\",\"Moz\",\"O\"];Object.keys(i).forEach(function(t){o.forEach(function(e){i[r(e,t)]=i[t]})});var a={background:{backgroundAttachment:!0,backgroundColor:!0,backgroundImage:!0,backgroundPositionX:!0,backgroundPositionY:!0,backgroundRepeat:!0},backgroundPosition:{backgroundPositionX:!0,backgroundPositionY:!0},border:{borderWidth:!0,borderStyle:!0,borderColor:!0},borderBottom:{borderBottomWidth:!0,borderBottomStyle:!0,borderBottomColor:!0},borderLeft:{borderLeftWidth:!0,borderLeftStyle:!0,borderLeftColor:!0},borderRight:{borderRightWidth:!0,borderRightStyle:!0,borderRightColor:!0},borderTop:{borderTopWidth:!0,borderTopStyle:!0,borderTopColor:!0},font:{fontStyle:!0,fontVariant:!0,fontWeight:!0,fontSize:!0,lineHeight:!0,fontFamily:!0},outline:{outlineWidth:!0,outlineStyle:!0,outlineColor:!0}},u={isUnitlessNumber:i,shorthandPropertyExpansions:a};t.exports=u},function(t,e,n){\"use strict\";function r(t,e){if(!(t instanceof e))throw new TypeError(\"Cannot call a class as a function\")}var i=n(2),o=n(17),a=(n(0),function(){function t(e){r(this,t),this._callbacks=null,this._contexts=null,this._arg=e}return t.prototype.enqueue=function(t,e){this._callbacks=this._callbacks||[],this._callbacks.push(t),this._contexts=this._contexts||[],this._contexts.push(e)},t.prototype.notifyAll=function(){var t=this._callbacks,e=this._contexts,n=this._arg;if(t&&e){t.length!==e.length?i(\"24\"):void 0,this._callbacks=null,this._contexts=null;for(var r=0;r<t.length;r++)t[r].call(e[r],n);t.length=0,e.length=0}},t.prototype.checkpoint=function(){return this._callbacks?this._callbacks.length:0},t.prototype.rollback=function(t){this._callbacks&&this._contexts&&(this._callbacks.length=t,this._contexts.length=t)},t.prototype.reset=function(){this._callbacks=null,this._contexts=null},t.prototype.destructor=function(){this.reset()},t}());t.exports=o.addPoolingTo(a)},function(t,e,n){\"use strict\";function r(t){return!!s.hasOwnProperty(t)||!c.hasOwnProperty(t)&&(u.test(t)?(s[t]=!0,!0):(c[t]=!0,!1))}function i(t,e){return null==e||t.hasBooleanValue&&!e||t.hasNumericValue&&isNaN(e)||t.hasPositiveNumericValue&&e<1||t.hasOverloadedBooleanValue&&e===!1}var o=n(21),a=(n(4),n(9),n(394)),u=(n(1),new RegExp(\"^[\"+o.ATTRIBUTE_NAME_START_CHAR+\"][\"+o.ATTRIBUTE_NAME_CHAR+\"]*$\")),c={},s={},l={createMarkupForID:function(t){return o.ID_ATTRIBUTE_NAME+\"=\"+a(t)},setAttributeForID:function(t,e){t.setAttribute(o.ID_ATTRIBUTE_NAME,e)},createMarkupForRoot:function(){return o.ROOT_ATTRIBUTE_NAME+'=\"\"'},setAttributeForRoot:function(t){t.setAttribute(o.ROOT_ATTRIBUTE_NAME,\"\")},createMarkupForProperty:function(t,e){var n=o.properties.hasOwnProperty(t)?o.properties[t]:null;if(n){if(i(n,e))return\"\";var r=n.attributeName;return n.hasBooleanValue||n.hasOverloadedBooleanValue&&e===!0?r+'=\"\"':r+\"=\"+a(e)}return o.isCustomAttribute(t)?null==e?\"\":t+\"=\"+a(e):null},createMarkupForCustomAttribute:function(t,e){return r(t)&&null!=e?t+\"=\"+a(e):\"\"},setValueForProperty:function(t,e,n){var r=o.properties.hasOwnProperty(e)?o.properties[e]:null;if(r){var a=r.mutationMethod;if(a)a(t,n);else{if(i(r,n))return void this.deleteValueForProperty(t,e);if(r.mustUseProperty)t[r.propertyName]=n;else{var u=r.attributeName,c=r.attributeNamespace;c?t.setAttributeNS(c,u,\"\"+n):r.hasBooleanValue||r.hasOverloadedBooleanValue&&n===!0?t.setAttribute(u,\"\"):t.setAttribute(u,\"\"+n)}}}else if(o.isCustomAttribute(e))return void l.setValueForAttribute(t,e,n)},setValueForAttribute:function(t,e,n){if(r(e)){null==n?t.removeAttribute(e):t.setAttribute(e,\"\"+n)}},deleteValueForAttribute:function(t,e){t.removeAttribute(e)},deleteValueForProperty:function(t,e){var n=o.properties.hasOwnProperty(e)?o.properties[e]:null;if(n){var r=n.mutationMethod;if(r)r(t,void 0);else if(n.mustUseProperty){var i=n.propertyName;n.hasBooleanValue?t[i]=!1:t[i]=\"\"}else t.removeAttribute(n.attributeName)}else o.isCustomAttribute(e)&&t.removeAttribute(e)}};t.exports=l},function(t,e,n){\"use strict\";var r={hasCachedChildNodes:1};t.exports=r},function(t,e,n){\"use strict\";function r(){if(this._rootNodeID&&this._wrapperState.pendingUpdate){this._wrapperState.pendingUpdate=!1;var t=this._currentElement.props,e=u.getValue(t);null!=e&&i(this,Boolean(t.multiple),e)}}function i(t,e,n){var r,i,o=c.getNodeFromInstance(t).options;if(e){for(r={},i=0;i<n.length;i++)r[\"\"+n[i]]=!0;for(i=0;i<o.length;i++){var a=r.hasOwnProperty(o[i].value);o[i].selected!==a&&(o[i].selected=a)}}else{for(r=\"\"+n,i=0;i<o.length;i++)if(o[i].value===r)return void(o[i].selected=!0);o.length&&(o[0].selected=!0)}}function o(t){var e=this._currentElement.props,n=u.executeOnChange(e,t);return this._rootNodeID&&(this._wrapperState.pendingUpdate=!0),s.asap(r,this),n}var a=n(3),u=n(85),c=n(4),s=n(11),l=(n(1),!1),f={getHostProps:function(t,e){return a({},e,{onChange:t._wrapperState.onChange,value:void 0})},mountWrapper:function(t,e){var n=u.getValue(e);t._wrapperState={pendingUpdate:!1,initialValue:null!=n?n:e.defaultValue,listeners:null,onChange:o.bind(t),wasMultiple:Boolean(e.multiple)},void 0===e.value||void 0===e.defaultValue||l||(l=!0)},getSelectValueContext:function(t){return t._wrapperState.initialValue},postUpdateWrapper:function(t){var e=t._currentElement.props;t._wrapperState.initialValue=void 0;var n=t._wrapperState.wasMultiple;t._wrapperState.wasMultiple=Boolean(e.multiple);var r=u.getValue(e);null!=r?(t._wrapperState.pendingUpdate=!1,i(t,Boolean(e.multiple),r)):n!==Boolean(e.multiple)&&(null!=e.defaultValue?i(t,Boolean(e.multiple),e.defaultValue):i(t,Boolean(e.multiple),e.multiple?[]:\"\"))}};t.exports=f},function(t,e,n){\"use strict\";var r,i={injectEmptyComponentFactory:function(t){r=t}},o={create:function(t){return r(t)}};o.injection=i,t.exports=o},function(t,e,n){\"use strict\";var r={logTopLevelRenders:!1};t.exports=r},function(t,e,n){\"use strict\";function r(t){return u?void 0:a(\"111\",t.type),new u(t)}function i(t){return new c(t)}function o(t){return t instanceof c}var a=n(2),u=(n(0),null),c=null,s={injectGenericComponentClass:function(t){u=t},injectTextComponentClass:function(t){c=t}},l={createInternalComponent:r,createInstanceForText:i,isTextComponent:o,injection:s};t.exports=l},function(t,e,n){\"use strict\";function r(t){return o(document.documentElement,t)}var i=n(353),o=n(320),a=n(151),u=n(152),c={hasSelectionCapabilities:function(t){var e=t&&t.nodeName&&t.nodeName.toLowerCase();return e&&(\"input\"===e&&\"text\"===t.type||\"textarea\"===e||\"true\"===t.contentEditable)},getSelectionInformation:function(){var t=u();return{focusedElem:t,selectionRange:c.hasSelectionCapabilities(t)?c.getSelection(t):null}},restoreSelection:function(t){var e=u(),n=t.focusedElem,i=t.selectionRange;e!==n&&r(n)&&(c.hasSelectionCapabilities(n)&&c.setSelection(n,i),a(n))},getSelection:function(t){var e;if(\"selectionStart\"in t)e={start:t.selectionStart,end:t.selectionEnd};else if(document.selection&&t.nodeName&&\"input\"===t.nodeName.toLowerCase()){var n=document.selection.createRange();n.parentElement()===t&&(e={start:-n.moveStart(\"character\",-t.value.length),end:-n.moveEnd(\"character\",-t.value.length)})}else e=i.getOffsets(t);return e||{start:0,end:0}},setSelection:function(t,e){var n=e.start,r=e.end;if(void 0===r&&(r=n),\"selectionStart\"in t)t.selectionStart=n,t.selectionEnd=Math.min(r,t.value.length);else if(document.selection&&t.nodeName&&\"input\"===t.nodeName.toLowerCase()){var o=t.createTextRange();o.collapse(!0),o.moveStart(\"character\",n),o.moveEnd(\"character\",r-n),o.select()}else i.setOffsets(t,e)}};t.exports=c},function(t,e,n){\"use strict\";function r(t,e){for(var n=Math.min(t.length,e.length),r=0;r<n;r++)if(t.charAt(r)!==e.charAt(r))return r;return t.length===e.length?-1:n}function i(t){return t?t.nodeType===D?t.documentElement:t.firstChild:null}function o(t){return t.getAttribute&&t.getAttribute(A)||\"\"}function a(t,e,n,r,i){var o;if(x.logTopLevelRenders){var a=t._currentElement.props.child,u=a.type;o=\"React mount: \"+(\"string\"==typeof u?u:u.displayName||u.name),console.time(o)}var c=M.mountComponent(t,n,null,_(t,e),i,0);o&&console.timeEnd(o),t._renderedComponent._topLevelWrapper=t,j._mountImageIntoNode(c,e,t,r,n)}function u(t,e,n,r){var i=E.ReactReconcileTransaction.getPooled(!n&&b.useCreateElement);i.perform(a,null,t,e,i,n,r),E.ReactReconcileTransaction.release(i)}function c(t,e,n){for(M.unmountComponent(t,n),e.nodeType===D&&(e=e.documentElement);e.lastChild;)e.removeChild(e.lastChild)}function s(t){var e=i(t);if(e){var n=y.getInstanceFromNode(e);return!(!n||!n._hostParent)}}function l(t){return!(!t||t.nodeType!==I&&t.nodeType!==D&&t.nodeType!==R)}function f(t){var e=i(t),n=e&&y.getInstanceFromNode(e);return n&&!n._hostParent?n:null}function p(t){var e=f(t);return e?e._hostContainerInfo._topLevelWrapper:null}var h=n(2),d=n(20),v=n(21),g=n(26),m=n(51),y=(n(15),n(4)),_=n(347),b=n(349),x=n(160),w=n(40),C=(n(9),n(363)),M=n(24),k=n(88),E=n(11),T=n(38),S=n(169),P=(n(0),n(55)),N=n(95),A=(n(1),v.ID_ATTRIBUTE_NAME),O=v.ROOT_ATTRIBUTE_NAME,I=1,D=9,R=11,L={},U=1,F=function(){this.rootID=U++};F.prototype.isReactComponent={},F.prototype.render=function(){return this.props.child},F.isReactTopLevelWrapper=!0;var j={TopLevelWrapper:F,_instancesByReactRootID:L,scrollMonitor:function(t,e){e()},_updateRootComponent:function(t,e,n,r,i){return j.scrollMonitor(r,function(){k.enqueueElementInternal(t,e,n),i&&k.enqueueCallbackInternal(t,i)}),t},_renderNewRootComponent:function(t,e,n,r){l(e)?void 0:h(\"37\"),m.ensureScrollValueMonitoring();var i=S(t,!1);E.batchedUpdates(u,i,e,n,r);var o=i._instance.rootID;return L[o]=i,i},renderSubtreeIntoContainer:function(t,e,n,r){return null!=t&&w.has(t)?void 0:h(\"38\"),j._renderSubtreeIntoContainer(t,e,n,r)},_renderSubtreeIntoContainer:function(t,e,n,r){k.validateCallback(r,\"ReactDOM.render\"),g.isValidElement(e)?void 0:h(\"39\",\"string\"==typeof e?\" Instead of passing a string like 'div', pass React.createElement('div') or <div />.\":\"function\"==typeof e?\" Instead of passing a class like Foo, pass React.createElement(Foo) or <Foo />.\":null!=e&&void 0!==e.props?\" This may be caused by unintentionally loading two independent copies of React.\":\"\");var a,u=g.createElement(F,{child:e});if(t){var c=w.get(t);a=c._processChildContext(c._context)}else a=T;var l=p(n);if(l){var f=l._currentElement,d=f.props.child;if(N(d,e)){var v=l._renderedComponent.getPublicInstance(),m=r&&function(){r.call(v)};return j._updateRootComponent(l,u,a,n,m),v}j.unmountComponentAtNode(n)}var y=i(n),_=y&&!!o(y),b=s(n),x=_&&!l&&!b,C=j._renderNewRootComponent(u,n,x,a)._renderedComponent.getPublicInstance();return r&&r.call(C),C},render:function(t,e,n){return j._renderSubtreeIntoContainer(null,t,e,n)},unmountComponentAtNode:function(t){l(t)?void 0:h(\"40\");var e=p(t);if(!e){s(t),1===t.nodeType&&t.hasAttribute(O);return!1}return delete L[e._instance.rootID],E.batchedUpdates(c,e,t,!1),!0},_mountImageIntoNode:function(t,e,n,o,a){if(l(e)?void 0:h(\"41\"),o){var u=i(e);if(C.canReuseMarkup(t,u))return void y.precacheNode(n,u);var c=u.getAttribute(C.CHECKSUM_ATTR_NAME);u.removeAttribute(C.CHECKSUM_ATTR_NAME);var s=u.outerHTML;u.setAttribute(C.CHECKSUM_ATTR_NAME,c);var f=t,p=r(f,s),v=\" (client) \"+f.substring(p-20,p+20)+\"\\n (server) \"+s.substring(p-20,p+20);e.nodeType===D?h(\"42\",v):void 0}if(e.nodeType===D?h(\"43\"):void 0,a.useCreateElement){for(;e.lastChild;)e.removeChild(e.lastChild);d.insertTreeBefore(e,t,null)}else P(e,t),y.precacheNode(n,e.firstChild)}};t.exports=j},function(t,e,n){\"use strict\";var r=n(2),i=n(26),o=(n(0),{HOST:0,COMPOSITE:1,EMPTY:2,getType:function(t){return null===t||t===!1?o.EMPTY:i.isValidElement(t)?\"function\"==typeof t.type?o.COMPOSITE:o.HOST:void r(\"26\",t)}});t.exports=o},function(t,e,n){\"use strict\";function r(t,e){return null==e?i(\"30\"):void 0,null==t?e:Array.isArray(t)?Array.isArray(e)?(t.push.apply(t,e),t):(t.push(e),t):Array.isArray(e)?[t].concat(e):[t,e]}var i=n(2);n(0);t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n){Array.isArray(t)?t.forEach(e,n):t&&e.call(n,t)}t.exports=r},function(t,e,n){\"use strict\";function r(t){for(var e;(e=t._renderedNodeType)===i.COMPOSITE;)t=t._renderedComponent;return e===i.HOST?t._renderedComponent:e===i.EMPTY?null:void 0}var i=n(164);t.exports=r},function(t,e,n){\"use strict\";function r(){return!o&&i.canUseDOM&&(o=\"textContent\"in document.documentElement?\"textContent\":\"innerText\"),o}var i=n(6),o=null;t.exports=r},function(t,e,n){\"use strict\";function r(t){if(t){var e=t.getName();if(e)return\" Check the render method of `\"+e+\"`.\"}return\"\"}function i(t){return\"function\"==typeof t&&\"undefined\"!=typeof t.prototype&&\"function\"==typeof t.prototype.mountComponent&&\"function\"==typeof t.prototype.receiveComponent}function o(t,e){var n;if(null===t||t===!1)n=s.create(o);else if(\"object\"==typeof t){var u=t,c=u.type;if(\"function\"!=typeof c&&\"string\"!=typeof c){var p=\"\";p+=r(u._owner),a(\"130\",null==c?c:typeof c,p)}\"string\"==typeof u.type?n=l.createInternalComponent(u):i(u.type)?(n=new u.type(u),n.getHostNode||(n.getHostNode=n.getNativeNode)):n=new f(u)}else\"string\"==typeof t||\"number\"==typeof t?n=l.createInstanceForText(t):a(\"131\",typeof t);return n._mountIndex=0,n._mountImage=null,n}var a=n(2),u=n(3),c=n(344),s=n(159),l=n(161),f=(n(391),n(0),n(1),function(t){this.construct(t)});u(f.prototype,c,{_instantiateReactComponent:o}),t.exports=o},function(t,e,n){\"use strict\";function r(t){var e=t&&t.nodeName&&t.nodeName.toLowerCase();return\"input\"===e?!!i[t.type]:\"textarea\"===e}var i={color:!0,date:!0,datetime:!0,\"datetime-local\":!0,email:!0,month:!0,number:!0,password:!0,range:!0,search:!0,tel:!0,text:!0,time:!0,url:!0,week:!0};t.exports=r},function(t,e,n){\"use strict\";var r=n(6),i=n(54),o=n(55),a=function(t,e){if(e){var n=t.firstChild;if(n&&n===t.lastChild&&3===n.nodeType)return void(n.nodeValue=e)}t.textContent=e};r.canUseDOM&&(\"textContent\"in document.documentElement||(a=function(t,e){return 3===t.nodeType?void(t.nodeValue=e):void o(t,i(e))})),t.exports=a},function(t,e,n){\"use strict\";function r(t,e){return t&&\"object\"==typeof t&&null!=t.key?s.escape(t.key):e.toString(36)}function i(t,e,n,o){var p=typeof t;if(\"undefined\"!==p&&\"boolean\"!==p||(t=null),null===t||\"string\"===p||\"number\"===p||\"object\"===p&&t.$$typeof===u)return n(o,t,\"\"===e?l+r(t,0):e),1;var h,d,v=0,g=\"\"===e?l:e+f;if(Array.isArray(t))for(var m=0;m<t.length;m++)h=t[m],d=g+r(h,m),v+=i(h,d,n,o);else{var y=c(t);if(y){var _,b=y.call(t);if(y!==t.entries)for(var x=0;!(_=b.next()).done;)h=_.value,d=g+r(h,x++),v+=i(h,d,n,o);else for(;!(_=b.next()).done;){var w=_.value;w&&(h=w[1],d=g+s.escape(w[0])+f+r(h,0),v+=i(h,d,n,o))}}else if(\"object\"===p){var C=\"\",M=String(t);a(\"31\",\"[object Object]\"===M?\"object with keys {\"+Object.keys(t).join(\", \")+\"}\":M,C)}}return v}function o(t,e,n){return null==t?0:i(t,\"\",e,n)}var a=n(2),u=(n(15),n(359)),c=n(390),s=(n(0),n(84)),l=(n(1),\".\"),f=\":\";t.exports=o},function(t,e,n){\"use strict\";function r(t){var e=Function.prototype.toString,n=Object.prototype.hasOwnProperty,r=RegExp(\"^\"+e.call(n).replace(/[\\\\^$.*+?()[\\]{}|]/g,\"\\\\$&\").replace(/hasOwnProperty|(function).*?(?=\\\\\\()| for .+?(?=\\\\\\])/g,\"$1.*?\")+\"$\");try{var i=e.call(t);return r.test(i)}catch(t){return!1}}function i(t){var e=s(t);if(e){var n=e.childIDs;l(t),n.forEach(i)}}function o(t,e,n){return\"\\n    in \"+(t||\"Unknown\")+(e?\" (at \"+e.fileName.replace(/^.*[\\\\\\/]/,\"\")+\":\"+e.lineNumber+\")\":n?\" (created by \"+n+\")\":\"\")}function a(t){return null==t?\"#empty\":\"string\"==typeof t||\"number\"==typeof t?\"#text\":\"string\"==typeof t.type?t.type:t.type.displayName||t.type.name||\"Unknown\"}function u(t){var e,n=k.getDisplayName(t),r=k.getElement(t),i=k.getOwnerID(t);return i&&(e=k.getDisplayName(i)),o(n,r&&r._source,e)}var c,s,l,f,p,h,d,v=n(28),g=n(15),m=(n(0),n(1),\"function\"==typeof Array.from&&\"function\"==typeof Map&&r(Map)&&null!=Map.prototype&&\"function\"==typeof Map.prototype.keys&&r(Map.prototype.keys)&&\"function\"==typeof Set&&r(Set)&&null!=Set.prototype&&\"function\"==typeof Set.prototype.keys&&r(Set.prototype.keys));if(m){var y=new Map,_=new Set;c=function(t,e){y.set(t,e)},s=function(t){return y.get(t)},l=function(t){y.delete(t)},f=function(){return Array.from(y.keys())},p=function(t){_.add(t)},h=function(t){_.delete(t)},d=function(){return Array.from(_.keys())}}else{var b={},x={},w=function(t){return\".\"+t},C=function(t){return parseInt(t.substr(1),10)};c=function(t,e){var n=w(t);b[n]=e},s=function(t){var e=w(t);return b[e]},l=function(t){var e=w(t);delete b[e]},f=function(){return Object.keys(b).map(C)},p=function(t){var e=w(t);x[e]=!0},h=function(t){var e=w(t);delete x[e]},d=function(){return Object.keys(x).map(C)}}var M=[],k={onSetChildren:function(t,e){var n=s(t);n?void 0:v(\"144\"),n.childIDs=e;for(var r=0;r<e.length;r++){var i=e[r],o=s(i);o?void 0:v(\"140\"),null==o.childIDs&&\"object\"==typeof o.element&&null!=o.element?v(\"141\"):void 0,o.isMounted?void 0:v(\"71\"),null==o.parentID&&(o.parentID=t),o.parentID!==t?v(\"142\",i,o.parentID,t):void 0}},onBeforeMountComponent:function(t,e,n){var r={element:e,parentID:n,text:null,childIDs:[],isMounted:!1,updateCount:0};c(t,r)},onBeforeUpdateComponent:function(t,e){var n=s(t);n&&n.isMounted&&(n.element=e)},onMountComponent:function(t){var e=s(t);e?void 0:v(\"144\"),e.isMounted=!0;var n=0===e.parentID;n&&p(t)},onUpdateComponent:function(t){var e=s(t);e&&e.isMounted&&e.updateCount++},onUnmountComponent:function(t){var e=s(t);if(e){e.isMounted=!1;var n=0===e.parentID;n&&h(t)}M.push(t)},purgeUnmountedComponents:function(){if(!k._preventPurging){for(var t=0;t<M.length;t++){var e=M[t];i(e)}M.length=0}},isMounted:function(t){var e=s(t);return!!e&&e.isMounted},getCurrentStackAddendum:function(t){var e=\"\";if(t){var n=a(t),r=t._owner;e+=o(n,t._source,r&&r.getName())}var i=g.current,u=i&&i._debugID;return e+=k.getStackAddendumByID(u)},getStackAddendumByID:function(t){for(var e=\"\";t;)e+=u(t),t=k.getParentID(t);return e},getChildIDs:function(t){var e=s(t);return e?e.childIDs:[]},getDisplayName:function(t){var e=k.getElement(t);return e?a(e):null},getElement:function(t){var e=s(t);return e?e.element:null},getOwnerID:function(t){var e=k.getElement(t);return e&&e._owner?e._owner._debugID:null},getParentID:function(t){var e=s(t);return e?e.parentID:null},getSource:function(t){var e=s(t),n=e?e.element:null,r=null!=n?n._source:null;return r},getText:function(t){var e=k.getElement(t);return\"string\"==typeof e?e:\"number\"==typeof e?\"\"+e:null},getUpdateCount:function(t){var e=s(t);return e?e.updateCount:0},getRootIDs:d,getRegisteredIDs:f};t.exports=k},function(t,e,n){\"use strict\";var r=\"function\"==typeof Symbol&&Symbol.for&&Symbol.for(\"react.element\")||60103;t.exports=r},function(t,e,n){\"use strict\";var r={};t.exports=r},function(t,e,n){\"use strict\";var r=!1;t.exports=r},function(t,e,n){\"use strict\";function r(t){var e=t&&(i&&t[i]||t[o]);if(\"function\"==typeof e)return e}var i=\"function\"==typeof Symbol&&Symbol.iterator,o=\"@@iterator\";t.exports=r},,function(t,e,n){\"use strict\";function r(t){return t&&t.__esModule?t:{default:t}}function i(t,e){if(!(t instanceof e))throw new TypeError(\"Cannot call a class as a function\")}function o(t,e){if(!t)throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\");return!e||\"object\"!=typeof e&&\"function\"!=typeof e?t:e}function a(t,e){if(\"function\"!=typeof e&&null!==e)throw new TypeError(\"Super expression must either be null or a function, not \"+typeof e);t.prototype=Object.create(e&&e.prototype,{constructor:{value:t,enumerable:!1,writable:!0,configurable:!0}}),e&&(Object.setPrototypeOf?Object.setPrototypeOf(t,e):t.__proto__=e)}Object.defineProperty(e,\"__esModule\",{value:!0});var u=\"function\"==typeof Symbol&&\"symbol\"==typeof Symbol.iterator?function(t){return typeof t}:function(t){return t&&\"function\"==typeof Symbol&&t.constructor===Symbol&&t!==Symbol.prototype?\"symbol\":typeof t},c=function(){function t(t,e){for(var n=0;n<e.length;n++){var r=e[n];r.enumerable=r.enumerable||!1,r.configurable=!0,\"value\"in r&&(r.writable=!0),Object.defineProperty(t,r.key,r)}}return function(e,n,r){return n&&t(e.prototype,n),r&&t(e,r),e}}(),s=n(41),l=r(s),f=n(129),p=n(64),h=n(30),d=n(77),v=n(112),g=n(134),m=n(10),y=n(39),_=n(56),b=r(_),x=function(t){function e(){i(this,e);var t=o(this,(e.__proto__||Object.getPrototypeOf(e)).call(this));return window.lastAdditiveForceArrayVisualizer=t,t.topOffset=28,t.leftOffset=80,t.height=350,t.effectFormat=(0,h.format)(\".2\"),t.redraw=(0,y.debounce)(function(){return t.draw()},200),t}return a(e,t),c(e,[{key:\"componentDidMount\",value:function(){var t=this;this.mainGroup=this.svg.append(\"g\"),this.onTopGroup=this.svg.append(\"g\"),this.xaxisElement=this.onTopGroup.append(\"g\").attr(\"transform\",\"translate(0,35)\").attr(\"class\",\"force-bar-array-xaxis\"),this.yaxisElement=this.onTopGroup.append(\"g\").attr(\"transform\",\"translate(0,35)\").attr(\"class\",\"force-bar-array-yaxis\"),this.hoverGroup1=this.svg.append(\"g\"),this.hoverGroup2=this.svg.append(\"g\"),this.baseValueTitle=this.svg.append(\"text\"),this.hoverLine=this.svg.append(\"line\"),this.hoverxOutline=this.svg.append(\"text\").attr(\"text-anchor\",\"middle\").attr(\"font-weight\",\"bold\").attr(\"fill\",\"#fff\").attr(\"stroke\",\"#fff\").attr(\"stroke-width\",\"6\").attr(\"font-size\",\"12px\"),this.hoverx=this.svg.append(\"text\").attr(\"text-anchor\",\"middle\").attr(\"font-weight\",\"bold\").attr(\"fill\",\"#000\").attr(\"font-size\",\"12px\"),this.hoverxTitle=this.svg.append(\"text\").attr(\"text-anchor\",\"middle\").attr(\"opacity\",.6).attr(\"font-size\",\"12px\"),this.hoveryOutline=this.svg.append(\"text\").attr(\"text-anchor\",\"end\").attr(\"font-weight\",\"bold\").attr(\"fill\",\"#fff\").attr(\"stroke\",\"#fff\").attr(\"stroke-width\",\"6\").attr(\"font-size\",\"12px\"),this.hovery=this.svg.append(\"text\").attr(\"text-anchor\",\"end\").attr(\"font-weight\",\"bold\").attr(\"fill\",\"#000\").attr(\"font-size\",\"12px\"),this.xlabel=this.wrapper.select(\".additive-force-array-xlabel\"),this.ylabel=this.wrapper.select(\".additive-force-array-ylabel\");var e=void 0;\"string\"==typeof this.props.plot_cmap?this.props.plot_cmap in b.default.colors?e=b.default.colors[this.props.plot_cmap]:(console.log(\"Invalid color map name, reverting to default.\"),e=b.default.colors.RdBu):Array.isArray(this.props.plot_cmap)&&(e=this.props.plot_cmap),this.colors=e.map(function(t){return(0,m.hsl)(t)}),this.brighterColors=[1.45,1.6].map(function(e,n){return t.colors[n].brighter(e)});var n=(0,h.format)(\",.4\");if(null!=this.props.ordering_keys&&null!=this.props.ordering_keys_time_format){var r=function(t){return\"object\"==(\"undefined\"==typeof t?\"undefined\":u(t))?this.formatTime(t):n(t)};this.parseTime=(0,d.timeParse)(this.props.ordering_keys_time_format),this.formatTime=(0,d.timeFormat)(this.props.ordering_keys_time_format),this.xtickFormat=r}else this.parseTime=null,this.formatTime=null,this.xtickFormat=n;this.xscale=(0,p.scaleLinear)(),this.xaxis=(0,v.axisBottom)().scale(this.xscale).tickSizeInner(4).tickSizeOuter(0).tickFormat(function(e){return t.xtickFormat(e)}).tickPadding(-18),this.ytickFormat=n,this.yscale=(0,p.scaleLinear)(),this.yaxis=(0,v.axisLeft)().scale(this.yscale).tickSizeInner(4).tickSizeOuter(0).tickFormat(function(e){return t.ytickFormat(t.invLinkFunction(e))}).tickPadding(2),this.xlabel.node().onchange=function(){return t.internalDraw()},this.ylabel.node().onchange=function(){return t.internalDraw()},this.svg.on(\"mousemove\",function(e){return t.mouseMoved(e)}),this.svg.on(\"click\",function(){return alert(\"This original index of the sample you clicked is \"+t.nearestExpIndex)}),this.svg.on(\"mouseout\",function(e){return t.mouseOut(e)}),window.addEventListener(\"resize\",this.redraw),window.setTimeout(this.redraw,50)}},{key:\"componentDidUpdate\",value:function(){this.draw()}},{key:\"mouseOut\",value:function(){this.hoverLine.attr(\"display\",\"none\"),this.hoverx.attr(\"display\",\"none\"),this.hoverxOutline.attr(\"display\",\"none\"),this.hoverxTitle.attr(\"display\",\"none\"),this.hovery.attr(\"display\",\"none\"),this.hoveryOutline.attr(\"display\",\"none\"),this.hoverGroup1.attr(\"display\",\"none\"),this.hoverGroup2.attr(\"display\",\"none\")}},{key:\"mouseMoved\",value:function(){var t=this,e=void 0,n=void 0;this.hoverLine.attr(\"display\",\"\"),this.hoverx.attr(\"display\",\"\"),this.hoverxOutline.attr(\"display\",\"\"),this.hoverxTitle.attr(\"display\",\"\"),this.hovery.attr(\"display\",\"\"),this.hoveryOutline.attr(\"display\",\"\"),this.hoverGroup1.attr(\"display\",\"\"),this.hoverGroup2.attr(\"display\",\"\");var r=(0,f.mouse)(this.svg.node())[0];if(this.props.explanations){for(e=0;e<this.currExplanations.length;++e)(!n||Math.abs(n.xmapScaled-r)>Math.abs(this.currExplanations[e].xmapScaled-r))&&(n=this.currExplanations[e]);this.nearestExpIndex=n.origInd,this.hoverLine.attr(\"x1\",n.xmapScaled).attr(\"x2\",n.xmapScaled).attr(\"y1\",0+this.topOffset).attr(\"y2\",this.height),this.hoverx.attr(\"x\",n.xmapScaled).attr(\"y\",this.topOffset-5).text(this.xtickFormat(n.xmap)),this.hoverxOutline.attr(\"x\",n.xmapScaled).attr(\"y\",this.topOffset-5).text(this.xtickFormat(n.xmap)),this.hoverxTitle.attr(\"x\",n.xmapScaled).attr(\"y\",this.topOffset-18).text(n.count>1?n.count+\" averaged samples\":\"\"),this.hovery.attr(\"x\",this.leftOffset-6).attr(\"y\",n.joinPointy).text(this.ytickFormat(this.invLinkFunction(n.joinPoint))),this.hoveryOutline.attr(\"x\",this.leftOffset-6).attr(\"y\",n.joinPointy).text(this.ytickFormat(this.invLinkFunction(n.joinPoint)));for(var i=[],o=void 0,a=void 0,u=this.currPosOrderedFeatures.length-1;u>=0;--u){var c=this.currPosOrderedFeatures[u],s=n.features[c];a=5+(s.posyTop+s.posyBottom)/2,(!o||a-o>=15)&&s.posyTop-s.posyBottom>=6&&(i.push(s),o=a)}var l=[];o=void 0;var p=!0,h=!1,d=void 0;try{for(var v,g=this.currNegOrderedFeatures[Symbol.iterator]();!(p=(v=g.next()).done);p=!0){var m=v.value,y=n.features[m];a=5+(y.negyTop+y.negyBottom)/2,(!o||o-a>=15)&&y.negyTop-y.negyBottom>=6&&(l.push(y),o=a)}}catch(t){h=!0,d=t}finally{try{!p&&g.return&&g.return()}finally{if(h)throw d}}var _=function(e){var r=\"\";return null!==e.value&&void 0!==e.value&&(r=\" = \"+(isNaN(e.value)?e.value:t.ytickFormat(e.value))),n.count>1?\"mean(\"+t.props.featureNames[e.ind]+\")\"+r:t.props.featureNames[e.ind]+r},b=this.hoverGroup1.selectAll(\".pos-values\").data(i);b.enter().append(\"text\").attr(\"class\",\"pos-values\").merge(b).attr(\"x\",n.xmapScaled+5).attr(\"y\",function(t){return 4+(t.posyTop+t.posyBottom)/2}).attr(\"text-anchor\",\"start\").attr(\"font-size\",12).attr(\"stroke\",\"#fff\").attr(\"fill\",\"#fff\").attr(\"stroke-width\",\"4\").attr(\"stroke-linejoin\",\"round\").attr(\"opacity\",1).text(_),b.exit().remove();var x=this.hoverGroup2.selectAll(\".pos-values\").data(i);x.enter().append(\"text\").attr(\"class\",\"pos-values\").merge(x).attr(\"x\",n.xmapScaled+5).attr(\"y\",function(t){return 4+(t.posyTop+t.posyBottom)/2}).attr(\"text-anchor\",\"start\").attr(\"font-size\",12).attr(\"fill\",this.colors[0]).text(_),x.exit().remove();var w=this.hoverGroup1.selectAll(\".neg-values\").data(l);w.enter().append(\"text\").attr(\"class\",\"neg-values\").merge(w).attr(\"x\",n.xmapScaled+5).attr(\"y\",function(t){return 4+(t.negyTop+t.negyBottom)/2}).attr(\"text-anchor\",\"start\").attr(\"font-size\",12).attr(\"stroke\",\"#fff\").attr(\"fill\",\"#fff\").attr(\"stroke-width\",\"4\").attr(\"stroke-linejoin\",\"round\").attr(\"opacity\",1).text(_),w.exit().remove();var C=this.hoverGroup2.selectAll(\".neg-values\").data(l);C.enter().append(\"text\").attr(\"class\",\"neg-values\").merge(C).attr(\"x\",n.xmapScaled+5).attr(\"y\",function(t){return 4+(t.negyTop+t.negyBottom)/2}).attr(\"text-anchor\",\"start\").attr(\"font-size\",12).attr(\"fill\",this.colors[1]).text(_),C.exit().remove()}}},{key:\"draw\",value:function(){var t=this;if(this.props.explanations&&0!==this.props.explanations.length){(0,y.each)(this.props.explanations,function(t,e){return t.origInd=e});var e={},n={},r={},i=!0,o=!1,a=void 0;try{for(var u,c=this.props.explanations[Symbol.iterator]();!(i=(u=c.next()).done);i=!0){var s=u.value;for(var l in s.features)void 0===e[l]&&(e[l]=0,n[l]=0,r[l]=0),s.features[l].effect>0?e[l]+=s.features[l].effect:n[l]-=s.features[l].effect,null!==s.features[l].value&&void 0!==s.features[l].value&&(r[l]+=1)}}catch(t){o=!0,a=t}finally{try{!i&&c.return&&c.return()}finally{if(o)throw a}}this.usedFeatures=(0,y.sortBy)((0,y.keys)(e),function(t){return-(e[t]+n[t])}),console.log(\"found \",this.usedFeatures.length,\" used features\"),this.posOrderedFeatures=(0,y.sortBy)(this.usedFeatures,function(t){return e[t]}),this.negOrderedFeatures=(0,y.sortBy)(this.usedFeatures,function(t){return-n[t]}),this.singleValueFeatures=(0,y.filter)(this.usedFeatures,function(t){return r[t]>0});var f=[\"sample order by similarity\",\"sample order by output value\",\"original sample ordering\"].concat(this.singleValueFeatures.map(function(e){return t.props.featureNames[e]}));null!=this.props.ordering_keys&&f.unshift(\"sample order by key\");var p=this.xlabel.selectAll(\"option\").data(f);p.enter().append(\"option\").merge(p).attr(\"value\",function(t){return t}).text(function(t){return t}),p.exit().remove();var h=this.props.outNames[0]?this.props.outNames[0]:\"model output value\";f=(0,y.map)(this.usedFeatures,function(e){return[t.props.featureNames[e],t.props.featureNames[e]+\" effects\"]}),f.unshift([\"model output value\",h]);var d=this.ylabel.selectAll(\"option\").data(f);d.enter().append(\"option\").merge(d).attr(\"value\",function(t){return t[0]}).text(function(t){return t[1]}),d.exit().remove(),this.ylabel.style(\"top\",(this.height-10-this.topOffset)/2+this.topOffset+\"px\").style(\"left\",10-this.ylabel.node().offsetWidth/2+\"px\"),this.internalDraw()}}},{key:\"internalDraw\",value:function(){var t=this,e=!0,n=!1,r=void 0;try{for(var i,o=this.props.explanations[Symbol.iterator]();!(e=(i=o.next()).done);e=!0){var a=i.value,c=!0,s=!1,l=void 0;try{for(var f,h=this.usedFeatures[Symbol.iterator]();!(c=(f=h.next()).done);c=!0){var d=f.value;a.features.hasOwnProperty(d)||(a.features[d]={effect:0,value:0}),a.features[d].ind=d}}catch(t){s=!0,l=t}finally{try{!c&&h.return&&h.return()}finally{if(s)throw l}}}}catch(t){n=!0,r=t}finally{try{!e&&o.return&&o.return()}finally{if(n)throw r}}var v=void 0,m=this.xlabel.node().value,_=\"sample order by key\"===m&&null!=this.props.ordering_keys_time_format;if(_?this.xscale=(0,p.scaleTime)():this.xscale=(0,p.scaleLinear)(),this.xaxis.scale(this.xscale),\"sample order by similarity\"===m)v=(0,y.sortBy)(this.props.explanations,function(t){return t.simIndex}),(0,y.each)(v,function(t,e){return t.xmap=e});else if(\"sample order by output value\"===m)v=(0,y.sortBy)(this.props.explanations,function(t){return-t.outValue}),(0,y.each)(v,function(t,e){return t.xmap=e});else if(\"original sample ordering\"===m)v=(0,y.sortBy)(this.props.explanations,function(t){return t.origInd}),(0,y.each)(v,function(t,e){return t.xmap=e});else if(\"sample order by key\"===m)v=this.props.explanations,_?(0,y.each)(v,function(e,n){return e.xmap=t.parseTime(t.props.ordering_keys[n])}):(0,y.each)(v,function(e,n){return e.xmap=t.props.ordering_keys[n]}),v=(0,y.sortBy)(v,function(t){return t.xmap});else{var b=function(){var e=(0,y.findKey)(t.props.featureNames,function(t){return t===m});(0,y.each)(t.props.explanations,function(t,n){return t.xmap=t.features[e].value});var n=(0,y.sortBy)(t.props.explanations,function(t){return t.xmap}),r=(0,y.map)(n,function(t){return t.xmap});if(\"string\"==typeof r[0])return alert(\"Ordering by category names is not yet supported.\"),{v:void 0};var i=(0,y.min)(r),o=(0,y.max)(r),a=(o-i)/100;v=[];for(var u=void 0,c=void 0,s=0;s<n.length;++s){var l=n[s];if(u&&!c&&l.xmap-u.xmap<=a||c&&l.xmap-c.xmap<=a){c||(c=(0,y.cloneDeep)(u),c.count=1);var f=!0,p=!1,h=void 0;try{for(var d,g=t.usedFeatures[Symbol.iterator]();!(f=(d=g.next()).done);f=!0){var _=d.value;c.features[_].effect+=l.features[_].effect,c.features[_].value+=l.features[_].value;\n",
       "}}catch(t){p=!0,h=t}finally{try{!f&&g.return&&g.return()}finally{if(p)throw h}}c.count+=1}else if(u)if(c){var b=!0,x=!1,w=void 0;try{for(var C,M=t.usedFeatures[Symbol.iterator]();!(b=(C=M.next()).done);b=!0){var k=C.value;c.features[k].effect/=c.count,c.features[k].value/=c.count}}catch(t){x=!0,w=t}finally{try{!b&&M.return&&M.return()}finally{if(x)throw w}}v.push(c),c=void 0}else v.push(u);u=l}u.xmap-v[v.length-1].xmap>a&&v.push(u)}();if(\"object\"===(\"undefined\"==typeof b?\"undefined\":u(b)))return b.v}this.currUsedFeatures=this.usedFeatures,this.currPosOrderedFeatures=this.posOrderedFeatures,this.currNegOrderedFeatures=this.negOrderedFeatures;var x=this.ylabel.node().value;if(\"model output value\"!==x){var w=v;v=(0,y.cloneDeep)(v);for(var C=(0,y.findKey)(this.props.featureNames,function(t){return t===x}),M=0;M<v.length;++M){var k=v[M].features[C];v[M].features={},v[M].features[C]=k,w[M].remapped_version=v[M]}this.currUsedFeatures=[C],this.currPosOrderedFeatures=[C],this.currNegOrderedFeatures=[C]}this.currExplanations=v,\"identity\"===this.props.link?this.invLinkFunction=function(e){return t.props.baseValue+e}:\"logit\"===this.props.link?this.invLinkFunction=function(e){return 1/(1+Math.exp(-(t.props.baseValue+e)))}:console.log(\"ERROR: Unrecognized link function: \",this.props.link),this.predValues=(0,y.map)(v,function(t){return(0,y.sum)((0,y.map)(t.features,function(t){return t.effect}))});var E=this.wrapper.node().offsetWidth;if(0==E)return setTimeout(function(){return t.draw(v)},500);this.svg.style(\"height\",this.height+\"px\"),this.svg.style(\"width\",E+\"px\");var T=(0,y.map)(v,function(t){return t.xmap});this.xscale.domain([(0,y.min)(T),(0,y.max)(T)]).range([this.leftOffset,E]).clamp(!0),this.xaxisElement.attr(\"transform\",\"translate(0,\"+this.topOffset+\")\").call(this.xaxis);for(var S=0;S<this.currExplanations.length;++S)this.currExplanations[S].xmapScaled=this.xscale(this.currExplanations[S].xmap);for(var P=v.length,N=0,A=0;A<P;++A){var O=v[A].features,I=(0,y.sum)((0,y.map)((0,y.filter)(O,function(t){return t.effect>0}),function(t){return t.effect}))||0,D=(0,y.sum)((0,y.map)((0,y.filter)(O,function(t){return t.effect<0}),function(t){return-t.effect}))||0;N=Math.max(N,2.2*Math.max(I,D))}this.yscale.domain([-N/2,N/2]).range([this.height-10,this.topOffset]),this.yaxisElement.attr(\"transform\",\"translate(\"+this.leftOffset+\",0)\").call(this.yaxis);for(var R=0;R<P;++R){var L=v[R].features,U=(0,y.sum)((0,y.map)((0,y.filter)(L,function(t){return t.effect<0}),function(t){return-t.effect}))||0,F=-U,j=void 0,B=!0,W=!1,V=void 0;try{for(var z,H=this.currPosOrderedFeatures[Symbol.iterator]();!(B=(z=H.next()).done);B=!0)j=z.value,L[j].posyTop=this.yscale(F),L[j].effect>0&&(F+=L[j].effect),L[j].posyBottom=this.yscale(F),L[j].ind=j}catch(t){W=!0,V=t}finally{try{!B&&H.return&&H.return()}finally{if(W)throw V}}var q=F,Y=!0,K=!1,G=void 0;try{for(var $,X=this.currNegOrderedFeatures[Symbol.iterator]();!(Y=($=X.next()).done);Y=!0)j=$.value,L[j].negyTop=this.yscale(F),L[j].effect<0&&(F-=L[j].effect),L[j].negyBottom=this.yscale(F)}catch(t){K=!0,G=t}finally{try{!Y&&X.return&&X.return()}finally{if(K)throw G}}v[R].joinPoint=q,v[R].joinPointy=this.yscale(q)}var Z=(0,g.line)().x(function(t){return t[0]}).y(function(t){return t[1]}),Q=this.mainGroup.selectAll(\".force-bar-array-area-pos\").data(this.currUsedFeatures);Q.enter().append(\"path\").attr(\"class\",\"force-bar-array-area-pos\").merge(Q).attr(\"d\",function(t){var e=(0,y.map)((0,y.range)(P),function(e){return[v[e].xmapScaled,v[e].features[t].posyTop]}),n=(0,y.map)((0,y.rangeRight)(P),function(e){return[v[e].xmapScaled,v[e].features[t].posyBottom]});return Z(e.concat(n))}).attr(\"fill\",this.colors[0]),Q.exit().remove();var J=this.mainGroup.selectAll(\".force-bar-array-area-neg\").data(this.currUsedFeatures);J.enter().append(\"path\").attr(\"class\",\"force-bar-array-area-neg\").merge(J).attr(\"d\",function(t){var e=(0,y.map)((0,y.range)(P),function(e){return[v[e].xmapScaled,v[e].features[t].negyTop]}),n=(0,y.map)((0,y.rangeRight)(P),function(e){return[v[e].xmapScaled,v[e].features[t].negyBottom]});return Z(e.concat(n))}).attr(\"fill\",this.colors[1]),J.exit().remove();var tt=this.mainGroup.selectAll(\".force-bar-array-divider-pos\").data(this.currUsedFeatures);tt.enter().append(\"path\").attr(\"class\",\"force-bar-array-divider-pos\").merge(tt).attr(\"d\",function(t){var e=(0,y.map)((0,y.range)(P),function(e){return[v[e].xmapScaled,v[e].features[t].posyBottom]});return Z(e)}).attr(\"fill\",\"none\").attr(\"stroke-width\",1).attr(\"stroke\",function(){return t.colors[0].brighter(1.2)}),tt.exit().remove();var et=this.mainGroup.selectAll(\".force-bar-array-divider-neg\").data(this.currUsedFeatures);et.enter().append(\"path\").attr(\"class\",\"force-bar-array-divider-neg\").merge(et).attr(\"d\",function(t){var e=(0,y.map)((0,y.range)(P),function(e){return[v[e].xmapScaled,v[e].features[t].negyTop]});return Z(e)}).attr(\"fill\",\"none\").attr(\"stroke-width\",1).attr(\"stroke\",function(){return t.colors[1].brighter(1.5)}),et.exit().remove();for(var nt=function(t,e,n,r,i){var o=void 0,a=void 0;\"pos\"===i?(o=t[n].features[e].posyBottom,a=t[n].features[e].posyTop):(o=t[n].features[e].negyBottom,a=t[n].features[e].negyTop);for(var u=void 0,c=void 0,s=n+1;s<=r;++s)\"pos\"===i?(u=t[s].features[e].posyBottom,c=t[s].features[e].posyTop):(u=t[s].features[e].negyBottom,c=t[s].features[e].negyTop),u>o&&(o=u),c<a&&(a=c);return{top:o,bottom:a}},rt=100,it=20,ot=100,at=[],ut=[\"pos\",\"neg\"],ct=0;ct<ut.length;ct++){var st=ut[ct],lt=!0,ft=!1,pt=void 0;try{for(var ht,dt=this.currUsedFeatures[Symbol.iterator]();!(lt=(ht=dt.next()).done);lt=!0)for(var vt=ht.value,gt=0,mt=0,yt=0,_t={top:0,bottom:0},bt=void 0;mt<P-1;){for(;yt<rt&&mt<P-1;)++mt,yt=v[mt].xmapScaled-v[gt].xmapScaled;for(_t=nt(v,vt,gt,mt,st);_t.bottom-_t.top<it&&gt<mt;)++gt,_t=nt(v,vt,gt,mt,st);if(yt=v[mt].xmapScaled-v[gt].xmapScaled,_t.bottom-_t.top>=it&&yt>=rt){for(;mt<P-1;){if(++mt,bt=nt(v,vt,gt,mt,st),!(bt.bottom-bt.top>it)){--mt;break}_t=bt}yt=v[mt].xmapScaled-v[gt].xmapScaled,at.push([(v[mt].xmapScaled+v[gt].xmapScaled)/2,(_t.top+_t.bottom)/2,this.props.featureNames[vt]]);var xt=v[mt].xmapScaled;for(gt=mt;xt+ot>v[gt].xmapScaled&&gt<P-1;)++gt;mt=gt}}}catch(t){ft=!0,pt=t}finally{try{!lt&&dt.return&&dt.return()}finally{if(ft)throw pt}}}var wt=this.onTopGroup.selectAll(\".force-bar-array-flabels\").data(at);wt.enter().append(\"text\").attr(\"class\",\"force-bar-array-flabels\").merge(wt).attr(\"x\",function(t){return t[0]}).attr(\"y\",function(t){return t[1]+4}).text(function(t){return t[2]}),wt.exit().remove()}},{key:\"componentWillUnmount\",value:function(){window.removeEventListener(\"resize\",this.redraw)}},{key:\"render\",value:function(){var t=this;return l.default.createElement(\"div\",{ref:function(e){return t.wrapper=(0,f.select)(e)},style:{textAlign:\"center\"}},l.default.createElement(\"style\",{dangerouslySetInnerHTML:{__html:\"\\n          .force-bar-array-wrapper {\\n            text-align: center;\\n          }\\n          .force-bar-array-xaxis path {\\n            fill: none;\\n            opacity: 0.4;\\n          }\\n          .force-bar-array-xaxis .domain {\\n            opacity: 0;\\n          }\\n          .force-bar-array-xaxis paths {\\n            display: none;\\n          }\\n          .force-bar-array-yaxis path {\\n            fill: none;\\n            opacity: 0.4;\\n          }\\n          .force-bar-array-yaxis paths {\\n            display: none;\\n          }\\n          .tick line {\\n            stroke: #000;\\n            stroke-width: 1px;\\n            opacity: 0.4;\\n          }\\n          .tick text {\\n            fill: #000;\\n            opacity: 0.5;\\n            font-size: 12px;\\n            padding: 0px;\\n          }\\n          .force-bar-array-flabels {\\n            font-size: 12px;\\n            fill: #fff;\\n            text-anchor: middle;\\n          }\\n          .additive-force-array-xlabel {\\n            background: none;\\n            border: 1px solid #ccc;\\n            opacity: 0.5;\\n            margin-bottom: 0px;\\n            font-size: 12px;\\n            font-family: arial;\\n            margin-left: 80px;\\n            max-width: 300px;\\n          }\\n          .additive-force-array-xlabel:focus {\\n            outline: none;\\n          }\\n          .additive-force-array-ylabel {\\n            position: relative;\\n            top: 0px;\\n            left: 0px;\\n            transform: rotate(-90deg);\\n            background: none;\\n            border: 1px solid #ccc;\\n            opacity: 0.5;\\n            margin-bottom: 0px;\\n            font-size: 12px;\\n            font-family: arial;\\n            max-width: 150px;\\n          }\\n          .additive-force-array-ylabel:focus {\\n            outline: none;\\n          }\\n          .additive-force-array-hoverLine {\\n            stroke-width: 1px;\\n            stroke: #fff;\\n            opacity: 1;\\n          }\"}}),l.default.createElement(\"select\",{className:\"additive-force-array-xlabel\"}),l.default.createElement(\"div\",{style:{height:\"0px\",textAlign:\"left\"}},l.default.createElement(\"select\",{className:\"additive-force-array-ylabel\"})),l.default.createElement(\"svg\",{ref:function(e){return t.svg=(0,f.select)(e)},style:{userSelect:\"none\",display:\"block\",fontFamily:\"arial\",sansSerif:!0}}))}}]),e}(l.default.Component);x.defaultProps={plot_cmap:\"RdBu\",ordering_keys:null,ordering_keys_time_format:null},e.default=x},function(t,e,n){\"use strict\";function r(t){return t&&t.__esModule?t:{default:t}}function i(t,e){if(!(t instanceof e))throw new TypeError(\"Cannot call a class as a function\")}function o(t,e){if(!t)throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\");return!e||\"object\"!=typeof e&&\"function\"!=typeof e?t:e}function a(t,e){if(\"function\"!=typeof e&&null!==e)throw new TypeError(\"Super expression must either be null or a function, not \"+typeof e);t.prototype=Object.create(e&&e.prototype,{constructor:{value:t,enumerable:!1,writable:!0,configurable:!0}}),e&&(Object.setPrototypeOf?Object.setPrototypeOf(t,e):t.__proto__=e)}Object.defineProperty(e,\"__esModule\",{value:!0});var u=function(){function t(t,e){for(var n=0;n<e.length;n++){var r=e[n];r.enumerable=r.enumerable||!1,r.configurable=!0,\"value\"in r&&(r.writable=!0),Object.defineProperty(t,r.key,r)}}return function(e,n,r){return n&&t(e.prototype,n),r&&t(e,r),e}}(),c=n(41),s=r(c),l=n(129),f=n(64),p=n(30),h=n(112),d=n(134),v=n(10),g=n(39),m=n(56),y=r(m),b=function(t){function e(){i(this,e);var t=o(this,(e.__proto__||Object.getPrototypeOf(e)).call(this));return window.lastAdditiveForceVisualizer=t,t.effectFormat=(0,p.format)(\".2\"),t.redraw=(0,g.debounce)(function(){return t.draw()},200),t}return a(e,t),u(e,[{key:\"componentDidMount\",value:function(){var t=this;this.mainGroup=this.svg.append(\"g\"),this.axisElement=this.mainGroup.append(\"g\").attr(\"transform\",\"translate(0,35)\").attr(\"class\",\"force-bar-axis\"),this.onTopGroup=this.svg.append(\"g\"),this.baseValueTitle=this.svg.append(\"text\"),this.joinPointLine=this.svg.append(\"line\"),this.joinPointLabelOutline=this.svg.append(\"text\"),this.joinPointLabel=this.svg.append(\"text\"),this.joinPointTitleLeft=this.svg.append(\"text\"),this.joinPointTitleLeftArrow=this.svg.append(\"text\"),this.joinPointTitle=this.svg.append(\"text\"),this.joinPointTitleRightArrow=this.svg.append(\"text\"),this.joinPointTitleRight=this.svg.append(\"text\"),this.hoverLabelBacking=this.svg.append(\"text\").attr(\"x\",10).attr(\"y\",20).attr(\"text-anchor\",\"middle\").attr(\"font-size\",12).attr(\"stroke\",\"#fff\").attr(\"fill\",\"#fff\").attr(\"stroke-width\",\"4\").attr(\"stroke-linejoin\",\"round\").text(\"\").on(\"mouseover\",function(){t.hoverLabel.attr(\"opacity\",1),t.hoverLabelBacking.attr(\"opacity\",1)}).on(\"mouseout\",function(){t.hoverLabel.attr(\"opacity\",0),t.hoverLabelBacking.attr(\"opacity\",0)}),this.hoverLabel=this.svg.append(\"text\").attr(\"x\",10).attr(\"y\",20).attr(\"text-anchor\",\"middle\").attr(\"font-size\",12).attr(\"fill\",\"#0f0\").text(\"\").on(\"mouseover\",function(){t.hoverLabel.attr(\"opacity\",1),t.hoverLabelBacking.attr(\"opacity\",1)}).on(\"mouseout\",function(){t.hoverLabel.attr(\"opacity\",0),t.hoverLabelBacking.attr(\"opacity\",0)});var e=void 0;\"string\"==typeof this.props.plot_cmap?this.props.plot_cmap in y.default.colors?e=y.default.colors[this.props.plot_cmap]:(console.log(\"Invalid color map name, reverting to default.\"),e=y.default.colors.RdBu):Array.isArray(this.props.plot_cmap)&&(e=this.props.plot_cmap),this.colors=e.map(function(t){return(0,v.hsl)(t)}),this.brighterColors=[1.45,1.6].map(function(e,n){return t.colors[n].brighter(e)}),this.colors.map(function(e,n){var r=t.svg.append(\"linearGradient\").attr(\"id\",\"linear-grad-\"+n).attr(\"x1\",\"0%\").attr(\"y1\",\"0%\").attr(\"x2\",\"0%\").attr(\"y2\",\"100%\");r.append(\"stop\").attr(\"offset\",\"0%\").attr(\"stop-color\",e).attr(\"stop-opacity\",.6),r.append(\"stop\").attr(\"offset\",\"100%\").attr(\"stop-color\",e).attr(\"stop-opacity\",0);var i=t.svg.append(\"linearGradient\").attr(\"id\",\"linear-backgrad-\"+n).attr(\"x1\",\"0%\").attr(\"y1\",\"0%\").attr(\"x2\",\"0%\").attr(\"y2\",\"100%\");i.append(\"stop\").attr(\"offset\",\"0%\").attr(\"stop-color\",e).attr(\"stop-opacity\",.5),i.append(\"stop\").attr(\"offset\",\"100%\").attr(\"stop-color\",e).attr(\"stop-opacity\",0)}),this.tickFormat=(0,p.format)(\",.4\"),this.scaleCentered=(0,f.scaleLinear)(),this.axis=(0,h.axisBottom)().scale(this.scaleCentered).tickSizeInner(4).tickSizeOuter(0).tickFormat(function(e){return t.tickFormat(t.invLinkFunction(e))}).tickPadding(-18),window.addEventListener(\"resize\",this.redraw),window.setTimeout(this.redraw,50)}},{key:\"componentDidUpdate\",value:function(){this.draw()}},{key:\"draw\",value:function(){var t=this;(0,g.each)(this.props.featureNames,function(e,n){t.props.features[n]&&(t.props.features[n].name=e)}),\"identity\"===this.props.link?this.invLinkFunction=function(e){return t.props.baseValue+e}:\"logit\"===this.props.link?this.invLinkFunction=function(e){return 1/(1+Math.exp(-(t.props.baseValue+e)))}:console.log(\"ERROR: Unrecognized link function: \",this.props.link);var e=this.svg.node().parentNode.offsetWidth;if(0==e)return setTimeout(function(){return t.draw(t.props)},500);this.svg.style(\"height\",\"150px\"),this.svg.style(\"width\",e+\"px\");var n=50,r=(0,g.sortBy)(this.props.features,function(t){return-1/(t.effect+1e-10)}),i=(0,g.sum)((0,g.map)(r,function(t){return Math.abs(t.effect)})),o=(0,g.sum)((0,g.map)((0,g.filter)(r,function(t){return t.effect>0}),function(t){return t.effect}))||0,a=(0,g.sum)((0,g.map)((0,g.filter)(r,function(t){return t.effect<0}),function(t){return-t.effect}))||0;this.domainSize=3*Math.max(o,a);var u=(0,f.scaleLinear)().domain([0,this.domainSize]).range([0,e]),c=e/2-u(a);this.scaleCentered.domain([-this.domainSize/2,this.domainSize/2]).range([0,e]).clamp(!0),this.axisElement.attr(\"transform\",\"translate(0,\"+n+\")\").call(this.axis);var s=0,l=void 0,h=void 0,v=void 0;for(l=0;l<r.length;++l)r[l].x=s,r[l].effect<0&&void 0===h&&(h=s,v=l),s+=Math.abs(r[l].effect);void 0===h&&(h=s,v=l);var m=(0,d.line)().x(function(t){return t[0]}).y(function(t){return t[1]}),y=function(e){return void 0!==e.value&&null!==e.value&&\"\"!==e.value?e.name+\" = \"+(isNaN(e.value)?e.value:t.tickFormat(e.value)):e.name};r=this.props.hideBars?[]:r;var b=this.mainGroup.selectAll(\".force-bar-blocks\").data(r);b.enter().append(\"path\").attr(\"class\",\"force-bar-blocks\").merge(b).attr(\"d\",function(t,e){var r=u(t.x)+c,i=u(Math.abs(t.effect)),o=t.effect<0?-4:4,a=o;return e===v&&(o=0),e===v-1&&(a=0),m([[r,6+n],[r+i,6+n],[r+i+a,14.5+n],[r+i,23+n],[r,23+n],[r+o,14.5+n]])}).attr(\"fill\",function(e){return e.effect>0?t.colors[0]:t.colors[1]}).on(\"mouseover\",function(e){if(u(Math.abs(e.effect))<u(i)/50||u(Math.abs(e.effect))<10){var r=u(e.x)+c,o=u(Math.abs(e.effect));t.hoverLabel.attr(\"opacity\",1).attr(\"x\",r+o/2).attr(\"y\",n+.5).attr(\"fill\",e.effect>0?t.colors[0]:t.colors[1]).text(y(e)),t.hoverLabelBacking.attr(\"opacity\",1).attr(\"x\",r+o/2).attr(\"y\",n+.5).text(y(e))}}).on(\"mouseout\",function(){t.hoverLabel.attr(\"opacity\",0),t.hoverLabelBacking.attr(\"opacity\",0)}),b.exit().remove();var x=_.filter(r,function(t){return u(Math.abs(t.effect))>u(i)/50&&u(Math.abs(t.effect))>10}),w=this.onTopGroup.selectAll(\".force-bar-labels\").data(x);if(w.exit().remove(),w=w.enter().append(\"text\").attr(\"class\",\"force-bar-labels\").attr(\"font-size\",\"12px\").attr(\"y\",48+n).merge(w).text(function(e){return void 0!==e.value&&null!==e.value&&\"\"!==e.value?e.name+\" = \"+(isNaN(e.value)?e.value:t.tickFormat(e.value)):e.name}).attr(\"fill\",function(e){return e.effect>0?t.colors[0]:t.colors[1]}).attr(\"stroke\",function(t){return t.textWidth=Math.max(this.getComputedTextLength(),u(Math.abs(t.effect))-10),t.innerTextWidth=this.getComputedTextLength(),\"none\"}),this.filteredData=x,r.length>0){s=h+u.invert(5);for(var C=v;C<r.length;++C)r[C].textx=s,s+=u.invert(r[C].textWidth+10);s=h-u.invert(5);for(var M=v-1;M>=0;--M)r[M].textx=s,s-=u.invert(r[M].textWidth+10)}w.attr(\"x\",function(t){return u(t.textx)+c+(t.effect>0?-t.textWidth/2:t.textWidth/2)}).attr(\"text-anchor\",\"middle\"),x=(0,g.filter)(x,function(n){return u(n.textx)+c>t.props.labelMargin&&u(n.textx)+c<e-t.props.labelMargin}),this.filteredData2=x;var k=x.slice(),E=(0,g.findIndex)(r,x[0])-1;E>=0&&k.unshift(r[E]);var T=this.mainGroup.selectAll(\".force-bar-labelBacking\").data(x);T.enter().append(\"path\").attr(\"class\",\"force-bar-labelBacking\").attr(\"stroke\",\"none\").attr(\"opacity\",.2).merge(T).attr(\"d\",function(t){return m([[u(t.x)+u(Math.abs(t.effect))+c,23+n],[(t.effect>0?u(t.textx):u(t.textx)+t.textWidth)+c+5,33+n],[(t.effect>0?u(t.textx):u(t.textx)+t.textWidth)+c+5,54+n],[(t.effect>0?u(t.textx)-t.textWidth:u(t.textx))+c-5,54+n],[(t.effect>0?u(t.textx)-t.textWidth:u(t.textx))+c-5,33+n],[u(t.x)+c,23+n]])}).attr(\"fill\",function(t){return\"url(#linear-backgrad-\"+(t.effect>0?0:1)+\")\"}),T.exit().remove();var S=this.mainGroup.selectAll(\".force-bar-labelDividers\").data(x.slice(0,-1));S.enter().append(\"rect\").attr(\"class\",\"force-bar-labelDividers\").attr(\"height\",\"21px\").attr(\"width\",\"1px\").attr(\"y\",33+n).merge(S).attr(\"x\",function(t){return(t.effect>0?u(t.textx):u(t.textx)+t.textWidth)+c+4.5}).attr(\"fill\",function(t){return\"url(#linear-grad-\"+(t.effect>0?0:1)+\")\"}),S.exit().remove();var P=this.mainGroup.selectAll(\".force-bar-labelLinks\").data(x.slice(0,-1));P.enter().append(\"line\").attr(\"class\",\"force-bar-labelLinks\").attr(\"y1\",23+n).attr(\"y2\",33+n).attr(\"stroke-opacity\",.5).attr(\"stroke-width\",1).merge(P).attr(\"x1\",function(t){return u(t.x)+u(Math.abs(t.effect))+c}).attr(\"x2\",function(t){return(t.effect>0?u(t.textx):u(t.textx)+t.textWidth)+c+5}).attr(\"stroke\",function(e){return e.effect>0?t.colors[0]:t.colors[1]}),P.exit().remove();var N=this.mainGroup.selectAll(\".force-bar-blockDividers\").data(r.slice(0,-1));N.enter().append(\"path\").attr(\"class\",\"force-bar-blockDividers\").attr(\"stroke-width\",2).attr(\"fill\",\"none\").merge(N).attr(\"d\",function(t){var e=u(t.x)+u(Math.abs(t.effect))+c;return m([[e,6+n],[e+(t.effect<0?-4:4),14.5+n],[e,23+n]])}).attr(\"stroke\",function(e,n){return v===n+1||Math.abs(e.effect)<1e-8?\"#rgba(0,0,0,0)\":e.effect>0?t.brighterColors[0]:t.brighterColors[1]}),N.exit().remove(),this.joinPointLine.attr(\"x1\",u(h)+c).attr(\"x2\",u(h)+c).attr(\"y1\",0+n).attr(\"y2\",6+n).attr(\"stroke\",\"#F2F2F2\").attr(\"stroke-width\",1).attr(\"opacity\",1),this.joinPointLabelOutline.attr(\"x\",u(h)+c).attr(\"y\",-5+n).attr(\"color\",\"#fff\").attr(\"text-anchor\",\"middle\").attr(\"font-weight\",\"bold\").attr(\"stroke\",\"#fff\").attr(\"stroke-width\",6).text((0,p.format)(\",.2f\")(this.invLinkFunction(h-a))).attr(\"opacity\",1),console.log(\"joinPoint\",h,c,n,a),this.joinPointLabel.attr(\"x\",u(h)+c).attr(\"y\",-5+n).attr(\"text-anchor\",\"middle\").attr(\"font-weight\",\"bold\").attr(\"fill\",\"#000\").text((0,p.format)(\",.2f\")(this.invLinkFunction(h-a))).attr(\"opacity\",1),this.joinPointTitle.attr(\"x\",u(h)+c).attr(\"y\",-22+n).attr(\"text-anchor\",\"middle\").attr(\"font-size\",\"12\").attr(\"fill\",\"#000\").text(this.props.outNames[0]).attr(\"opacity\",.5),this.props.hideBars||(this.joinPointTitleLeft.attr(\"x\",u(h)+c-16).attr(\"y\",-38+n).attr(\"text-anchor\",\"end\").attr(\"font-size\",\"13\").attr(\"fill\",this.colors[0]).text(\"higher\").attr(\"opacity\",1),this.joinPointTitleRight.attr(\"x\",u(h)+c+16).attr(\"y\",-38+n).attr(\"text-anchor\",\"start\").attr(\"font-size\",\"13\").attr(\"fill\",this.colors[1]).text(\"lower\").attr(\"opacity\",1),this.joinPointTitleLeftArrow.attr(\"x\",u(h)+c+7).attr(\"y\",-42+n).attr(\"text-anchor\",\"end\").attr(\"font-size\",\"13\").attr(\"fill\",this.colors[0]).text(\"→\").attr(\"opacity\",1),this.joinPointTitleRightArrow.attr(\"x\",u(h)+c-7).attr(\"y\",-36+n).attr(\"text-anchor\",\"start\").attr(\"font-size\",\"13\").attr(\"fill\",this.colors[1]).text(\"←\").attr(\"opacity\",1)),this.props.hideBaseValueLabel||this.baseValueTitle.attr(\"x\",this.scaleCentered(0)).attr(\"y\",-22+n).attr(\"text-anchor\",\"middle\").attr(\"font-size\",\"12\").attr(\"fill\",\"#000\").text(\"base value\").attr(\"opacity\",.5)}},{key:\"componentWillUnmount\",value:function(){window.removeEventListener(\"resize\",this.redraw)}},{key:\"render\",value:function(){var t=this;return s.default.createElement(\"svg\",{ref:function(e){return t.svg=(0,l.select)(e)},style:{userSelect:\"none\",display:\"block\",fontFamily:\"arial\",sansSerif:!0}},s.default.createElement(\"style\",{dangerouslySetInnerHTML:{__html:\"\\n          .force-bar-axis path {\\n            fill: none;\\n            opacity: 0.4;\\n          }\\n          .force-bar-axis paths {\\n            display: none;\\n          }\\n          .tick line {\\n            stroke: #000;\\n            stroke-width: 1px;\\n            opacity: 0.4;\\n          }\\n          .tick text {\\n            fill: #000;\\n            opacity: 0.5;\\n            font-size: 12px;\\n            padding: 0px;\\n          }\"}}))}}]),e}(s.default.Component);b.defaultProps={plot_cmap:\"RdBu\"},e.default=b},function(t,e,n){\"use strict\";function r(t){return t&&t.__esModule?t:{default:t}}function i(t,e){if(!(t instanceof e))throw new TypeError(\"Cannot call a class as a function\")}function o(t,e){if(!t)throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\");return!e||\"object\"!=typeof e&&\"function\"!=typeof e?t:e}function a(t,e){if(\"function\"!=typeof e&&null!==e)throw new TypeError(\"Super expression must either be null or a function, not \"+typeof e);t.prototype=Object.create(e&&e.prototype,{constructor:{value:t,enumerable:!1,writable:!0,configurable:!0}}),e&&(Object.setPrototypeOf?Object.setPrototypeOf(t,e):t.__proto__=e)}Object.defineProperty(e,\"__esModule\",{value:!0});var u=function(){function t(t,e){for(var n=0;n<e.length;n++){var r=e[n];r.enumerable=r.enumerable||!1,r.configurable=!0,\"value\"in r&&(r.writable=!0),Object.defineProperty(t,r.key,r)}}return function(e,n,r){return n&&t(e.prototype,n),r&&t(e,r),e}}(),c=n(41),s=r(c),l=n(64),f=n(30),p=n(39),h=n(56),d=r(h),v=function(t){function e(){i(this,e);var t=o(this,(e.__proto__||Object.getPrototypeOf(e)).call(this));return t.width=100,window.lastSimpleListInstance=t,t.effectFormat=(0,f.format)(\".2\"),t}return a(e,t),u(e,[{key:\"render\",value:function(){var t=this,e=void 0;\"string\"==typeof this.props.plot_cmap?this.props.plot_cmap in d.default.colors?e=d.default.colors[this.props.plot_cmap]:(console.log(\"Invalid color map name, reverting to default.\"),e=d.default.colors.RdBu):Array.isArray(this.props.plot_cmap)&&(e=this.props.plot_cmap),console.log(this.props.features,this.props.features),this.scale=(0,l.scaleLinear)().domain([0,(0,p.max)((0,p.map)(this.props.features,function(t){return Math.abs(t.effect)}))]).range([0,this.width]);var n=(0,p.reverse)((0,p.sortBy)(Object.keys(this.props.features),function(e){return Math.abs(t.props.features[e].effect)})),r=n.map(function(n){var r=t.props.features[n],i=t.props.featureNames[n],o={width:t.scale(Math.abs(r.effect)),height:\"20px\",background:r.effect<0?e[0]:e[1],display:\"inline-block\"},a=void 0,u=void 0,c={lineHeight:\"20px\",display:\"inline-block\",width:t.width+40,verticalAlign:\"top\",marginRight:\"5px\",textAlign:\"right\"},l={lineHeight:\"20px\",display:\"inline-block\",width:t.width+40,verticalAlign:\"top\",marginLeft:\"5px\"};return r.effect<0?(u=s.default.createElement(\"span\",{style:l},i),c.width=40+t.width-t.scale(Math.abs(r.effect)),c.textAlign=\"right\",c.color=\"#999\",c.fontSize=\"13px\",a=s.default.createElement(\"span\",{style:c},t.effectFormat(r.effect))):(c.textAlign=\"right\",a=s.default.createElement(\"span\",{style:c},i),l.width=40,l.textAlign=\"left\",l.color=\"#999\",l.fontSize=\"13px\",u=s.default.createElement(\"span\",{style:l},t.effectFormat(r.effect))),s.default.createElement(\"div\",{key:n,style:{marginTop:\"2px\"}},a,s.default.createElement(\"div\",{style:o}),u)});return s.default.createElement(\"span\",null,r)}}]),e}(s.default.Component);v.defaultProps={plot_cmap:\"RdBu\"},e.default=v},function(t,e,n){\"use strict\";t.exports=n(345)},function(t,e,n){var r=(n(0),n(398)),i=!1;t.exports=function(t){t=t||{};var e=t.shouldRejectClick||r;i=!0,n(22).injection.injectEventPluginsByName({TapEventPlugin:n(396)(e)})}},function(t,e,n){\"use strict\";e.a=function(t){return function(){return t}}},function(t,e,n){\"use strict\"},function(t,e,n){\"use strict\";n(101),n(102),n(184),n(105),n(187),n(109),n(108)},function(t,e,n){\"use strict\";e.a=function(t){return t}},function(t,e,n){\"use strict\"},function(t,e,n){\"use strict\";n(29)},function(t,e,n){\"use strict\";n(18),n(29),n(57)},function(t,e,n){\"use strict\"},function(t,e,n){\"use strict\"},function(t,e,n){\"use strict\"},function(t,e,n){\"use strict\";n(18)},function(t,e,n){\"use strict\"},function(t,e,n){\"use strict\"},function(t,e,n){\"use strict\";n(101),n(18),n(29),n(57)},function(t,e,n){\"use strict\";n(104)},function(t,e,n){\"use strict\";n(110)},function(t,e,n){\"use strict\";n.d(e,\"a\",function(){return r});var r=Array.prototype.slice},function(t,e,n){\"use strict\";function r(t,e,n){var r=t(n);return\"translate(\"+(isFinite(r)?r:e(n))+\",0)\"}function i(t,e,n){var r=t(n);return\"translate(0,\"+(isFinite(r)?r:e(n))+\")\"}function o(t){var e=t.bandwidth()/2;return t.round()&&(e=Math.round(e)),function(n){return t(n)+e}}function a(){return!this.__axis}function u(t,e){function n(n){var p,b=null==c?e.ticks?e.ticks.apply(e,u):e.domain():c,x=null==s?e.tickFormat?e.tickFormat.apply(e,u):h.a:s,w=Math.max(l,0)+_,C=t===d||t===g?r:i,M=e.range(),k=M[0]+.5,E=M[M.length-1]+.5,T=(e.bandwidth?o:h.a)(e.copy()),S=n.selection?n.selection():n,P=S.selectAll(\".domain\").data([null]),N=S.selectAll(\".tick\").data(b,e).order(),A=N.exit(),O=N.enter().append(\"g\").attr(\"class\",\"tick\"),I=N.select(\"line\"),D=N.select(\"text\"),R=t===d||t===m?-1:1,L=t===m||t===v?(p=\"x\",\"y\"):(p=\"y\",\"x\");P=P.merge(P.enter().insert(\"path\",\".tick\").attr(\"class\",\"domain\").attr(\"stroke\",\"#000\")),N=N.merge(O),I=I.merge(O.append(\"line\").attr(\"stroke\",\"#000\").attr(p+\"2\",R*l).attr(L+\"1\",.5).attr(L+\"2\",.5)),D=D.merge(O.append(\"text\").attr(\"fill\",\"#000\").attr(p,R*w).attr(L,.5).attr(\"dy\",t===d?\"0em\":t===g?\"0.71em\":\"0.32em\")),n!==S&&(P=P.transition(n),N=N.transition(n),I=I.transition(n),D=D.transition(n),A=A.transition(n).attr(\"opacity\",y).attr(\"transform\",function(t){return C(T,this.parentNode.__axis||T,t)}),O.attr(\"opacity\",y).attr(\"transform\",function(t){return C(this.parentNode.__axis||T,T,t)})),A.remove(),P.attr(\"d\",t===m||t==v?\"M\"+R*f+\",\"+k+\"H0.5V\"+E+\"H\"+R*f:\"M\"+k+\",\"+R*f+\"V0.5H\"+E+\"V\"+R*f),N.attr(\"opacity\",1).attr(\"transform\",function(t){return C(T,T,t)}),I.attr(p+\"2\",R*l),D.attr(p,R*w).text(x),S.filter(a).attr(\"fill\",\"none\").attr(\"font-size\",10).attr(\"font-family\",\"sans-serif\").attr(\"text-anchor\",t===v?\"start\":t===m?\"end\":\"middle\"),S.each(function(){this.__axis=T})}var u=[],c=null,s=null,l=6,f=6,_=3;return n.scale=function(t){return arguments.length?(e=t,n):e},n.ticks=function(){return u=p.a.call(arguments),n},n.tickArguments=function(t){return arguments.length?(u=null==t?[]:p.a.call(t),n):u.slice()},n.tickValues=function(t){return arguments.length?(c=null==t?null:p.a.call(t),n):c&&c.slice()},n.tickFormat=function(t){return arguments.length?(s=t,n):s},n.tickSize=function(t){return arguments.length?(l=f=+t,n):l},n.tickSizeInner=function(t){return arguments.length?(l=+t,n):l},n.tickSizeOuter=function(t){return arguments.length?(f=+t,n):f},n.tickPadding=function(t){return arguments.length?(_=+t,n):_},n}function c(t){return u(d,t)}function s(t){return u(v,t)}function l(t){return u(g,t)}function f(t){return u(m,t)}var p=n(200),h=n(202);e.a=c,e.b=s,e.c=l,e.d=f;var d=1,v=2,g=3,m=4,y=1e-6},function(t,e,n){\"use strict\";e.a=function(t){return t}},function(t,e,n){\"use strict\";var r=(n(206),n(207),n(58));n.d(e,\"a\",function(){return r.a});n(205),n(208),n(204)},function(t,e,n){\"use strict\"},function(t,e,n){\"use strict\"},function(t,e,n){\"use strict\";n(58)},function(t,e,n){\"use strict\";function r(){}function i(t,e){var n=new r;if(t instanceof r)t.each(function(t){n.add(t)});else if(t){var i=-1,o=t.length;if(null==e)for(;++i<o;)n.add(t[i]);else for(;++i<o;)n.add(e(t[i],i,t))}return n}var o=n(58),a=o.a.prototype;r.prototype=i.prototype={constructor:r,has:a.has,add:function(t){return t+=\"\",this[o.b+t]=t,this},remove:a.remove,clear:a.clear,values:a.keys,size:a.size,empty:a.empty,each:a.each}},function(t,e,n){\"use strict\"},function(t,e,n){\"use strict\";function r(t){if(t instanceof o)return new o(t.h,t.s,t.l,t.opacity);t instanceof u.d||(t=n.i(u.e)(t));var e=t.r/255,r=t.g/255,i=t.b/255,a=(g*i+d*e-v*r)/(g+d-v),s=i-a,l=(h*(r-a)-f*s)/p,m=Math.sqrt(l*l+s*s)/(h*a*(1-a)),y=m?Math.atan2(l,s)*c.a-120:NaN;return new o(y<0?y+360:y,m,a,t.opacity)}function i(t,e,n,i){return 1===arguments.length?r(t):new o(t,e,n,null==i?1:i)}function o(t,e,n,r){this.h=+t,this.s=+e,this.l=+n,this.opacity=+r}var a=n(60),u=n(59),c=n(113);e.a=i;var s=-.14861,l=1.78277,f=-.29227,p=-.90649,h=1.97294,d=h*p,v=h*l,g=l*f-p*s;n.i(a.a)(o,i,n.i(a.b)(u.f,{brighter:function(t){return t=null==t?u.g:Math.pow(u.g,t),new o(this.h,this.s,this.l*t,this.opacity)},darker:function(t){return t=null==t?u.h:Math.pow(u.h,t),new o(this.h,this.s,this.l*t,this.opacity)},rgb:function(){var t=isNaN(this.h)?0:(this.h+120)*c.b,e=+this.l,n=isNaN(this.s)?0:this.s*e*(1-e),r=Math.cos(t),i=Math.sin(t);return new u.d(255*(e+n*(s*r+l*i)),255*(e+n*(f*r+p*i)),255*(e+n*(h*r)),this.opacity)}}))},function(t,e,n){\"use strict\";function r(t){if(t instanceof o)return new o(t.l,t.a,t.b,t.opacity);if(t instanceof p){var e=t.h*v.b;return new o(t.l,Math.cos(e)*t.c,Math.sin(e)*t.c,t.opacity)}t instanceof d.d||(t=n.i(d.e)(t));var r=s(t.r),i=s(t.g),u=s(t.b),c=a((.4124564*r+.3575761*i+.1804375*u)/m),l=a((.2126729*r+.7151522*i+.072175*u)/y),f=a((.0193339*r+.119192*i+.9503041*u)/_);return new o(116*l-16,500*(c-l),200*(l-f),t.opacity)}function i(t,e,n,i){return 1===arguments.length?r(t):new o(t,e,n,null==i?1:i)}function o(t,e,n,r){this.l=+t,this.a=+e,this.b=+n,this.opacity=+r}function a(t){return t>C?Math.pow(t,1/3):t/w+b}function u(t){return t>x?t*t*t:w*(t-b)}function c(t){return 255*(t<=.0031308?12.92*t:1.055*Math.pow(t,1/2.4)-.055)}function s(t){return(t/=255)<=.04045?t/12.92:Math.pow((t+.055)/1.055,2.4)}function l(t){if(t instanceof p)return new p(t.h,t.c,t.l,t.opacity);t instanceof o||(t=r(t));var e=Math.atan2(t.b,t.a)*v.a;return new p(e<0?e+360:e,Math.sqrt(t.a*t.a+t.b*t.b),t.l,t.opacity)}function f(t,e,n,r){return 1===arguments.length?l(t):new p(t,e,n,null==r?1:r)}function p(t,e,n,r){this.h=+t,this.c=+e,this.l=+n,this.opacity=+r}var h=n(60),d=n(59),v=n(113);e.a=i,e.b=f;var g=18,m=.95047,y=1,_=1.08883,b=4/29,x=6/29,w=3*x*x,C=x*x*x;n.i(h.a)(o,i,n.i(h.b)(d.f,{brighter:function(t){return new o(this.l+g*(null==t?1:t),this.a,this.b,this.opacity)},darker:function(t){return new o(this.l-g*(null==t?1:t),this.a,this.b,this.opacity)},rgb:function(){var t=(this.l+16)/116,e=isNaN(this.a)?t:t+this.a/500,n=isNaN(this.b)?t:t-this.b/200;return t=y*u(t),e=m*u(e),n=_*u(n),new d.d(c(3.2404542*e-1.5371385*t-.4985314*n),c(-.969266*e+1.8760108*t+.041556*n),c(.0556434*e-.2040259*t+1.0572252*n),this.opacity)}})),n.i(h.a)(p,f,n.i(h.b)(d.f,{brighter:function(t){return new p(this.h,this.c,this.l+g*(null==t?1:t),this.opacity)},darker:function(t){return new p(this.h,this.c,this.l-g*(null==t?1:t),this.opacity)},rgb:function(){return r(this).rgb()}}))},function(t,e,n){\"use strict\";function r(t){return o=n.i(i.a)(t),a=o.format,u=o.formatPrefix,o}var i=n(117);n.d(e,\"b\",function(){return a}),n.d(e,\"c\",function(){\n",
       "return u}),e.a=r;var o,a,u;r({decimal:\".\",thousands:\",\",grouping:[3],currency:[\"$\",\"\"]})},function(t,e,n){\"use strict\";e.a=function(t,e){t=t.toPrecision(e);t:for(var n,r=t.length,i=1,o=-1;i<r;++i)switch(t[i]){case\".\":o=n=i;break;case\"0\":0===o&&(o=i),n=i;break;case\"e\":break t;default:o>0&&(o=0)}return o>0?t.slice(0,o)+t.slice(n+1):t}},function(t,e,n){\"use strict\";e.a=function(t,e){return function(n,r){for(var i=n.length,o=[],a=0,u=t[0],c=0;i>0&&u>0&&(c+u+1>r&&(u=Math.max(1,r-c)),o.push(n.substring(i-=u,i+u)),!((c+=u+1)>r));)u=t[a=(a+1)%t.length];return o.reverse().join(e)}}},function(t,e,n){\"use strict\";var r=n(61);e.a=function(t,e){var i=n.i(r.a)(t,e);if(!i)return t+\"\";var o=i[0],a=i[1];return a<0?\"0.\"+new Array(-a).join(\"0\")+o:o.length>a+1?o.slice(0,a+1)+\".\"+o.slice(a+1):o+new Array(a-o.length+2).join(\"0\")}},function(t,e,n){\"use strict\";var r=n(42);e.a=function(t){return Math.max(0,-n.i(r.a)(Math.abs(t)))}},function(t,e,n){\"use strict\";var r=n(42);e.a=function(t,e){return Math.max(0,3*Math.max(-8,Math.min(8,Math.floor(n.i(r.a)(e)/3)))-n.i(r.a)(Math.abs(t)))}},function(t,e,n){\"use strict\";var r=n(42);e.a=function(t,e){return t=Math.abs(t),e=Math.abs(e)-t,Math.max(0,n.i(r.a)(e)-n.i(r.a)(t))+1}},function(t,e,n){\"use strict\";function r(t){return function e(r){function a(e,a){var u=t((e=n.i(i.cubehelix)(e)).h,(a=n.i(i.cubehelix)(a)).h),c=n.i(o.a)(e.s,a.s),s=n.i(o.a)(e.l,a.l),l=n.i(o.a)(e.opacity,a.opacity);return function(t){return e.h=u(t),e.s=c(t),e.l=s(Math.pow(t,r)),e.opacity=l(t),e+\"\"}}return r=+r,a.gamma=e,a}(1)}var i=n(10),o=n(32);n.d(e,\"a\",function(){return a});var a=(r(o.b),r(o.a))},function(t,e,n){\"use strict\";function r(t){return function(e,r){var a=t((e=n.i(i.hcl)(e)).h,(r=n.i(i.hcl)(r)).h),u=n.i(o.a)(e.c,r.c),c=n.i(o.a)(e.l,r.l),s=n.i(o.a)(e.opacity,r.opacity);return function(t){return e.h=a(t),e.c=u(t),e.l=c(t),e.opacity=s(t),e+\"\"}}}var i=n(10),o=n(32);r(o.b),r(o.a)},function(t,e,n){\"use strict\";function r(t){return function(e,r){var a=t((e=n.i(i.hsl)(e)).h,(r=n.i(i.hsl)(r)).h),u=n.i(o.a)(e.s,r.s),c=n.i(o.a)(e.l,r.l),s=n.i(o.a)(e.opacity,r.opacity);return function(t){return e.h=a(t),e.s=u(t),e.l=c(t),e.opacity=s(t),e+\"\"}}}var i=n(10),o=n(32);r(o.b),r(o.a)},function(t,e,n){\"use strict\";n(10),n(32)},function(t,e,n){\"use strict\"},function(t,e,n){\"use strict\";e.a=function(t,e){return t=+t,e-=t,function(n){return Math.round(t+e*n)}}},function(t,e,n){\"use strict\";n.d(e,\"a\",function(){return i});var r=180/Math.PI,i={translateX:0,translateY:0,rotate:0,skewX:0,scaleX:1,scaleY:1};e.b=function(t,e,n,i,o,a){var u,c,s;return(u=Math.sqrt(t*t+e*e))&&(t/=u,e/=u),(s=t*n+e*i)&&(n-=t*s,i-=e*s),(c=Math.sqrt(n*n+i*i))&&(n/=c,i/=c,s/=c),t*i<e*n&&(t=-t,e=-e,s=-s,u=-u),{translateX:o,translateY:a,rotate:Math.atan2(e,t)*r,skewX:Math.atan(s)*r,scaleX:u,scaleY:c}}},function(t,e,n){\"use strict\";function r(t,e,r,o){function a(t){return t.length?t.pop()+\" \":\"\"}function u(t,o,a,u,c,s){if(t!==a||o!==u){var l=c.push(\"translate(\",null,e,null,r);s.push({i:l-4,x:n.i(i.a)(t,a)},{i:l-2,x:n.i(i.a)(o,u)})}else(a||u)&&c.push(\"translate(\"+a+e+u+r)}function c(t,e,r,u){t!==e?(t-e>180?e+=360:e-t>180&&(t+=360),u.push({i:r.push(a(r)+\"rotate(\",null,o)-2,x:n.i(i.a)(t,e)})):e&&r.push(a(r)+\"rotate(\"+e+o)}function s(t,e,r,u){t!==e?u.push({i:r.push(a(r)+\"skewX(\",null,o)-2,x:n.i(i.a)(t,e)}):e&&r.push(a(r)+\"skewX(\"+e+o)}function l(t,e,r,o,u,c){if(t!==r||e!==o){var s=u.push(a(u)+\"scale(\",null,\",\",null,\")\");c.push({i:s-4,x:n.i(i.a)(t,r)},{i:s-2,x:n.i(i.a)(e,o)})}else 1===r&&1===o||u.push(a(u)+\"scale(\"+r+\",\"+o+\")\")}return function(e,n){var r=[],i=[];return e=t(e),n=t(n),u(e.translateX,e.translateY,n.translateX,n.translateY,r,i),c(e.rotate,n.rotate,r,i),s(e.skewX,n.skewX,r,i),l(e.scaleX,e.scaleY,n.scaleX,n.scaleY,r,i),e=n=null,function(t){for(var e,n=-1,o=i.length;++n<o;)r[(e=i[n]).i]=e.x(t);return r.join(\"\")}}}var i=n(43),o=n(226);r(o.a,\"px, \",\"px)\",\"deg)\"),r(o.b,\", \",\")\",\")\")},function(t,e,n){\"use strict\";function r(t){return\"none\"===t?o.a:(a||(a=document.createElement(\"DIV\"),u=document.documentElement,c=document.defaultView),a.style.transform=t,t=c.getComputedStyle(u.appendChild(a),null).getPropertyValue(\"transform\"),u.removeChild(a),t=t.slice(7,-1).split(\",\"),n.i(o.b)(+t[0],+t[1],+t[2],+t[3],+t[4],+t[5]))}function i(t){return null==t?o.a:(s||(s=document.createElementNS(\"http://www.w3.org/2000/svg\",\"g\")),s.setAttribute(\"transform\",t),(t=s.transform.baseVal.consolidate())?(t=t.matrix,n.i(o.b)(t.a,t.b,t.c,t.d,t.e,t.f)):o.a)}var o=n(224);e.a=r,e.b=i;var a,u,c,s},function(t,e,n){\"use strict\";Math.SQRT2},function(t,e,n){\"use strict\";function r(){this._x0=this._y0=this._x1=this._y1=null,this._=\"\"}function i(){return new r}var o=Math.PI,a=2*o,u=1e-6,c=a-u;r.prototype=i.prototype={constructor:r,moveTo:function(t,e){this._+=\"M\"+(this._x0=this._x1=+t)+\",\"+(this._y0=this._y1=+e)},closePath:function(){null!==this._x1&&(this._x1=this._x0,this._y1=this._y0,this._+=\"Z\")},lineTo:function(t,e){this._+=\"L\"+(this._x1=+t)+\",\"+(this._y1=+e)},quadraticCurveTo:function(t,e,n,r){this._+=\"Q\"+ +t+\",\"+ +e+\",\"+(this._x1=+n)+\",\"+(this._y1=+r)},bezierCurveTo:function(t,e,n,r,i,o){this._+=\"C\"+ +t+\",\"+ +e+\",\"+ +n+\",\"+ +r+\",\"+(this._x1=+i)+\",\"+(this._y1=+o)},arcTo:function(t,e,n,r,i){t=+t,e=+e,n=+n,r=+r,i=+i;var a=this._x1,c=this._y1,s=n-t,l=r-e,f=a-t,p=c-e,h=f*f+p*p;if(i<0)throw new Error(\"negative radius: \"+i);if(null===this._x1)this._+=\"M\"+(this._x1=t)+\",\"+(this._y1=e);else if(h>u)if(Math.abs(p*s-l*f)>u&&i){var d=n-a,v=r-c,g=s*s+l*l,m=d*d+v*v,y=Math.sqrt(g),_=Math.sqrt(h),b=i*Math.tan((o-Math.acos((g+h-m)/(2*y*_)))/2),x=b/_,w=b/y;Math.abs(x-1)>u&&(this._+=\"L\"+(t+x*f)+\",\"+(e+x*p)),this._+=\"A\"+i+\",\"+i+\",0,0,\"+ +(p*d>f*v)+\",\"+(this._x1=t+w*s)+\",\"+(this._y1=e+w*l)}else this._+=\"L\"+(this._x1=t)+\",\"+(this._y1=e);else;},arc:function(t,e,n,r,i,s){t=+t,e=+e,n=+n;var l=n*Math.cos(r),f=n*Math.sin(r),p=t+l,h=e+f,d=1^s,v=s?r-i:i-r;if(n<0)throw new Error(\"negative radius: \"+n);null===this._x1?this._+=\"M\"+p+\",\"+h:(Math.abs(this._x1-p)>u||Math.abs(this._y1-h)>u)&&(this._+=\"L\"+p+\",\"+h),n&&(v>c?this._+=\"A\"+n+\",\"+n+\",0,1,\"+d+\",\"+(t-l)+\",\"+(e-f)+\"A\"+n+\",\"+n+\",0,1,\"+d+\",\"+(this._x1=p)+\",\"+(this._y1=h):(v<0&&(v=v%a+a),this._+=\"A\"+n+\",\"+n+\",0,\"+ +(v>=o)+\",\"+d+\",\"+(this._x1=t+n*Math.cos(i))+\",\"+(this._y1=e+n*Math.sin(i))))},rect:function(t,e,n,r){this._+=\"M\"+(this._x0=this._x1=+t)+\",\"+(this._y0=this._y1=+e)+\"h\"+ +n+\"v\"+ +r+\"h\"+-n+\"Z\"},toString:function(){return this._}},e.a=i},function(t,e,n){\"use strict\";function r(){function t(){var t=c().length,r=l[1]<l[0],o=l[r-0],u=l[1-r];e=(u-o)/Math.max(1,t-p+2*h),f&&(e=Math.floor(e)),o+=(u-o-e*(t-p))*d,i=e*(1-p),f&&(o=Math.round(o),i=Math.round(i));var v=n.i(a.g)(t).map(function(t){return o+e*t});return s(r?v.reverse():v)}var e,i,o=n.i(u.a)().unknown(void 0),c=o.domain,s=o.range,l=[0,1],f=!1,p=0,h=0,d=.5;return delete o.unknown,o.domain=function(e){return arguments.length?(c(e),t()):c()},o.range=function(e){return arguments.length?(l=[+e[0],+e[1]],t()):l.slice()},o.rangeRound=function(e){return l=[+e[0],+e[1]],f=!0,t()},o.bandwidth=function(){return i},o.step=function(){return e},o.round=function(e){return arguments.length?(f=!!e,t()):f},o.padding=function(e){return arguments.length?(p=h=Math.max(0,Math.min(1,e)),t()):p},o.paddingInner=function(e){return arguments.length?(p=Math.max(0,Math.min(1,e)),t()):p},o.paddingOuter=function(e){return arguments.length?(h=Math.max(0,Math.min(1,e)),t()):h},o.align=function(e){return arguments.length?(d=Math.max(0,Math.min(1,e)),t()):d},o.copy=function(){return r().domain(c()).range(l).round(f).paddingInner(p).paddingOuter(h).align(d)},t()}function i(t){var e=t.copy;return t.padding=t.paddingOuter,delete t.paddingInner,delete t.paddingOuter,t.copy=function(){return i(e())},t}function o(){return i(r().paddingInner(1))}var a=n(12),u=n(127);e.a=r,e.b=o},function(t,e,n){\"use strict\";var r=n(33);e.a=n.i(r.a)(\"1f77b4ff7f0e2ca02cd627289467bd8c564be377c27f7f7fbcbd2217becf\")},function(t,e,n){\"use strict\";var r=n(33);e.a=n.i(r.a)(\"1f77b4aec7e8ff7f0effbb782ca02c98df8ad62728ff98969467bdc5b0d58c564bc49c94e377c2f7b6d27f7f7fc7c7c7bcbd22dbdb8d17becf9edae5\")},function(t,e,n){\"use strict\";var r=n(33);e.a=n.i(r.a)(\"393b795254a36b6ecf9c9ede6379398ca252b5cf6bcedb9c8c6d31bd9e39e7ba52e7cb94843c39ad494ad6616be7969c7b4173a55194ce6dbdde9ed6\")},function(t,e,n){\"use strict\";var r=n(33);e.a=n.i(r.a)(\"3182bd6baed69ecae1c6dbefe6550dfd8d3cfdae6bfdd0a231a35474c476a1d99bc7e9c0756bb19e9ac8bcbddcdadaeb636363969696bdbdbdd9d9d9\")},function(t,e,n){\"use strict\";var r=n(10),i=n(31);e.a=n.i(i.d)(n.i(r.cubehelix)(300,.5,0),n.i(r.cubehelix)(-240,.5,1))},function(t,e,n){\"use strict\";function r(){function t(t){return+t}var e=[0,1];return t.invert=t,t.domain=t.range=function(n){return arguments.length?(e=i.a.call(n,a.a),t):e.slice()},t.copy=function(){return r().domain(e)},n.i(o.b)(t)}var i=n(16),o=n(34),a=n(126);e.a=r},function(t,e,n){\"use strict\";function r(t,e){return(e=Math.log(e/t))?function(n){return Math.log(n/t)/e}:n.i(p.a)(e)}function i(t,e){return t<0?function(n){return-Math.pow(-e,n)*Math.pow(-t,1-n)}:function(n){return Math.pow(e,n)*Math.pow(t,1-n)}}function o(t){return isFinite(t)?+(\"1e\"+t):t<0?0:t}function a(t){return 10===t?o:t===Math.E?Math.exp:function(e){return Math.pow(t,e)}}function u(t){return t===Math.E?Math.log:10===t&&Math.log10||2===t&&Math.log2||(t=Math.log(t),function(e){return Math.log(e)/t})}function c(t){return function(e){return-t(-e)}}function s(){function t(){return v=u(p),g=a(p),o()[0]<0&&(v=c(v),g=c(g)),e}var e=n.i(d.a)(r,i).domain([1,10]),o=e.domain,p=10,v=u(10),g=a(10);return e.base=function(e){return arguments.length?(p=+e,t()):p},e.domain=function(e){return arguments.length?(o(e),t()):o()},e.ticks=function(t){var e,r=o(),i=r[0],a=r[r.length-1];(e=a<i)&&(f=i,i=a,a=f);var u,c,s,f=v(i),h=v(a),d=null==t?10:+t,m=[];if(!(p%1)&&h-f<d){if(f=Math.round(f)-1,h=Math.round(h)+1,i>0){for(;f<h;++f)for(c=1,u=g(f);c<p;++c)if(s=u*c,!(s<i)){if(s>a)break;m.push(s)}}else for(;f<h;++f)for(c=p-1,u=g(f);c>=1;--c)if(s=u*c,!(s<i)){if(s>a)break;m.push(s)}}else m=n.i(l.a)(f,h,Math.min(h-f,d)).map(g);return e?m.reverse():m},e.tickFormat=function(t,r){if(null==r&&(r=10===p?\".0e\":\",\"),\"function\"!=typeof r&&(r=n.i(f.format)(r)),t===1/0)return r;null==t&&(t=10);var i=Math.max(1,p*t/e.ticks().length);return function(t){var e=t/g(Math.round(v(t)));return e*p<p-.5&&(e*=p),e<=i?r(t):\"\"}},e.nice=function(){return o(n.i(h.a)(o(),{floor:function(t){return g(Math.floor(v(t)))},ceil:function(t){return g(Math.ceil(v(t)))}}))},e.copy=function(){return n.i(d.c)(e,s().base(p))},e}var l=n(12),f=n(30),p=n(65),h=n(125),d=n(45);e.a=s},function(t,e,n){\"use strict\";function r(t,e){return t<0?-Math.pow(-t,e):Math.pow(t,e)}function i(){function t(t,e){return(e=r(e,o)-(t=r(t,o)))?function(n){return(r(n,o)-t)/e}:n.i(a.a)(e)}function e(t,e){return e=r(e,o)-(t=r(t,o)),function(n){return r(t+e*n,1/o)}}var o=1,s=n.i(c.a)(t,e),l=s.domain;return s.exponent=function(t){return arguments.length?(o=+t,l(l())):o},s.copy=function(){return n.i(c.c)(s,i().exponent(o))},n.i(u.b)(s)}function o(){return i().exponent(.5)}var a=n(65),u=n(34),c=n(45);e.a=i,e.b=o},function(t,e,n){\"use strict\";function r(){function t(){var t=0,r=Math.max(1,u.length);for(c=new Array(r-1);++t<r;)c[t-1]=n.i(i.e)(a,t/r);return e}function e(t){if(!isNaN(t=+t))return u[n.i(i.c)(c,t)]}var a=[],u=[],c=[];return e.invertExtent=function(t){var e=u.indexOf(t);return e<0?[NaN,NaN]:[e>0?c[e-1]:a[0],e<c.length?c[e]:a[a.length-1]]},e.domain=function(e){if(!arguments.length)return a.slice();a=[];for(var n,r=0,o=e.length;r<o;++r)n=e[r],null==n||isNaN(n=+n)||a.push(n);return a.sort(i.f),t()},e.range=function(e){return arguments.length?(u=o.b.call(e),t()):u.slice()},e.quantiles=function(){return c.slice()},e.copy=function(){return r().domain(a).range(u)},e}var i=n(12),o=n(16);e.a=r},function(t,e,n){\"use strict\";function r(){function t(t){if(t<=t)return f[n.i(i.c)(l,t,0,s)]}function e(){var e=-1;for(l=new Array(s);++e<s;)l[e]=((e+1)*c-(e-s)*u)/(s+1);return t}var u=0,c=1,s=1,l=[.5],f=[0,1];return t.domain=function(t){return arguments.length?(u=+t[0],c=+t[1],e()):[u,c]},t.range=function(t){return arguments.length?(s=(f=o.b.call(t)).length-1,e()):f.slice()},t.invertExtent=function(t){var e=f.indexOf(t);return e<0?[NaN,NaN]:e<1?[u,l[0]]:e>=s?[l[s-1],c]:[l[e-1],l[e]]},t.copy=function(){return r().domain([u,c]).range(f)},n.i(a.b)(t)}var i=n(12),o=n(16),a=n(34);e.a=r},function(t,e,n){\"use strict\";var r=n(10),i=n(31);n.d(e,\"b\",function(){return o}),n.d(e,\"c\",function(){return a});var o=n.i(i.d)(n.i(r.cubehelix)(-100,.75,.35),n.i(r.cubehelix)(80,1.5,.8)),a=n.i(i.d)(n.i(r.cubehelix)(260,.75,.35),n.i(r.cubehelix)(80,1.5,.8)),u=n.i(r.cubehelix)();e.a=function(t){(t<0||t>1)&&(t-=Math.floor(t));var e=Math.abs(t-.5);return u.h=360*t-100,u.s=1.5-1.5*e,u.l=.8-.9*e,u+\"\"}},function(t,e,n){\"use strict\";function r(t){function e(e){var n=(e-o)/(a-o);return t(u?Math.max(0,Math.min(1,n)):n)}var o=0,a=1,u=!1;return e.domain=function(t){return arguments.length?(o=+t[0],a=+t[1],e):[o,a]},e.clamp=function(t){return arguments.length?(u=!!t,e):u},e.interpolator=function(n){return arguments.length?(t=n,e):t},e.copy=function(){return r(t).domain([o,a]).clamp(u)},n.i(i.b)(e)}var i=n(34);e.a=r},function(t,e,n){\"use strict\";function r(){function t(t){if(t<=t)return a[n.i(i.c)(e,t,0,u)]}var e=[.5],a=[0,1],u=1;return t.domain=function(n){return arguments.length?(e=o.b.call(n),u=Math.min(e.length,a.length-1),t):e.slice()},t.range=function(n){return arguments.length?(a=o.b.call(n),u=Math.min(e.length,a.length-1),t):a.slice()},t.invertExtent=function(t){var n=a.indexOf(t);return[e[n-1],e[n]]},t.copy=function(){return r().domain(e).range(a)},t}var i=n(12),o=n(16);e.a=r},function(t,e,n){\"use strict\";var r=n(12),i=n(30);e.a=function(t,e,o){var a,u=t[0],c=t[t.length-1],s=n.i(r.b)(u,c,null==e?10:e);switch(o=n.i(i.formatSpecifier)(null==o?\",f\":o),o.type){case\"s\":var l=Math.max(Math.abs(u),Math.abs(c));return null!=o.precision||isNaN(a=n.i(i.precisionPrefix)(s,l))||(o.precision=a),n.i(i.formatPrefix)(o,l);case\"\":case\"e\":case\"g\":case\"p\":case\"r\":null!=o.precision||isNaN(a=n.i(i.precisionRound)(s,Math.max(Math.abs(u),Math.abs(c))))||(o.precision=a-(\"e\"===o.type));break;case\"f\":case\"%\":null!=o.precision||isNaN(a=n.i(i.precisionFixed)(s))||(o.precision=a-2*(\"%\"===o.type))}return n.i(i.format)(o)}},function(t,e,n){\"use strict\";var r=n(128),i=n(77),o=n(79);e.a=function(){return n.i(r.b)(o.f,o.i,o.j,o.e,o.k,o.l,o.m,o.n,i.utcFormat).domain([Date.UTC(2e3,0,1),Date.UTC(2e3,0,2)])}},function(t,e,n){\"use strict\";function r(t){var e=t.length;return function(n){return t[Math.max(0,Math.min(e-1,Math.floor(n*e)))]}}var i=n(33);n.d(e,\"b\",function(){return o}),n.d(e,\"c\",function(){return a}),n.d(e,\"d\",function(){return u}),e.a=r(n.i(i.a)(\"44015444025645045745055946075a46085c460a5d460b5e470d60470e6147106347116447136548146748166848176948186a481a6c481b6d481c6e481d6f481f70482071482173482374482475482576482677482878482979472a7a472c7a472d7b472e7c472f7d46307e46327e46337f463480453581453781453882443983443a83443b84433d84433e85423f854240864241864142874144874045884046883f47883f48893e49893e4a893e4c8a3d4d8a3d4e8a3c4f8a3c508b3b518b3b528b3a538b3a548c39558c39568c38588c38598c375a8c375b8d365c8d365d8d355e8d355f8d34608d34618d33628d33638d32648e32658e31668e31678e31688e30698e306a8e2f6b8e2f6c8e2e6d8e2e6e8e2e6f8e2d708e2d718e2c718e2c728e2c738e2b748e2b758e2a768e2a778e2a788e29798e297a8e297b8e287c8e287d8e277e8e277f8e27808e26818e26828e26828e25838e25848e25858e24868e24878e23888e23898e238a8d228b8d228c8d228d8d218e8d218f8d21908d21918c20928c20928c20938c1f948c1f958b1f968b1f978b1f988b1f998a1f9a8a1e9b8a1e9c891e9d891f9e891f9f881fa0881fa1881fa1871fa28720a38620a48621a58521a68522a78522a88423a98324aa8325ab8225ac8226ad8127ad8128ae8029af7f2ab07f2cb17e2db27d2eb37c2fb47c31b57b32b67a34b67935b77937b87838b9773aba763bbb753dbc743fbc7340bd7242be7144bf7046c06f48c16e4ac16d4cc26c4ec36b50c46a52c56954c56856c66758c7655ac8645cc8635ec96260ca6063cb5f65cb5e67cc5c69cd5b6ccd5a6ece5870cf5773d05675d05477d1537ad1517cd2507fd34e81d34d84d44b86d54989d5488bd6468ed64590d74393d74195d84098d83e9bd93c9dd93ba0da39a2da37a5db36a8db34aadc32addc30b0dd2fb2dd2db5de2bb8de29bade28bddf26c0df25c2df23c5e021c8e020cae11fcde11dd0e11cd2e21bd5e21ad8e219dae319dde318dfe318e2e418e5e419e7e419eae51aece51befe51cf1e51df4e61ef6e620f8e621fbe723fde725\"));var o=r(n.i(i.a)(\"00000401000501010601010802010902020b02020d03030f03031204041405041606051806051a07061c08071e0907200a08220b09240c09260d0a290e0b2b100b2d110c2f120d31130d34140e36150e38160f3b180f3d19103f1a10421c10441d11471e114920114b21114e22115024125325125527125829115a2a115c2c115f2d11612f116331116533106734106936106b38106c390f6e3b0f703d0f713f0f72400f74420f75440f764510774710784910784a10794c117a4e117b4f127b51127c52137c54137d56147d57157e59157e5a167e5c167f5d177f5f187f601880621980641a80651a80671b80681c816a1c816b1d816d1d816e1e81701f81721f817320817521817621817822817922827b23827c23827e24828025828125818326818426818627818827818928818b29818c29818e2a81902a81912b81932b80942c80962c80982d80992d809b2e7f9c2e7f9e2f7fa02f7fa1307ea3307ea5317ea6317da8327daa337dab337cad347cae347bb0357bb2357bb3367ab5367ab73779b83779ba3878bc3978bd3977bf3a77c03a76c23b75c43c75c53c74c73d73c83e73ca3e72cc3f71cd4071cf4070d0416fd2426fd3436ed5446dd6456cd8456cd9466bdb476adc4869de4968df4a68e04c67e24d66e34e65e44f64e55064e75263e85362e95462ea5661eb5760ec5860ed5a5fee5b5eef5d5ef05f5ef1605df2625df2645cf3655cf4675cf4695cf56b5cf66c5cf66e5cf7705cf7725cf8745cf8765cf9785df9795df97b5dfa7d5efa7f5efa815ffb835ffb8560fb8761fc8961fc8a62fc8c63fc8e64fc9065fd9266fd9467fd9668fd9869fd9a6afd9b6bfe9d6cfe9f6dfea16efea36ffea571fea772fea973feaa74feac76feae77feb078feb27afeb47bfeb67cfeb77efeb97ffebb81febd82febf84fec185fec287fec488fec68afec88cfeca8dfecc8ffecd90fecf92fed194fed395fed597fed799fed89afdda9cfddc9efddea0fde0a1fde2a3fde3a5fde5a7fde7a9fde9aafdebacfcecaefceeb0fcf0b2fcf2b4fcf4b6fcf6b8fcf7b9fcf9bbfcfbbdfcfdbf\")),a=r(n.i(i.a)(\"00000401000501010601010802010a02020c02020e03021004031204031405041706041907051b08051d09061f0a07220b07240c08260d08290e092b10092d110a30120a32140b34150b37160b39180c3c190c3e1b0c411c0c431e0c451f0c48210c4a230c4c240c4f260c51280b53290b552b0b572d0b592f0a5b310a5c320a5e340a5f3609613809623909633b09643d09653e0966400a67420a68440a68450a69470b6a490b6a4a0c6b4c0c6b4d0d6c4f0d6c510e6c520e6d540f6d550f6d57106e59106e5a116e5c126e5d126e5f136e61136e62146e64156e65156e67166e69166e6a176e6c186e6d186e6f196e71196e721a6e741a6e751b6e771c6d781c6d7a1d6d7c1d6d7d1e6d7f1e6c801f6c82206c84206b85216b87216b88226a8a226a8c23698d23698f24699025689225689326679526679727669827669a28659b29649d29649f2a63a02a63a22b62a32c61a52c60a62d60a82e5fa92e5eab2f5ead305dae305cb0315bb1325ab3325ab43359b63458b73557b93556ba3655bc3754bd3853bf3952c03a51c13a50c33b4fc43c4ec63d4dc73e4cc83f4bca404acb4149cc4248ce4347cf4446d04545d24644d34743d44842d54a41d74b3fd84c3ed94d3dda4e3cdb503bdd513ade5238df5337e05536e15635e25734e35933e45a31e55c30e65d2fe75e2ee8602de9612bea632aeb6429eb6628ec6726ed6925ee6a24ef6c23ef6e21f06f20f1711ff1731df2741cf3761bf37819f47918f57b17f57d15f67e14f68013f78212f78410f8850ff8870ef8890cf98b0bf98c0af98e09fa9008fa9207fa9407fb9606fb9706fb9906fb9b06fb9d07fc9f07fca108fca309fca50afca60cfca80dfcaa0ffcac11fcae12fcb014fcb216fcb418fbb61afbb81dfbba1ffbbc21fbbe23fac026fac228fac42afac62df9c72ff9c932f9cb35f8cd37f8cf3af7d13df7d340f6d543f6d746f5d949f5db4cf4dd4ff4df53f4e156f3e35af3e55df2e661f2e865f2ea69f1ec6df1ed71f1ef75f1f179f2f27df2f482f3f586f3f68af4f88ef5f992f6fa96f8fb9af9fc9dfafda1fcffa4\")),u=r(n.i(i.a)(\"0d088710078813078916078a19068c1b068d1d068e20068f2206902406912605912805922a05932c05942e05952f059631059733059735049837049938049a3a049a3c049b3e049c3f049c41049d43039e44039e46039f48039f4903a04b03a14c02a14e02a25002a25102a35302a35502a45601a45801a45901a55b01a55c01a65e01a66001a66100a76300a76400a76600a76700a86900a86a00a86c00a86e00a86f00a87100a87201a87401a87501a87701a87801a87a02a87b02a87d03a87e03a88004a88104a78305a78405a78606a68707a68808a68a09a58b0aa58d0ba58e0ca48f0da4910ea3920fa39410a29511a19613a19814a099159f9a169f9c179e9d189d9e199da01a9ca11b9ba21d9aa31e9aa51f99a62098a72197a82296aa2395ab2494ac2694ad2793ae2892b02991b12a90b22b8fb32c8eb42e8db52f8cb6308bb7318ab83289ba3388bb3488bc3587bd3786be3885bf3984c03a83c13b82c23c81c33d80c43e7fc5407ec6417dc7427cc8437bc9447aca457acb4679cc4778cc4977cd4a76ce4b75cf4c74d04d73d14e72d24f71d35171d45270d5536fd5546ed6556dd7566cd8576bd9586ada5a6ada5b69db5c68dc5d67dd5e66de5f65de6164df6263e06363e16462e26561e26660e3685fe4695ee56a5de56b5de66c5ce76e5be76f5ae87059e97158e97257ea7457eb7556eb7655ec7754ed7953ed7a52ee7b51ef7c51ef7e50f07f4ff0804ef1814df1834cf2844bf3854bf3874af48849f48948f58b47f58c46f68d45f68f44f79044f79143f79342f89441f89540f9973ff9983ef99a3efa9b3dfa9c3cfa9e3bfb9f3afba139fba238fca338fca537fca636fca835fca934fdab33fdac33fdae32fdaf31fdb130fdb22ffdb42ffdb52efeb72dfeb82cfeba2cfebb2bfebd2afebe2afec029fdc229fdc328fdc527fdc627fdc827fdca26fdcb26fccd25fcce25fcd025fcd225fbd324fbd524fbd724fad824fada24f9dc24f9dd25f8df25f8e125f7e225f7e425f6e626f6e826f5e926f5eb27f4ed27f3ee27f3f027f2f227f1f426f1f525f0f724f0f921\"))},function(t,e,n){\"use strict\";e.a=function(t){return function(){return t}}},function(t,e,n){\"use strict\";function r(){return new i}function i(){this._=\"@\"+(++o).toString(36)}e.a=r;var o=0;i.prototype=r.prototype={constructor:i,get:function(t){for(var e=this._;!(e in t);)if(!(t=t.parentNode))return;return t[e]},set:function(t,e){return t[this._]=e},remove:function(t){return this._ in t&&delete t[this._]},toString:function(){return this._}}},function(t,e,n){\"use strict\";var r=n(72),i=n(69);e.a=function(t){var e=n.i(r.a)();return e.changedTouches&&(e=e.changedTouches[0]),n.i(i.a)(t,e)}},function(t,e,n){\"use strict\";var r=n(7);e.a=function(t){return\"string\"==typeof t?new r.b([[document.querySelector(t)]],[document.documentElement]):new r.b([[t]],r.c)}},function(t,e,n){\"use strict\";var r=n(7);e.a=function(t){return\"string\"==typeof t?new r.b([document.querySelectorAll(t)],[document.documentElement]):new r.b([null==t?[]:t],r.c)}},function(t,e,n){\"use strict\";var r=n(66);e.a=function(t){var e=\"function\"==typeof t?t:n.i(r.a)(t);return this.select(function(){return this.appendChild(e.apply(this,arguments))})}},function(t,e,n){\"use strict\";function r(t){return function(){this.removeAttribute(t)}}function i(t){return function(){this.removeAttributeNS(t.space,t.local)}}function o(t,e){return function(){this.setAttribute(t,e)}}function a(t,e){return function(){this.setAttributeNS(t.space,t.local,e)}}function u(t,e){return function(){var n=e.apply(this,arguments);null==n?this.removeAttribute(t):this.setAttribute(t,n)}}function c(t,e){return function(){var n=e.apply(this,arguments);null==n?this.removeAttributeNS(t.space,t.local):this.setAttributeNS(t.space,t.local,n)}}var s=n(67);e.a=function(t,e){var l=n.i(s.a)(t);if(arguments.length<2){var f=this.node();return l.local?f.getAttributeNS(l.space,l.local):f.getAttribute(l)}return this.each((null==e?l.local?i:r:\"function\"==typeof e?l.local?c:u:l.local?a:o)(l,e))}},function(t,e,n){\"use strict\";e.a=function(){var t=arguments[0];return arguments[0]=this,t.apply(null,arguments),this}},function(t,e,n){\"use strict\";function r(t){return t.trim().split(/^|\\s+/)}function i(t){return t.classList||new o(t)}function o(t){this._node=t,this._names=r(t.getAttribute(\"class\")||\"\")}function a(t,e){for(var n=i(t),r=-1,o=e.length;++r<o;)n.add(e[r])}function u(t,e){for(var n=i(t),r=-1,o=e.length;++r<o;)n.remove(e[r])}function c(t){return function(){a(this,t)}}function s(t){return function(){u(this,t)}}function l(t,e){return function(){(e.apply(this,arguments)?a:u)(this,t)}}o.prototype={add:function(t){var e=this._names.indexOf(t);e<0&&(this._names.push(t),this._node.setAttribute(\"class\",this._names.join(\" \")))},remove:function(t){var e=this._names.indexOf(t);e>=0&&(this._names.splice(e,1),this._node.setAttribute(\"class\",this._names.join(\" \")))},contains:function(t){return this._names.indexOf(t)>=0}},e.a=function(t,e){var n=r(t+\"\");if(arguments.length<2){for(var o=i(this.node()),a=-1,u=n.length;++a<u;)if(!o.contains(n[a]))return!1;return!0}return this.each((\"function\"==typeof e?l:e?c:s)(n,e))}},function(t,e,n){\"use strict\";function r(t,e,n,r,i,o){for(var u,c=0,s=e.length,l=o.length;c<l;++c)(u=e[c])?(u.__data__=o[c],r[c]=u):n[c]=new a.b(t,o[c]);for(;c<s;++c)(u=e[c])&&(i[c]=u)}function i(t,e,n,r,i,o,u){var s,l,f,p={},h=e.length,d=o.length,v=new Array(h);for(s=0;s<h;++s)(l=e[s])&&(v[s]=f=c+u.call(l,l.__data__,s,e),f in p?i[s]=l:p[f]=l);for(s=0;s<d;++s)f=c+u.call(t,o[s],s,o),(l=p[f])?(r[s]=l,l.__data__=o[s],p[f]=null):n[s]=new a.b(t,o[s]);for(s=0;s<h;++s)(l=e[s])&&p[v[s]]===l&&(i[s]=l)}var o=n(7),a=n(131),u=n(246),c=\"$\";e.a=function(t,e){if(!t)return y=new Array(this.size()),d=-1,this.each(function(t){y[++d]=t}),y;var a=e?i:r,c=this._parents,s=this._groups;\"function\"!=typeof t&&(t=n.i(u.a)(t));for(var l=s.length,f=new Array(l),p=new Array(l),h=new Array(l),d=0;d<l;++d){var v=c[d],g=s[d],m=g.length,y=t.call(v,v&&v.__data__,d,c),_=y.length,b=p[d]=new Array(_),x=f[d]=new Array(_),w=h[d]=new Array(m);a(v,g,b,x,w,y,e);for(var C,M,k=0,E=0;k<_;++k)if(C=b[k]){for(k>=E&&(E=k+1);!(M=x[E])&&++E<_;);C._next=M||null}}return f=new o.b(f,c),f._enter=p,f._exit=h,f}},function(t,e,n){\"use strict\";e.a=function(t){return arguments.length?this.property(\"__data__\",t):this.node().__data__}},function(t,e,n){\"use strict\";function r(t,e,r){var i=n.i(a.a)(t),o=i.CustomEvent;o?o=new o(e,r):(o=i.document.createEvent(\"Event\"),r?(o.initEvent(e,r.bubbles,r.cancelable),o.detail=r.detail):o.initEvent(e,!1,!1)),t.dispatchEvent(o)}function i(t,e){return function(){return r(this,t,e)}}function o(t,e){return function(){return r(this,t,e.apply(this,arguments))}}var a=n(73);e.a=function(t,e){return this.each((\"function\"==typeof e?o:i)(t,e))}},function(t,e,n){\"use strict\";e.a=function(t){for(var e=this._groups,n=0,r=e.length;n<r;++n)for(var i,o=e[n],a=0,u=o.length;a<u;++a)(i=o[a])&&t.call(i,i.__data__,a,o);return this}},function(t,e,n){\"use strict\";e.a=function(){return!this.node()}},function(t,e,n){\"use strict\";var r=n(132),i=n(7);e.a=function(){return new i.b(this._exit||this._groups.map(r.a),this._parents)}},function(t,e,n){\"use strict\";var r=n(7),i=n(130);e.a=function(t){\"function\"!=typeof t&&(t=n.i(i.a)(t));for(var e=this._groups,o=e.length,a=new Array(o),u=0;u<o;++u)for(var c,s=e[u],l=s.length,f=a[u]=[],p=0;p<l;++p)(c=s[p])&&t.call(c,c.__data__,p,s)&&f.push(c);return new r.b(a,this._parents)}},function(t,e,n){\"use strict\";function r(){this.innerHTML=\"\"}function i(t){return function(){this.innerHTML=t}}function o(t){return function(){var e=t.apply(this,arguments);this.innerHTML=null==e?\"\":e}}e.a=function(t){return arguments.length?this.each(null==t?r:(\"function\"==typeof t?o:i)(t)):this.node().innerHTML}},function(t,e,n){\"use strict\";function r(){return null}var i=n(66),o=n(71);e.a=function(t,e){var a=\"function\"==typeof t?t:n.i(i.a)(t),u=null==e?r:\"function\"==typeof e?e:n.i(o.a)(e);return this.select(function(){return this.insertBefore(a.apply(this,arguments),u.apply(this,arguments)||null)})}},function(t,e,n){\"use strict\";function r(){this.previousSibling&&this.parentNode.insertBefore(this,this.parentNode.firstChild)}e.a=function(){return this.each(r)}},function(t,e,n){\"use strict\";var r=n(7);e.a=function(t){for(var e=this._groups,n=t._groups,i=e.length,o=n.length,a=Math.min(i,o),u=new Array(i),c=0;c<a;++c)for(var s,l=e[c],f=n[c],p=l.length,h=u[c]=new Array(p),d=0;d<p;++d)(s=l[d]||f[d])&&(h[d]=s);for(;c<i;++c)u[c]=e[c];return new r.b(u,this._parents)}},function(t,e,n){\"use strict\";e.a=function(){for(var t=this._groups,e=0,n=t.length;e<n;++e)for(var r=t[e],i=0,o=r.length;i<o;++i){var a=r[i];if(a)return a}return null}},function(t,e,n){\"use strict\";e.a=function(){var t=new Array(this.size()),e=-1;return this.each(function(){t[++e]=this}),t}},function(t,e,n){\"use strict\";e.a=function(){for(var t=this._groups,e=-1,n=t.length;++e<n;)for(var r,i=t[e],o=i.length-1,a=i[o];--o>=0;)(r=i[o])&&(a&&a!==r.nextSibling&&a.parentNode.insertBefore(r,a),a=r);return this}},function(t,e,n){\"use strict\";function r(t){return function(){delete this[t]}}function i(t,e){return function(){this[t]=e}}function o(t,e){return function(){var n=e.apply(this,arguments);null==n?delete this[t]:this[t]=n}}e.a=function(t,e){return arguments.length>1?this.each((null==e?r:\"function\"==typeof e?o:i)(t,e)):this.node()[t]}},function(t,e,n){\"use strict\";function r(){this.nextSibling&&this.parentNode.appendChild(this)}e.a=function(){return this.each(r)}},function(t,e,n){\"use strict\";function r(){var t=this.parentNode;t&&t.removeChild(this)}e.a=function(){return this.each(r)}},function(t,e,n){\"use strict\";var r=n(7),i=n(71);e.a=function(t){\"function\"!=typeof t&&(t=n.i(i.a)(t));for(var e=this._groups,o=e.length,a=new Array(o),u=0;u<o;++u)for(var c,s,l=e[u],f=l.length,p=a[u]=new Array(f),h=0;h<f;++h)(c=l[h])&&(s=t.call(c,c.__data__,h,l))&&(\"__data__\"in c&&(s.__data__=c.__data__),p[h]=s);return new r.b(a,this._parents)}},function(t,e,n){\"use strict\";var r=n(7),i=n(133);e.a=function(t){\"function\"!=typeof t&&(t=n.i(i.a)(t));for(var e=this._groups,o=e.length,a=[],u=[],c=0;c<o;++c)for(var s,l=e[c],f=l.length,p=0;p<f;++p)(s=l[p])&&(a.push(t.call(s,s.__data__,p,l)),u.push(s));return new r.b(a,u)}},function(t,e,n){\"use strict\";e.a=function(){var t=0;return this.each(function(){++t}),t}},function(t,e,n){\"use strict\";function r(t,e){return t<e?-1:t>e?1:t>=e?0:NaN}var i=n(7);e.a=function(t){function e(e,n){return e&&n?t(e.__data__,n.__data__):!e-!n}t||(t=r);for(var n=this._groups,o=n.length,a=new Array(o),u=0;u<o;++u){for(var c,s=n[u],l=s.length,f=a[u]=new Array(l),p=0;p<l;++p)(c=s[p])&&(f[p]=c);f.sort(e)}return new i.b(a,this._parents).order()}},function(t,e,n){\"use strict\";function r(t){return function(){this.style.removeProperty(t)}}function i(t,e,n){return function(){this.style.setProperty(t,e,n)}}function o(t,e,n){return function(){var r=e.apply(this,arguments);null==r?this.style.removeProperty(t):this.style.setProperty(t,r,n)}}var a=n(73);e.a=function(t,e,u){var c;return arguments.length>1?this.each((null==e?r:\"function\"==typeof e?o:i)(t,e,null==u?\"\":u)):n.i(a.a)(c=this.node()).getComputedStyle(c,null).getPropertyValue(t)}},function(t,e,n){\"use strict\";function r(){this.textContent=\"\"}function i(t){return function(){this.textContent=t}}function o(t){return function(){var e=t.apply(this,arguments);this.textContent=null==e?\"\":e}}e.a=function(t){return arguments.length?this.each(null==t?r:(\"function\"==typeof t?o:i)(t)):this.node().textContent}},function(t,e,n){\"use strict\";var r=n(72),i=n(69);e.a=function(t,e,o){arguments.length<3&&(o=e,e=n.i(r.a)().changedTouches);for(var a,u=0,c=e?e.length:0;u<c;++u)if((a=e[u]).identifier===o)return n.i(i.a)(t,a);return null}},function(t,e,n){\"use strict\";var r=n(72),i=n(69);e.a=function(t,e){null==e&&(e=n.i(r.a)().touches);for(var o=0,a=e?e.length:0,u=new Array(a);o<a;++o)u[o]=n.i(i.a)(t,e[o]);return u}},function(t,e,n){\"use strict\";function r(t){return t.innerRadius}function i(t){return t.outerRadius}function o(t){return t.startAngle}function a(t){return t.endAngle}function u(t){return t&&t.padAngle}function c(t){return t>=1?h.d:t<=-1?-h.d:Math.asin(t)}function s(t,e,n,r,i,o,a,u){var c=n-t,s=r-e,l=a-i,f=u-o,p=(l*(e-o)-f*(t-i))/(f*c-l*s);return[t+p*c,e+p*s]}function l(t,e,n,r,i,o,a){var u=t-n,c=e-r,s=(a?o:-o)/Math.sqrt(u*u+c*c),l=s*c,f=-s*u,p=t+l,h=e+f,d=n+l,v=r+f,g=(p+d)/2,m=(h+v)/2,y=d-p,_=v-h,b=y*y+_*_,x=i-o,w=p*v-d*h,C=(_<0?-1:1)*Math.sqrt(Math.max(0,x*x*b-w*w)),M=(w*_-y*C)/b,k=(-w*y-_*C)/b,E=(w*_+y*C)/b,T=(-w*y+_*C)/b,S=M-g,P=k-m,N=E-g,A=T-m;return S*S+P*P>N*N+A*A&&(M=E,k=T),{cx:M,cy:k,x01:-l,y01:-f,x11:M*(i/x-1),y11:k*(i/x-1)}}var f=n(44),p=n(19),h=n(35);e.a=function(){function t(){var t,r,i=+e.apply(this,arguments),o=+d.apply(this,arguments),a=m.apply(this,arguments)-h.d,u=y.apply(this,arguments)-h.d,p=Math.abs(u-a),x=u>a;if(b||(b=t=n.i(f.a)()),o<i&&(r=o,o=i,i=r),o>h.a)if(p>h.c-h.a)b.moveTo(o*Math.cos(a),o*Math.sin(a)),b.arc(0,0,o,a,u,!x),i>h.a&&(b.moveTo(i*Math.cos(u),i*Math.sin(u)),b.arc(0,0,i,u,a,x));else{var w,C,M=a,k=u,E=a,T=u,S=p,P=p,N=_.apply(this,arguments)/2,A=N>h.a&&(g?+g.apply(this,arguments):Math.sqrt(i*i+o*o)),O=Math.min(Math.abs(o-i)/2,+v.apply(this,arguments)),I=O,D=O;\n",
       "if(A>h.a){var R=c(A/i*Math.sin(N)),L=c(A/o*Math.sin(N));(S-=2*R)>h.a?(R*=x?1:-1,E+=R,T-=R):(S=0,E=T=(a+u)/2),(P-=2*L)>h.a?(L*=x?1:-1,M+=L,k-=L):(P=0,M=k=(a+u)/2)}var U=o*Math.cos(M),F=o*Math.sin(M),j=i*Math.cos(T),B=i*Math.sin(T);if(O>h.a){var W=o*Math.cos(k),V=o*Math.sin(k),z=i*Math.cos(E),H=i*Math.sin(E);if(p<h.b){var q=S>h.a?s(U,F,z,H,W,V,j,B):[j,B],Y=U-q[0],K=F-q[1],G=W-q[0],$=V-q[1],X=1/Math.sin(Math.acos((Y*G+K*$)/(Math.sqrt(Y*Y+K*K)*Math.sqrt(G*G+$*$)))/2),Z=Math.sqrt(q[0]*q[0]+q[1]*q[1]);I=Math.min(O,(i-Z)/(X-1)),D=Math.min(O,(o-Z)/(X+1))}}P>h.a?D>h.a?(w=l(z,H,U,F,o,D,x),C=l(W,V,j,B,o,D,x),b.moveTo(w.cx+w.x01,w.cy+w.y01),D<O?b.arc(w.cx,w.cy,D,Math.atan2(w.y01,w.x01),Math.atan2(C.y01,C.x01),!x):(b.arc(w.cx,w.cy,D,Math.atan2(w.y01,w.x01),Math.atan2(w.y11,w.x11),!x),b.arc(0,0,o,Math.atan2(w.cy+w.y11,w.cx+w.x11),Math.atan2(C.cy+C.y11,C.cx+C.x11),!x),b.arc(C.cx,C.cy,D,Math.atan2(C.y11,C.x11),Math.atan2(C.y01,C.x01),!x))):(b.moveTo(U,F),b.arc(0,0,o,M,k,!x)):b.moveTo(U,F),i>h.a&&S>h.a?I>h.a?(w=l(j,B,W,V,i,-I,x),C=l(U,F,z,H,i,-I,x),b.lineTo(w.cx+w.x01,w.cy+w.y01),I<O?b.arc(w.cx,w.cy,I,Math.atan2(w.y01,w.x01),Math.atan2(C.y01,C.x01),!x):(b.arc(w.cx,w.cy,I,Math.atan2(w.y01,w.x01),Math.atan2(w.y11,w.x11),!x),b.arc(0,0,i,Math.atan2(w.cy+w.y11,w.cx+w.x11),Math.atan2(C.cy+C.y11,C.cx+C.x11),x),b.arc(C.cx,C.cy,I,Math.atan2(C.y11,C.x11),Math.atan2(C.y01,C.x01),!x))):b.arc(0,0,i,T,E,x):b.lineTo(j,B)}else b.moveTo(0,0);if(b.closePath(),t)return b=null,t+\"\"||null}var e=r,d=i,v=n.i(p.a)(0),g=null,m=o,y=a,_=u,b=null;return t.centroid=function(){var t=(+e.apply(this,arguments)+ +d.apply(this,arguments))/2,n=(+m.apply(this,arguments)+ +y.apply(this,arguments))/2-h.b/2;return[Math.cos(n)*t,Math.sin(n)*t]},t.innerRadius=function(r){return arguments.length?(e=\"function\"==typeof r?r:n.i(p.a)(+r),t):e},t.outerRadius=function(e){return arguments.length?(d=\"function\"==typeof e?e:n.i(p.a)(+e),t):d},t.cornerRadius=function(e){return arguments.length?(v=\"function\"==typeof e?e:n.i(p.a)(+e),t):v},t.padRadius=function(e){return arguments.length?(g=null==e?null:\"function\"==typeof e?e:n.i(p.a)(+e),t):g},t.startAngle=function(e){return arguments.length?(m=\"function\"==typeof e?e:n.i(p.a)(+e),t):m},t.endAngle=function(e){return arguments.length?(y=\"function\"==typeof e?e:n.i(p.a)(+e),t):y},t.padAngle=function(e){return arguments.length?(_=\"function\"==typeof e?e:n.i(p.a)(+e),t):_},t.context=function(e){return arguments.length?(b=null==e?null:e,t):b},t}},function(t,e,n){\"use strict\";n.d(e,\"a\",function(){return r});var r=Array.prototype.slice},function(t,e,n){\"use strict\";function r(t){this._context=t}var i=n(49),o=n(46);r.prototype={areaStart:i.a,areaEnd:i.a,lineStart:function(){this._x0=this._x1=this._x2=this._x3=this._x4=this._y0=this._y1=this._y2=this._y3=this._y4=NaN,this._point=0},lineEnd:function(){switch(this._point){case 1:this._context.moveTo(this._x2,this._y2),this._context.closePath();break;case 2:this._context.moveTo((this._x2+2*this._x3)/3,(this._y2+2*this._y3)/3),this._context.lineTo((this._x3+2*this._x2)/3,(this._y3+2*this._y2)/3),this._context.closePath();break;case 3:this.point(this._x2,this._y2),this.point(this._x3,this._y3),this.point(this._x4,this._y4)}},point:function(t,e){switch(t=+t,e=+e,this._point){case 0:this._point=1,this._x2=t,this._y2=e;break;case 1:this._point=2,this._x3=t,this._y3=e;break;case 2:this._point=3,this._x4=t,this._y4=e,this._context.moveTo((this._x0+4*this._x1+t)/6,(this._y0+4*this._y1+e)/6);break;default:n.i(o.c)(this,t,e)}this._x0=this._x1,this._x1=t,this._y0=this._y1,this._y1=e}},e.a=function(t){return new r(t)}},function(t,e,n){\"use strict\";function r(t){this._context=t}var i=n(46);r.prototype={areaStart:function(){this._line=0},areaEnd:function(){this._line=NaN},lineStart:function(){this._x0=this._x1=this._y0=this._y1=NaN,this._point=0},lineEnd:function(){(this._line||0!==this._line&&3===this._point)&&this._context.closePath(),this._line=1-this._line},point:function(t,e){switch(t=+t,e=+e,this._point){case 0:this._point=1;break;case 1:this._point=2;break;case 2:this._point=3;var r=(this._x0+4*this._x1+t)/6,o=(this._y0+4*this._y1+e)/6;this._line?this._context.lineTo(r,o):this._context.moveTo(r,o);break;case 3:this._point=4;default:n.i(i.c)(this,t,e)}this._x0=this._x1,this._x1=t,this._y0=this._y1,this._y1=e}},e.a=function(t){return new r(t)}},function(t,e,n){\"use strict\";function r(t,e){this._basis=new i.b(t),this._beta=e}var i=n(46);r.prototype={lineStart:function(){this._x=[],this._y=[],this._basis.lineStart()},lineEnd:function(){var t=this._x,e=this._y,n=t.length-1;if(n>0)for(var r,i=t[0],o=e[0],a=t[n]-i,u=e[n]-o,c=-1;++c<=n;)r=c/n,this._basis.point(this._beta*t[c]+(1-this._beta)*(i+r*a),this._beta*e[c]+(1-this._beta)*(o+r*u));this._x=this._y=null,this._basis.lineEnd()},point:function(t,e){this._x.push(+t),this._y.push(+e)}},e.a=function t(e){function n(t){return 1===e?new i.b(t):new r(t,e)}return n.beta=function(e){return t(+e)},n}(.85)},function(t,e,n){\"use strict\";function r(t,e){this._context=t,this._alpha=e}var i=n(136),o=n(49),a=n(74);r.prototype={areaStart:o.a,areaEnd:o.a,lineStart:function(){this._x0=this._x1=this._x2=this._x3=this._x4=this._x5=this._y0=this._y1=this._y2=this._y3=this._y4=this._y5=NaN,this._l01_a=this._l12_a=this._l23_a=this._l01_2a=this._l12_2a=this._l23_2a=this._point=0},lineEnd:function(){switch(this._point){case 1:this._context.moveTo(this._x3,this._y3),this._context.closePath();break;case 2:this._context.lineTo(this._x3,this._y3),this._context.closePath();break;case 3:this.point(this._x3,this._y3),this.point(this._x4,this._y4),this.point(this._x5,this._y5)}},point:function(t,e){if(t=+t,e=+e,this._point){var r=this._x2-t,i=this._y2-e;this._l23_a=Math.sqrt(this._l23_2a=Math.pow(r*r+i*i,this._alpha))}switch(this._point){case 0:this._point=1,this._x3=t,this._y3=e;break;case 1:this._point=2,this._context.moveTo(this._x4=t,this._y4=e);break;case 2:this._point=3,this._x5=t,this._y5=e;break;default:n.i(a.b)(this,t,e)}this._l01_a=this._l12_a,this._l12_a=this._l23_a,this._l01_2a=this._l12_2a,this._l12_2a=this._l23_2a,this._x0=this._x1,this._x1=this._x2,this._x2=t,this._y0=this._y1,this._y1=this._y2,this._y2=e}},e.a=function t(e){function n(t){return e?new r(t,e):new i.b(t,0)}return n.alpha=function(e){return t(+e)},n}(.5)},function(t,e,n){\"use strict\";function r(t,e){this._context=t,this._alpha=e}var i=n(137),o=n(74);r.prototype={areaStart:function(){this._line=0},areaEnd:function(){this._line=NaN},lineStart:function(){this._x0=this._x1=this._x2=this._y0=this._y1=this._y2=NaN,this._l01_a=this._l12_a=this._l23_a=this._l01_2a=this._l12_2a=this._l23_2a=this._point=0},lineEnd:function(){(this._line||0!==this._line&&3===this._point)&&this._context.closePath(),this._line=1-this._line},point:function(t,e){if(t=+t,e=+e,this._point){var r=this._x2-t,i=this._y2-e;this._l23_a=Math.sqrt(this._l23_2a=Math.pow(r*r+i*i,this._alpha))}switch(this._point){case 0:this._point=1;break;case 1:this._point=2;break;case 2:this._point=3,this._line?this._context.lineTo(this._x2,this._y2):this._context.moveTo(this._x2,this._y2);break;case 3:this._point=4;default:n.i(o.b)(this,t,e)}this._l01_a=this._l12_a,this._l12_a=this._l23_a,this._l01_2a=this._l12_2a,this._l12_2a=this._l23_2a,this._x0=this._x1,this._x1=this._x2,this._x2=t,this._y0=this._y1,this._y1=this._y2,this._y2=e}},e.a=function t(e){function n(t){return e?new r(t,e):new i.b(t,0)}return n.alpha=function(e){return t(+e)},n}(.5)},function(t,e,n){\"use strict\";function r(t){this._context=t}var i=n(49);r.prototype={areaStart:i.a,areaEnd:i.a,lineStart:function(){this._point=0},lineEnd:function(){this._point&&this._context.closePath()},point:function(t,e){t=+t,e=+e,this._point?this._context.lineTo(t,e):(this._point=1,this._context.moveTo(t,e))}},e.a=function(t){return new r(t)}},function(t,e,n){\"use strict\";function r(t){return t<0?-1:1}function i(t,e,n){var i=t._x1-t._x0,o=e-t._x1,a=(t._y1-t._y0)/(i||o<0&&-0),u=(n-t._y1)/(o||i<0&&-0),c=(a*o+u*i)/(i+o);return(r(a)+r(u))*Math.min(Math.abs(a),Math.abs(u),.5*Math.abs(c))||0}function o(t,e){var n=t._x1-t._x0;return n?(3*(t._y1-t._y0)/n-e)/2:e}function a(t,e,n){var r=t._x0,i=t._y0,o=t._x1,a=t._y1,u=(o-r)/3;t._context.bezierCurveTo(r+u,i+u*e,o-u,a-u*n,o,a)}function u(t){this._context=t}function c(t){this._context=new s(t)}function s(t){this._context=t}function l(t){return new u(t)}function f(t){return new c(t)}e.a=l,e.b=f,u.prototype={areaStart:function(){this._line=0},areaEnd:function(){this._line=NaN},lineStart:function(){this._x0=this._x1=this._y0=this._y1=this._t0=NaN,this._point=0},lineEnd:function(){switch(this._point){case 2:this._context.lineTo(this._x1,this._y1);break;case 3:a(this,this._t0,o(this,this._t0))}(this._line||0!==this._line&&1===this._point)&&this._context.closePath(),this._line=1-this._line},point:function(t,e){var n=NaN;if(t=+t,e=+e,t!==this._x1||e!==this._y1){switch(this._point){case 0:this._point=1,this._line?this._context.lineTo(t,e):this._context.moveTo(t,e);break;case 1:this._point=2;break;case 2:this._point=3,a(this,o(this,n=i(this,t,e)),n);break;default:a(this,this._t0,n=i(this,t,e))}this._x0=this._x1,this._x1=t,this._y0=this._y1,this._y1=e,this._t0=n}}},(c.prototype=Object.create(u.prototype)).point=function(t,e){u.prototype.point.call(this,e,t)},s.prototype={moveTo:function(t,e){this._context.moveTo(e,t)},closePath:function(){this._context.closePath()},lineTo:function(t,e){this._context.lineTo(e,t)},bezierCurveTo:function(t,e,n,r,i,o){this._context.bezierCurveTo(e,t,r,n,o,i)}}},function(t,e,n){\"use strict\";function r(t){this._context=t}function i(t){var e,n,r=t.length-1,i=new Array(r),o=new Array(r),a=new Array(r);for(i[0]=0,o[0]=2,a[0]=t[0]+2*t[1],e=1;e<r-1;++e)i[e]=1,o[e]=4,a[e]=4*t[e]+2*t[e+1];for(i[r-1]=2,o[r-1]=7,a[r-1]=8*t[r-1]+t[r],e=1;e<r;++e)n=i[e]/o[e-1],o[e]-=n,a[e]-=n*a[e-1];for(i[r-1]=a[r-1]/o[r-1],e=r-2;e>=0;--e)i[e]=(a[e]-i[e+1])/o[e];for(o[r-1]=(t[r]+i[r-1])/2,e=0;e<r-1;++e)o[e]=2*t[e+1]-i[e+1];return[i,o]}r.prototype={areaStart:function(){this._line=0},areaEnd:function(){this._line=NaN},lineStart:function(){this._x=[],this._y=[]},lineEnd:function(){var t=this._x,e=this._y,n=t.length;if(n)if(this._line?this._context.lineTo(t[0],e[0]):this._context.moveTo(t[0],e[0]),2===n)this._context.lineTo(t[1],e[1]);else for(var r=i(t),o=i(e),a=0,u=1;u<n;++a,++u)this._context.bezierCurveTo(r[0][a],o[0][a],r[1][a],o[1][a],t[u],e[u]);(this._line||0!==this._line&&1===n)&&this._context.closePath(),this._line=1-this._line,this._x=this._y=null},point:function(t,e){this._x.push(+t),this._y.push(+e)}},e.a=function(t){return new r(t)}},function(t,e,n){\"use strict\";function r(t,e){this._context=t,this._t=e}function i(t){return new r(t,0)}function o(t){return new r(t,1)}e.c=i,e.b=o,r.prototype={areaStart:function(){this._line=0},areaEnd:function(){this._line=NaN},lineStart:function(){this._x=this._y=NaN,this._point=0},lineEnd:function(){0<this._t&&this._t<1&&2===this._point&&this._context.lineTo(this._x,this._y),(this._line||0!==this._line&&1===this._point)&&this._context.closePath(),this._line>=0&&(this._t=1-this._t,this._line=1-this._line)},point:function(t,e){switch(t=+t,e=+e,this._point){case 0:this._point=1,this._line?this._context.lineTo(t,e):this._context.moveTo(t,e);break;case 1:this._point=2;default:if(this._t<=0)this._context.lineTo(this._x,e),this._context.lineTo(t,e);else{var n=this._x*(1-this._t)+t*this._t;this._context.lineTo(n,this._y),this._context.lineTo(n,e)}}this._x=t,this._y=e}},e.a=function(t){return new r(t,.5)}},function(t,e,n){\"use strict\";e.a=function(t,e){return e<t?-1:e>t?1:e>=t?0:NaN}},function(t,e,n){\"use strict\";e.a=function(t){return t}},function(t,e,n){\"use strict\";var r=n(36);e.a=function(t,e){if((o=t.length)>0){for(var i,o,a,u=0,c=t[0].length;u<c;++u){for(a=i=0;i<o;++i)a+=t[i][u][1]||0;if(a)for(i=0;i<o;++i)t[i][u][1]/=a}n.i(r.a)(t,e)}}},function(t,e,n){\"use strict\";var r=n(36);e.a=function(t,e){if((i=t.length)>0){for(var i,o=0,a=t[e[0]],u=a.length;o<u;++o){for(var c=0,s=0;c<i;++c)s+=t[c][o][1]||0;a[o][1]+=a[o][0]=-s/2}n.i(r.a)(t,e)}}},function(t,e,n){\"use strict\";var r=n(36);e.a=function(t,e){if((a=t.length)>0&&(o=(i=t[e[0]]).length)>0){for(var i,o,a,u=0,c=1;c<o;++c){for(var s=0,l=0,f=0;s<a;++s){for(var p=t[e[s]],h=p[c][1]||0,d=p[c-1][1]||0,v=(h-d)/2,g=0;g<s;++g){var m=t[e[g]],y=m[c][1]||0,_=m[c-1][1]||0;v+=y-_}l+=h,f+=v*h}i[c-1][1]+=i[c-1][0]=u,l&&(u-=f/l)}i[c-1][1]+=i[c-1][0]=u,n.i(r.a)(t,e)}}},function(t,e,n){\"use strict\";var r=n(76);e.a=function(t){return n.i(r.a)(t).reverse()}},function(t,e,n){\"use strict\";var r=n(37),i=n(76);e.a=function(t){var e,o,a=t.length,u=t.map(i.b),c=n.i(r.a)(t).sort(function(t,e){return u[e]-u[t]}),s=0,l=0,f=[],p=[];for(e=0;e<a;++e)o=c[e],s<l?(s+=u[o],f.push(o)):(l+=u[o],p.push(o));return p.reverse().concat(f)}},function(t,e,n){\"use strict\";var r=n(37);e.a=function(t){return n.i(r.a)(t).reverse()}},function(t,e,n){\"use strict\";var r=n(19),i=n(291),o=n(292),a=n(35);e.a=function(){function t(t){var n,r,i,o,p,h=t.length,d=0,v=new Array(h),g=new Array(h),m=+s.apply(this,arguments),y=Math.min(a.c,Math.max(-a.c,l.apply(this,arguments)-m)),_=Math.min(Math.abs(y)/h,f.apply(this,arguments)),b=_*(y<0?-1:1);for(n=0;n<h;++n)(p=g[v[n]=n]=+e(t[n],n,t))>0&&(d+=p);for(null!=u?v.sort(function(t,e){return u(g[t],g[e])}):null!=c&&v.sort(function(e,n){return c(t[e],t[n])}),n=0,i=d?(y-h*b)/d:0;n<h;++n,m=o)r=v[n],p=g[r],o=m+(p>0?p*i:0)+b,g[r]={data:t[r],index:n,value:p,startAngle:m,endAngle:o,padAngle:_};return g}var e=o.a,u=i.a,c=null,s=n.i(r.a)(0),l=n.i(r.a)(a.c),f=n.i(r.a)(0);return t.value=function(i){return arguments.length?(e=\"function\"==typeof i?i:n.i(r.a)(+i),t):e},t.sortValues=function(e){return arguments.length?(u=e,c=null,t):u},t.sort=function(e){return arguments.length?(c=e,u=null,t):c},t.startAngle=function(e){return arguments.length?(s=\"function\"==typeof e?e:n.i(r.a)(+e),t):s},t.endAngle=function(e){return arguments.length?(l=\"function\"==typeof e?e:n.i(r.a)(+e),t):l},t.padAngle=function(e){return arguments.length?(f=\"function\"==typeof e?e:n.i(r.a)(+e),t):f},t}},function(t,e,n){\"use strict\";var r=n(138),i=n(135),o=n(140);e.a=function(){var t=n.i(i.a)().curve(r.b),e=t.curve,a=t.lineX0,u=t.lineX1,c=t.lineY0,s=t.lineY1;return t.angle=t.x,delete t.x,t.startAngle=t.x0,delete t.x0,t.endAngle=t.x1,delete t.x1,t.radius=t.y,delete t.y,t.innerRadius=t.y0,delete t.y0,t.outerRadius=t.y1,delete t.y1,t.lineStartAngle=function(){return n.i(o.b)(a())},delete t.lineX0,t.lineEndAngle=function(){return n.i(o.b)(u())},delete t.lineX1,t.lineInnerRadius=function(){return n.i(o.b)(c())},delete t.lineY0,t.lineOuterRadius=function(){return n.i(o.b)(s())},delete t.lineY1,t.curve=function(t){return arguments.length?e(n.i(r.a)(t)):e()._curve},t}},function(t,e,n){\"use strict\";function r(t,e){return t[e]}var i=n(281),o=n(19),a=n(36),u=n(37);e.a=function(){function t(t){var n,r,i=e.apply(this,arguments),o=t.length,a=i.length,u=new Array(a);for(n=0;n<a;++n){for(var f,p=i[n],h=u[n]=new Array(o),d=0;d<o;++d)h[d]=f=[0,+l(t[d],p,d,t)],f.data=t[d];h.key=p}for(n=0,r=c(u);n<a;++n)u[r[n]].index=n;return s(u,r),u}var e=n.i(o.a)([]),c=u.a,s=a.a,l=r;return t.keys=function(r){return arguments.length?(e=\"function\"==typeof r?r:n.i(o.a)(i.a.call(r)),t):e},t.value=function(e){return arguments.length?(l=\"function\"==typeof e?e:n.i(o.a)(+e),t):l},t.order=function(e){return arguments.length?(c=null==e?u.a:\"function\"==typeof e?e:n.i(o.a)(i.a.call(e)),t):c},t.offset=function(e){return arguments.length?(s=null==e?a.a:e,t):s},t}},function(t,e,n){\"use strict\";var r=n(44),i=n(141),o=n(142),a=n(143),u=n(145),c=n(144),s=n(146),l=n(147),f=n(19);n.d(e,\"b\",function(){return p});var p=[i.a,o.a,a.a,c.a,u.a,s.a,l.a];e.a=function(){function t(){var t;if(a||(a=t=n.i(r.a)()),e.apply(this,arguments).draw(a,+o.apply(this,arguments)),t)return a=null,t+\"\"||null}var e=n.i(f.a)(i.a),o=n.i(f.a)(64),a=null;return t.type=function(r){return arguments.length?(e=\"function\"==typeof r?r:n.i(f.a)(r),t):e},t.size=function(e){return arguments.length?(o=\"function\"==typeof e?e:n.i(f.a)(+e),t):o},t.context=function(e){return arguments.length?(a=null==e?null:e,t):a},t}},function(t,e,n){\"use strict\";function r(t){var e=new Date(t);return isNaN(e)?null:e}var i=n(148),o=n(78),a=+new Date(\"2000-01-01T00:00:00.000Z\")?r:n.i(o.e)(i.b);e.a=a},function(t,e,n){\"use strict\";var r=n(5),i=n(13),o=n.i(r.a)(function(t){t.setHours(0,0,0,0)},function(t,e){t.setDate(t.getDate()+e)},function(t,e){return(e-t-(e.getTimezoneOffset()-t.getTimezoneOffset())*i.d)/i.b},function(t){return t.getDate()-1});e.a=o;o.range},function(t,e,n){\"use strict\";var r=n(5),i=n(13),o=n.i(r.a)(function(t){var e=t.getTimezoneOffset()*i.d%i.c;e<0&&(e+=i.c),t.setTime(Math.floor((+t-e)/i.c)*i.c+e)},function(t,e){t.setTime(+t+e*i.c)},function(t,e){return(e-t)/i.c},function(t){return t.getHours()});e.a=o;o.range},function(t,e,n){\"use strict\";var r=n(5),i=n.i(r.a)(function(){},function(t,e){t.setTime(+t+e)},function(t,e){return e-t});i.every=function(t){return t=Math.floor(t),isFinite(t)&&t>0?t>1?n.i(r.a)(function(e){e.setTime(Math.floor(e/t)*t)},function(e,n){e.setTime(+e+n*t)},function(e,n){return(n-e)/t}):i:null},e.a=i;i.range},function(t,e,n){\"use strict\";var r=n(5),i=n(13),o=n.i(r.a)(function(t){t.setTime(Math.floor(t/i.d)*i.d)},function(t,e){t.setTime(+t+e*i.d)},function(t,e){return(e-t)/i.d},function(t){return t.getMinutes()});e.a=o;o.range},function(t,e,n){\"use strict\";var r=n(5),i=n.i(r.a)(function(t){t.setDate(1),t.setHours(0,0,0,0)},function(t,e){t.setMonth(t.getMonth()+e)},function(t,e){return e.getMonth()-t.getMonth()+12*(e.getFullYear()-t.getFullYear())},function(t){return t.getMonth()});e.a=i;i.range},function(t,e,n){\"use strict\";var r=n(5),i=n(13),o=n.i(r.a)(function(t){t.setTime(Math.floor(t/i.e)*i.e)},function(t,e){t.setTime(+t+e*i.e)},function(t,e){return(e-t)/i.e},function(t){return t.getUTCSeconds()});e.a=o;o.range},function(t,e,n){\"use strict\";var r=n(5),i=n(13),o=n.i(r.a)(function(t){t.setUTCHours(0,0,0,0)},function(t,e){t.setUTCDate(t.getUTCDate()+e)},function(t,e){return(e-t)/i.b},function(t){return t.getUTCDate()-1});e.a=o;o.range},function(t,e,n){\"use strict\";var r=n(5),i=n(13),o=n.i(r.a)(function(t){t.setUTCMinutes(0,0,0)},function(t,e){t.setTime(+t+e*i.c)},function(t,e){return(e-t)/i.c},function(t){return t.getUTCHours()});e.a=o;o.range},function(t,e,n){\"use strict\";var r=n(5),i=n(13),o=n.i(r.a)(function(t){t.setUTCSeconds(0,0)},function(t,e){t.setTime(+t+e*i.d)},function(t,e){return(e-t)/i.d},function(t){return t.getUTCMinutes()});e.a=o;o.range},function(t,e,n){\"use strict\";var r=n(5),i=n.i(r.a)(function(t){t.setUTCDate(1),t.setUTCHours(0,0,0,0)},function(t,e){t.setUTCMonth(t.getUTCMonth()+e)},function(t,e){return e.getUTCMonth()-t.getUTCMonth()+12*(e.getUTCFullYear()-t.getUTCFullYear())},function(t){return t.getUTCMonth()});e.a=i;i.range},function(t,e,n){\"use strict\";function r(t){return n.i(i.a)(function(e){e.setUTCDate(e.getUTCDate()-(e.getUTCDay()+7-t)%7),e.setUTCHours(0,0,0,0)},function(t,e){t.setUTCDate(t.getUTCDate()+7*e)},function(t,e){return(e-t)/o.a})}var i=n(5),o=n(13);n.d(e,\"a\",function(){return a}),n.d(e,\"b\",function(){return u});var a=r(0),u=r(1),c=r(2),s=r(3),l=r(4),f=r(5),p=r(6);a.range,u.range,c.range,s.range,l.range,f.range,p.range},function(t,e,n){\"use strict\";var r=n(5),i=n.i(r.a)(function(t){t.setUTCMonth(0,1),t.setUTCHours(0,0,0,0)},function(t,e){t.setUTCFullYear(t.getUTCFullYear()+e)},function(t,e){return e.getUTCFullYear()-t.getUTCFullYear()},function(t){return t.getUTCFullYear()});i.every=function(t){return isFinite(t=Math.floor(t))&&t>0?n.i(r.a)(function(e){e.setUTCFullYear(Math.floor(e.getUTCFullYear()/t)*t),e.setUTCMonth(0,1),e.setUTCHours(0,0,0,0)},function(e,n){e.setUTCFullYear(e.getUTCFullYear()+n*t)}):null},e.a=i;i.range},function(t,e,n){\"use strict\";function r(t){return n.i(i.a)(function(e){e.setDate(e.getDate()-(e.getDay()+7-t)%7),e.setHours(0,0,0,0)},function(t,e){t.setDate(t.getDate()+7*e)},function(t,e){return(e-t-(e.getTimezoneOffset()-t.getTimezoneOffset())*o.d)/o.a})}var i=n(5),o=n(13);n.d(e,\"a\",function(){return a}),n.d(e,\"b\",function(){return u});var a=r(0),u=r(1),c=r(2),s=r(3),l=r(4),f=r(5),p=r(6);a.range,u.range,c.range,s.range,l.range,f.range,p.range},function(t,e,n){\"use strict\";var r=n(5),i=n.i(r.a)(function(t){t.setMonth(0,1),t.setHours(0,0,0,0)},function(t,e){t.setFullYear(t.getFullYear()+e)},function(t,e){return e.getFullYear()-t.getFullYear()},function(t){return t.getFullYear()});i.every=function(t){return isFinite(t=Math.floor(t))&&t>0?n.i(r.a)(function(e){e.setFullYear(Math.floor(e.getFullYear()/t)*t),e.setMonth(0,1),e.setHours(0,0,0,0)},function(e,n){e.setFullYear(e.getFullYear()+n*t)}):null},e.a=i;i.range},function(t,e,n){\"use strict\";function r(t){return t.replace(i,function(t,e){return e.toUpperCase()})}var i=/-(.)/g;t.exports=r},function(t,e,n){\"use strict\";function r(t){return i(t.replace(o,\"ms-\"))}var i=n(318),o=/^-ms-/;t.exports=r},function(t,e,n){\"use strict\";function r(t,e){return!(!t||!e)&&(t===e||!i(t)&&(i(e)?r(t,e.parentNode):\"contains\"in t?t.contains(e):!!t.compareDocumentPosition&&!!(16&t.compareDocumentPosition(e))))}var i=n(328);t.exports=r},function(t,e,n){\"use strict\";function r(t){var e=t.length;if(Array.isArray(t)||\"object\"!=typeof t&&\"function\"!=typeof t?a(!1):void 0,\"number\"!=typeof e?a(!1):void 0,0===e||e-1 in t?void 0:a(!1),\"function\"==typeof t.callee?a(!1):void 0,t.hasOwnProperty)try{return Array.prototype.slice.call(t)}catch(t){}for(var n=Array(e),r=0;r<e;r++)n[r]=t[r];return n}function i(t){return!!t&&(\"object\"==typeof t||\"function\"==typeof t)&&\"length\"in t&&!(\"setInterval\"in t)&&\"number\"!=typeof t.nodeType&&(Array.isArray(t)||\"callee\"in t||\"item\"in t)}function o(t){return i(t)?Array.isArray(t)?t.slice():r(t):[t]}var a=n(0);t.exports=o},function(t,e,n){\"use strict\";function r(t){var e=t.match(l);return e&&e[1].toLowerCase()}function i(t,e){var n=s;s?void 0:c(!1);var i=r(t),o=i&&u(i);if(o){n.innerHTML=o[1]+t+o[2];for(var l=o[0];l--;)n=n.lastChild}else n.innerHTML=t;var f=n.getElementsByTagName(\"script\");f.length&&(e?void 0:c(!1),a(f).forEach(e));for(var p=Array.from(n.childNodes);n.lastChild;)n.removeChild(n.lastChild);return p}var o=n(6),a=n(321),u=n(323),c=n(0),s=o.canUseDOM?document.createElement(\"div\"):null,l=/^\\s*<(\\w+)/;t.exports=i},function(t,e,n){\"use strict\";function r(t){return a?void 0:o(!1),p.hasOwnProperty(t)||(t=\"*\"),u.hasOwnProperty(t)||(\"*\"===t?a.innerHTML=\"<link />\":a.innerHTML=\"<\"+t+\"></\"+t+\">\",u[t]=!a.firstChild),u[t]?p[t]:null}var i=n(6),o=n(0),a=i.canUseDOM?document.createElement(\"div\"):null,u={},c=[1,'<select multiple=\"true\">',\"</select>\"],s=[1,\"<table>\",\"</table>\"],l=[3,\"<table><tbody><tr>\",\"</tr></tbody></table>\"],f=[1,'<svg xmlns=\"http://www.w3.org/2000/svg\">',\"</svg>\"],p={\"*\":[1,\"?<div>\",\"</div>\"],area:[1,\"<map>\",\"</map>\"],col:[2,\"<table><tbody></tbody><colgroup>\",\"</colgroup></table>\"],legend:[1,\"<fieldset>\",\"</fieldset>\"],param:[1,\"<object>\",\"</object>\"],tr:[2,\"<table><tbody>\",\"</tbody></table>\"],optgroup:c,option:c,caption:s,colgroup:s,tbody:s,tfoot:s,thead:s,td:l,th:l},h=[\"circle\",\"clipPath\",\"defs\",\"ellipse\",\"g\",\"image\",\"line\",\"linearGradient\",\"mask\",\"path\",\"pattern\",\"polygon\",\"polyline\",\"radialGradient\",\"rect\",\"stop\",\"text\",\"tspan\"];h.forEach(function(t){p[t]=f,u[t]=!0}),t.exports=r},function(t,e,n){\"use strict\";function r(t){return t===window?{x:window.pageXOffset||document.documentElement.scrollLeft,y:window.pageYOffset||document.documentElement.scrollTop}:{x:t.scrollLeft,y:t.scrollTop}}t.exports=r},function(t,e,n){\"use strict\";function r(t){return t.replace(i,\"-$1\").toLowerCase()}var i=/([A-Z])/g;t.exports=r},function(t,e,n){\"use strict\";function r(t){return i(t).replace(o,\"-ms-\")}var i=n(325),o=/^ms-/;t.exports=r},function(t,e,n){\"use strict\";function r(t){return!(!t||!(\"function\"==typeof Node?t instanceof Node:\"object\"==typeof t&&\"number\"==typeof t.nodeType&&\"string\"==typeof t.nodeName))}t.exports=r},function(t,e,n){\"use strict\";function r(t){return i(t)&&3==t.nodeType}var i=n(327);t.exports=r},function(t,e,n){\"use strict\";var r=function(t){var e;for(e in t)if(t.hasOwnProperty(e))return e;return null};t.exports=r},function(t,e,n){\"use strict\";function r(t){var e={};return function(n){return e.hasOwnProperty(n)||(e[n]=t.call(this,n)),e[n]}}t.exports=r},function(t,e,n){\"use strict\";var r={Properties:{\"aria-current\":0,\"aria-details\":0,\"aria-disabled\":0,\"aria-hidden\":0,\"aria-invalid\":0,\"aria-keyshortcuts\":0,\"aria-label\":0,\"aria-roledescription\":0,\"aria-autocomplete\":0,\"aria-checked\":0,\"aria-expanded\":0,\"aria-haspopup\":0,\"aria-level\":0,\"aria-modal\":0,\"aria-multiline\":0,\"aria-multiselectable\":0,\"aria-orientation\":0,\"aria-placeholder\":0,\"aria-pressed\":0,\"aria-readonly\":0,\"aria-required\":0,\"aria-selected\":0,\"aria-sort\":0,\"aria-valuemax\":0,\"aria-valuemin\":0,\"aria-valuenow\":0,\"aria-valuetext\":0,\"aria-atomic\":0,\"aria-busy\":0,\"aria-live\":0,\"aria-relevant\":0,\"aria-dropeffect\":0,\"aria-grabbed\":0,\"aria-activedescendant\":0,\"aria-colcount\":0,\"aria-colindex\":0,\"aria-colspan\":0,\"aria-controls\":0,\"aria-describedby\":0,\"aria-errormessage\":0,\"aria-flowto\":0,\"aria-labelledby\":0,\"aria-owns\":0,\"aria-posinset\":0,\"aria-rowcount\":0,\"aria-rowindex\":0,\"aria-rowspan\":0,\"aria-setsize\":0},DOMAttributeNames:{},DOMPropertyNames:{}};t.exports=r},function(t,e,n){\"use strict\";var r=n(4),i=n(151),o={focusDOMComponent:function(){i(r.getNodeFromInstance(this))}};t.exports=o},function(t,e,n){\"use strict\";function r(){var t=window.opera;return\"object\"==typeof t&&\"function\"==typeof t.version&&parseInt(t.version(),10)<=12}function i(t){return(t.ctrlKey||t.altKey||t.metaKey)&&!(t.ctrlKey&&t.altKey)}function o(t){switch(t){case\"topCompositionStart\":return E.compositionStart;case\"topCompositionEnd\":return E.compositionEnd;case\"topCompositionUpdate\":return E.compositionUpdate}}function a(t,e){return\"topKeyDown\"===t&&e.keyCode===_}function u(t,e){switch(t){case\"topKeyUp\":return y.indexOf(e.keyCode)!==-1;case\"topKeyDown\":return e.keyCode!==_;case\"topKeyPress\":case\"topMouseDown\":case\"topBlur\":return!0;default:return!1}}function c(t){var e=t.detail;return\"object\"==typeof e&&\"data\"in e?e.data:null}function s(t,e,n,r){var i,s;if(b?i=o(t):S?u(t,n)&&(i=E.compositionEnd):a(t,n)&&(i=E.compositionStart),!i)return null;C&&(S||i!==E.compositionStart?i===E.compositionEnd&&S&&(s=S.getData()):S=v.getPooled(r));var l=g.getPooled(i,e,n,r);if(s)l.data=s;else{var f=c(n);null!==f&&(l.data=f)}return h.accumulateTwoPhaseDispatches(l),l}function l(t,e){switch(t){case\"topCompositionEnd\":return c(e);case\"topKeyPress\":var n=e.which;return n!==M?null:(T=!0,k);case\"topTextInput\":var r=e.data;return r===k&&T?null:r;default:return null}}function f(t,e){if(S){if(\"topCompositionEnd\"===t||!b&&u(t,e)){var n=S.getData();return v.release(S),S=null,n}return null}switch(t){case\"topPaste\":return null;case\"topKeyPress\":return e.which&&!i(e)?String.fromCharCode(e.which):null;case\"topCompositionEnd\":return C?null:e.data;default:return null}}function p(t,e,n,r){var i;if(i=w?l(t,n):f(t,n),!i)return null;var o=m.getPooled(E.beforeInput,e,n,r);return o.data=i,h.accumulateTwoPhaseDispatches(o),o}var h=n(23),d=n(6),v=n(340),g=n(377),m=n(380),y=[9,13,27,32],_=229,b=d.canUseDOM&&\"CompositionEvent\"in window,x=null;d.canUseDOM&&\"documentMode\"in document&&(x=document.documentMode);var w=d.canUseDOM&&\"TextEvent\"in window&&!x&&!r(),C=d.canUseDOM&&(!b||x&&x>8&&x<=11),M=32,k=String.fromCharCode(M),E={beforeInput:{phasedRegistrationNames:{bubbled:\"onBeforeInput\",captured:\"onBeforeInputCapture\"},dependencies:[\"topCompositionEnd\",\"topKeyPress\",\"topTextInput\",\"topPaste\"]},compositionEnd:{phasedRegistrationNames:{bubbled:\"onCompositionEnd\",captured:\"onCompositionEndCapture\"},dependencies:[\"topBlur\",\"topCompositionEnd\",\"topKeyDown\",\"topKeyPress\",\"topKeyUp\",\"topMouseDown\"]},compositionStart:{phasedRegistrationNames:{bubbled:\"onCompositionStart\",captured:\"onCompositionStartCapture\"},dependencies:[\"topBlur\",\"topCompositionStart\",\"topKeyDown\",\"topKeyPress\",\"topKeyUp\",\"topMouseDown\"]},compositionUpdate:{phasedRegistrationNames:{bubbled:\"onCompositionUpdate\",captured:\"onCompositionUpdateCapture\"},dependencies:[\"topBlur\",\"topCompositionUpdate\",\"topKeyDown\",\"topKeyPress\",\"topKeyUp\",\"topMouseDown\"]}},T=!1,S=null,P={eventTypes:E,extractEvents:function(t,e,n,r){return[s(t,e,n,r),p(t,e,n,r)]}};t.exports=P},function(t,e,n){\"use strict\";var r=n(154),i=n(6),o=(n(9),n(319),n(386)),a=n(326),u=n(330),c=(n(1),u(function(t){return a(t)})),s=!1,l=\"cssFloat\";if(i.canUseDOM){var f=document.createElement(\"div\").style;try{f.font=\"\"}catch(t){s=!0}void 0===document.documentElement.style.cssFloat&&(l=\"styleFloat\")}var p={createMarkupForStyles:function(t,e){var n=\"\";for(var r in t)if(t.hasOwnProperty(r)){var i=t[r];null!=i&&(n+=c(r)+\":\",n+=o(r,i,e)+\";\")}return n||null},setValueForStyles:function(t,e,n){var i=t.style;for(var a in e)if(e.hasOwnProperty(a)){var u=o(a,e[a],n);if(\"float\"!==a&&\"cssFloat\"!==a||(a=l),u)i[a]=u;else{var c=s&&r.shorthandPropertyExpansions[a];if(c)for(var f in c)i[f]=\"\";else i[a]=\"\"}}}};t.exports=p},function(t,e,n){\"use strict\";function r(t){var e=t.nodeName&&t.nodeName.toLowerCase();return\"select\"===e||\"input\"===e&&\"file\"===t.type}function i(t){var e=C.getPooled(T.change,P,t,M(t));_.accumulateTwoPhaseDispatches(e),w.batchedUpdates(o,e)}function o(t){y.enqueueEvents(t),y.processEventQueue(!1)}function a(t,e){S=t,P=e,S.attachEvent(\"onchange\",i)}function u(){S&&(S.detachEvent(\"onchange\",i),S=null,P=null)}function c(t,e){if(\"topChange\"===t)return e}function s(t,e,n){\"topFocus\"===t?(u(),a(e,n)):\"topBlur\"===t&&u()}function l(t,e){S=t,P=e,N=t.value,A=Object.getOwnPropertyDescriptor(t.constructor.prototype,\"value\"),Object.defineProperty(S,\"value\",D),S.attachEvent?S.attachEvent(\"onpropertychange\",p):S.addEventListener(\"propertychange\",p,!1)}function f(){S&&(delete S.value,S.detachEvent?S.detachEvent(\"onpropertychange\",p):S.removeEventListener(\"propertychange\",p,!1),S=null,P=null,N=null,A=null)}function p(t){if(\"value\"===t.propertyName){var e=t.srcElement.value;e!==N&&(N=e,i(t))}}function h(t,e){if(\"topInput\"===t)return e}function d(t,e,n){\"topFocus\"===t?(f(),l(e,n)):\"topBlur\"===t&&f()}function v(t,e){if((\"topSelectionChange\"===t||\"topKeyUp\"===t||\"topKeyDown\"===t)&&S&&S.value!==N)return N=S.value,P}function g(t){return t.nodeName&&\"input\"===t.nodeName.toLowerCase()&&(\"checkbox\"===t.type||\"radio\"===t.type)}function m(t,e){if(\"topClick\"===t)return e}var y=n(22),_=n(23),b=n(6),x=n(4),w=n(11),C=n(14),M=n(93),k=n(94),E=n(170),T={change:{phasedRegistrationNames:{bubbled:\"onChange\",captured:\"onChangeCapture\"},dependencies:[\"topBlur\",\"topChange\",\"topClick\",\"topFocus\",\"topInput\",\"topKeyDown\",\"topKeyUp\",\"topSelectionChange\"]}},S=null,P=null,N=null,A=null,O=!1;b.canUseDOM&&(O=k(\"change\")&&(!document.documentMode||document.documentMode>8));var I=!1;b.canUseDOM&&(I=k(\"input\")&&(!document.documentMode||document.documentMode>11));var D={get:function(){return A.get.call(this)},set:function(t){N=\"\"+t,A.set.call(this,t)}},R={eventTypes:T,extractEvents:function(t,e,n,i){var o,a,u=e?x.getNodeFromInstance(e):window;if(r(u)?O?o=c:a=s:E(u)?I?o=h:(o=v,a=d):g(u)&&(o=m),o){var l=o(t,e);if(l){var f=C.getPooled(T.change,l,n,i);return f.type=\"change\",_.accumulateTwoPhaseDispatches(f),f}}a&&a(t,u,e)}};t.exports=R},function(t,e,n){\"use strict\";var r=n(2),i=n(20),o=n(6),a=n(322),u=n(8),c=(n(0),{dangerouslyReplaceNodeWithMarkup:function(t,e){if(o.canUseDOM?void 0:r(\"56\"),e?void 0:r(\"57\"),\"HTML\"===t.nodeName?r(\"58\"):void 0,\"string\"==typeof e){var n=a(e,u)[0];t.parentNode.replaceChild(n,t)}else i.replaceChildWithTree(t,e)}});t.exports=c},function(t,e,n){\"use strict\";var r=[\"ResponderEventPlugin\",\"SimpleEventPlugin\",\"TapEventPlugin\",\"EnterLeaveEventPlugin\",\"ChangeEventPlugin\",\"SelectEventPlugin\",\"BeforeInputEventPlugin\"];t.exports=r},function(t,e,n){\"use strict\";var r=n(23),i=n(4),o=n(52),a={mouseEnter:{registrationName:\"onMouseEnter\",dependencies:[\"topMouseOut\",\"topMouseOver\"]},mouseLeave:{registrationName:\"onMouseLeave\",dependencies:[\"topMouseOut\",\"topMouseOver\"]}},u={eventTypes:a,extractEvents:function(t,e,n,u){if(\"topMouseOver\"===t&&(n.relatedTarget||n.fromElement))return null;\n",
       "if(\"topMouseOut\"!==t&&\"topMouseOver\"!==t)return null;var c;if(u.window===u)c=u;else{var s=u.ownerDocument;c=s?s.defaultView||s.parentWindow:window}var l,f;if(\"topMouseOut\"===t){l=e;var p=n.relatedTarget||n.toElement;f=p?i.getClosestInstanceFromNode(p):null}else l=null,f=e;if(l===f)return null;var h=null==l?c:i.getNodeFromInstance(l),d=null==f?c:i.getNodeFromInstance(f),v=o.getPooled(a.mouseLeave,l,n,u);v.type=\"mouseleave\",v.target=h,v.relatedTarget=d;var g=o.getPooled(a.mouseEnter,f,n,u);return g.type=\"mouseenter\",g.target=d,g.relatedTarget=h,r.accumulateEnterLeaveDispatches(v,g,l,f),[v,g]}};t.exports=u},function(t,e,n){\"use strict\";var r={topAbort:null,topAnimationEnd:null,topAnimationIteration:null,topAnimationStart:null,topBlur:null,topCanPlay:null,topCanPlayThrough:null,topChange:null,topClick:null,topCompositionEnd:null,topCompositionStart:null,topCompositionUpdate:null,topContextMenu:null,topCopy:null,topCut:null,topDoubleClick:null,topDrag:null,topDragEnd:null,topDragEnter:null,topDragExit:null,topDragLeave:null,topDragOver:null,topDragStart:null,topDrop:null,topDurationChange:null,topEmptied:null,topEncrypted:null,topEnded:null,topError:null,topFocus:null,topInput:null,topInvalid:null,topKeyDown:null,topKeyPress:null,topKeyUp:null,topLoad:null,topLoadedData:null,topLoadedMetadata:null,topLoadStart:null,topMouseDown:null,topMouseMove:null,topMouseOut:null,topMouseOver:null,topMouseUp:null,topPaste:null,topPause:null,topPlay:null,topPlaying:null,topProgress:null,topRateChange:null,topReset:null,topScroll:null,topSeeked:null,topSeeking:null,topSelectionChange:null,topStalled:null,topSubmit:null,topSuspend:null,topTextInput:null,topTimeUpdate:null,topTouchCancel:null,topTouchEnd:null,topTouchMove:null,topTouchStart:null,topTransitionEnd:null,topVolumeChange:null,topWaiting:null,topWheel:null},i={topLevelTypes:r};t.exports=i},function(t,e,n){\"use strict\";function r(t){this._root=t,this._startText=this.getText(),this._fallbackText=null}var i=n(3),o=n(17),a=n(168);i(r.prototype,{destructor:function(){this._root=null,this._startText=null,this._fallbackText=null},getText:function(){return\"value\"in this._root?this._root.value:this._root[a()]},getData:function(){if(this._fallbackText)return this._fallbackText;var t,e,n=this._startText,r=n.length,i=this.getText(),o=i.length;for(t=0;t<r&&n[t]===i[t];t++);var a=r-t;for(e=1;e<=a&&n[r-e]===i[o-e];e++);var u=e>1?1-e:void 0;return this._fallbackText=i.slice(t,u),this._fallbackText}}),o.addPoolingTo(r),t.exports=r},function(t,e,n){\"use strict\";var r=n(21),i=r.injection.MUST_USE_PROPERTY,o=r.injection.HAS_BOOLEAN_VALUE,a=r.injection.HAS_NUMERIC_VALUE,u=r.injection.HAS_POSITIVE_NUMERIC_VALUE,c=r.injection.HAS_OVERLOADED_BOOLEAN_VALUE,s={isCustomAttribute:RegExp.prototype.test.bind(new RegExp(\"^(data|aria)-[\"+r.ATTRIBUTE_NAME_CHAR+\"]*$\")),Properties:{accept:0,acceptCharset:0,accessKey:0,action:0,allowFullScreen:o,allowTransparency:0,alt:0,as:0,async:o,autoComplete:0,autoPlay:o,capture:o,cellPadding:0,cellSpacing:0,charSet:0,challenge:0,checked:i|o,cite:0,classID:0,className:0,cols:u,colSpan:0,content:0,contentEditable:0,contextMenu:0,controls:o,coords:0,crossOrigin:0,data:0,dateTime:0,default:o,defer:o,dir:0,disabled:o,download:c,draggable:0,encType:0,form:0,formAction:0,formEncType:0,formMethod:0,formNoValidate:o,formTarget:0,frameBorder:0,headers:0,height:0,hidden:o,high:0,href:0,hrefLang:0,htmlFor:0,httpEquiv:0,icon:0,id:0,inputMode:0,integrity:0,is:0,keyParams:0,keyType:0,kind:0,label:0,lang:0,list:0,loop:o,low:0,manifest:0,marginHeight:0,marginWidth:0,max:0,maxLength:0,media:0,mediaGroup:0,method:0,min:0,minLength:0,multiple:i|o,muted:i|o,name:0,nonce:0,noValidate:o,open:o,optimum:0,pattern:0,placeholder:0,playsInline:o,poster:0,preload:0,profile:0,radioGroup:0,readOnly:o,referrerPolicy:0,rel:0,required:o,reversed:o,role:0,rows:u,rowSpan:a,sandbox:0,scope:0,scoped:o,scrolling:0,seamless:o,selected:i|o,shape:0,size:u,sizes:0,span:u,spellCheck:0,src:0,srcDoc:0,srcLang:0,srcSet:0,start:a,step:0,style:0,summary:0,tabIndex:0,target:0,title:0,type:0,useMap:0,value:0,width:0,wmode:0,wrap:0,about:0,datatype:0,inlist:0,prefix:0,property:0,resource:0,typeof:0,vocab:0,autoCapitalize:0,autoCorrect:0,autoSave:0,color:0,itemProp:0,itemScope:o,itemType:0,itemID:0,itemRef:0,results:0,security:0,unselectable:0},DOMAttributeNames:{acceptCharset:\"accept-charset\",className:\"class\",htmlFor:\"for\",httpEquiv:\"http-equiv\"},DOMPropertyNames:{}};t.exports=s},function(t,e,n){\"use strict\";(function(e){function r(t,e,n,r){var i=void 0===t[n];null!=e&&i&&(t[n]=o(e,!0))}var i=n(24),o=n(169),a=(n(84),n(95)),u=n(172);n(1);\"undefined\"!=typeof e&&e.env,1;var c={instantiateChildren:function(t,e,n,i){if(null==t)return null;var o={};return u(t,r,o),o},updateChildren:function(t,e,n,r,u,c,s,l,f){if(e||t){var p,h;for(p in e)if(e.hasOwnProperty(p)){h=t&&t[p];var d=h&&h._currentElement,v=e[p];if(null!=h&&a(d,v))i.receiveComponent(h,v,u,l),e[p]=h;else{h&&(r[p]=i.getHostNode(h),i.unmountComponent(h,!1));var g=o(v,!0);e[p]=g;var m=i.mountComponent(g,u,c,s,l,f);n.push(m)}}for(p in t)!t.hasOwnProperty(p)||e&&e.hasOwnProperty(p)||(h=t[p],r[p]=i.getHostNode(h),i.unmountComponent(h,!1))}},unmountChildren:function(t,e){for(var n in t)if(t.hasOwnProperty(n)){var r=t[n];i.unmountComponent(r,e)}}};t.exports=c}).call(e,n(153))},function(t,e,n){\"use strict\";var r=n(81),i=n(350),o={processChildrenUpdates:i.dangerouslyProcessChildrenUpdates,replaceNodeWithMarkup:r.dangerouslyReplaceNodeWithMarkup};t.exports=o},function(t,e,n){\"use strict\";function r(t){}function i(t,e){}function o(t){return!(!t.prototype||!t.prototype.isReactComponent)}function a(t){return!(!t.prototype||!t.prototype.isPureReactComponent)}var u=n(2),c=n(3),s=n(26),l=n(86),f=n(15),p=n(87),h=n(40),d=(n(9),n(164)),v=n(24),g=n(38),m=(n(0),n(80)),y=n(95),_=(n(1),{ImpureClass:0,PureClass:1,StatelessFunctional:2});r.prototype.render=function(){var t=h.get(this)._currentElement.type,e=t(this.props,this.context,this.updater);return i(t,e),e};var b=1,x={construct:function(t){this._currentElement=t,this._rootNodeID=0,this._compositeType=null,this._instance=null,this._hostParent=null,this._hostContainerInfo=null,this._updateBatchNumber=null,this._pendingElement=null,this._pendingStateQueue=null,this._pendingReplaceState=!1,this._pendingForceUpdate=!1,this._renderedNodeType=null,this._renderedComponent=null,this._context=null,this._mountOrder=0,this._topLevelWrapper=null,this._pendingCallbacks=null,this._calledComponentWillUnmount=!1},mountComponent:function(t,e,n,c){this._context=c,this._mountOrder=b++,this._hostParent=e,this._hostContainerInfo=n;var l,f=this._currentElement.props,p=this._processContext(c),d=this._currentElement.type,v=t.getUpdateQueue(),m=o(d),y=this._constructComponent(m,f,p,v);m||null!=y&&null!=y.render?a(d)?this._compositeType=_.PureClass:this._compositeType=_.ImpureClass:(l=y,i(d,l),null===y||y===!1||s.isValidElement(y)?void 0:u(\"105\",d.displayName||d.name||\"Component\"),y=new r(d),this._compositeType=_.StatelessFunctional);y.props=f,y.context=p,y.refs=g,y.updater=v,this._instance=y,h.set(y,this);var x=y.state;void 0===x&&(y.state=x=null),\"object\"!=typeof x||Array.isArray(x)?u(\"106\",this.getName()||\"ReactCompositeComponent\"):void 0,this._pendingStateQueue=null,this._pendingReplaceState=!1,this._pendingForceUpdate=!1;var w;return w=y.unstable_handleError?this.performInitialMountWithErrorHandling(l,e,n,t,c):this.performInitialMount(l,e,n,t,c),y.componentDidMount&&t.getReactMountReady().enqueue(y.componentDidMount,y),w},_constructComponent:function(t,e,n,r){return this._constructComponentWithoutOwner(t,e,n,r)},_constructComponentWithoutOwner:function(t,e,n,r){var i=this._currentElement.type;return t?new i(e,n,r):i(e,n,r)},performInitialMountWithErrorHandling:function(t,e,n,r,i){var o,a=r.checkpoint();try{o=this.performInitialMount(t,e,n,r,i)}catch(u){r.rollback(a),this._instance.unstable_handleError(u),this._pendingStateQueue&&(this._instance.state=this._processPendingState(this._instance.props,this._instance.context)),a=r.checkpoint(),this._renderedComponent.unmountComponent(!0),r.rollback(a),o=this.performInitialMount(t,e,n,r,i)}return o},performInitialMount:function(t,e,n,r,i){var o=this._instance,a=0;o.componentWillMount&&(o.componentWillMount(),this._pendingStateQueue&&(o.state=this._processPendingState(o.props,o.context))),void 0===t&&(t=this._renderValidatedComponent());var u=d.getType(t);this._renderedNodeType=u;var c=this._instantiateReactComponent(t,u!==d.EMPTY);this._renderedComponent=c;var s=v.mountComponent(c,r,e,n,this._processChildContext(i),a);return s},getHostNode:function(){return v.getHostNode(this._renderedComponent)},unmountComponent:function(t){if(this._renderedComponent){var e=this._instance;if(e.componentWillUnmount&&!e._calledComponentWillUnmount)if(e._calledComponentWillUnmount=!0,t){var n=this.getName()+\".componentWillUnmount()\";p.invokeGuardedCallback(n,e.componentWillUnmount.bind(e))}else e.componentWillUnmount();this._renderedComponent&&(v.unmountComponent(this._renderedComponent,t),this._renderedNodeType=null,this._renderedComponent=null,this._instance=null),this._pendingStateQueue=null,this._pendingReplaceState=!1,this._pendingForceUpdate=!1,this._pendingCallbacks=null,this._pendingElement=null,this._context=null,this._rootNodeID=0,this._topLevelWrapper=null,h.remove(e)}},_maskContext:function(t){var e=this._currentElement.type,n=e.contextTypes;if(!n)return g;var r={};for(var i in n)r[i]=t[i];return r},_processContext:function(t){var e=this._maskContext(t);return e},_processChildContext:function(t){var e,n=this._currentElement.type,r=this._instance;if(r.getChildContext&&(e=r.getChildContext()),e){\"object\"!=typeof n.childContextTypes?u(\"107\",this.getName()||\"ReactCompositeComponent\"):void 0;for(var i in e)i in n.childContextTypes?void 0:u(\"108\",this.getName()||\"ReactCompositeComponent\",i);return c({},t,e)}return t},_checkContextTypes:function(t,e,n){},receiveComponent:function(t,e,n){var r=this._currentElement,i=this._context;this._pendingElement=null,this.updateComponent(e,r,t,i,n)},performUpdateIfNecessary:function(t){null!=this._pendingElement?v.receiveComponent(this,this._pendingElement,t,this._context):null!==this._pendingStateQueue||this._pendingForceUpdate?this.updateComponent(t,this._currentElement,this._currentElement,this._context,this._context):this._updateBatchNumber=null},updateComponent:function(t,e,n,r,i){var o=this._instance;null==o?u(\"136\",this.getName()||\"ReactCompositeComponent\"):void 0;var a,c=!1;this._context===i?a=o.context:(a=this._processContext(i),c=!0);var s=e.props,l=n.props;e!==n&&(c=!0),c&&o.componentWillReceiveProps&&o.componentWillReceiveProps(l,a);var f=this._processPendingState(l,a),p=!0;this._pendingForceUpdate||(o.shouldComponentUpdate?p=o.shouldComponentUpdate(l,f,a):this._compositeType===_.PureClass&&(p=!m(s,l)||!m(o.state,f))),this._updateBatchNumber=null,p?(this._pendingForceUpdate=!1,this._performComponentUpdate(n,l,f,a,t,i)):(this._currentElement=n,this._context=i,o.props=l,o.state=f,o.context=a)},_processPendingState:function(t,e){var n=this._instance,r=this._pendingStateQueue,i=this._pendingReplaceState;if(this._pendingReplaceState=!1,this._pendingStateQueue=null,!r)return n.state;if(i&&1===r.length)return r[0];for(var o=c({},i?r[0]:n.state),a=i?1:0;a<r.length;a++){var u=r[a];c(o,\"function\"==typeof u?u.call(n,o,t,e):u)}return o},_performComponentUpdate:function(t,e,n,r,i,o){var a,u,c,s=this._instance,l=Boolean(s.componentDidUpdate);l&&(a=s.props,u=s.state,c=s.context),s.componentWillUpdate&&s.componentWillUpdate(e,n,r),this._currentElement=t,this._context=o,s.props=e,s.state=n,s.context=r,this._updateRenderedComponent(i,o),l&&i.getReactMountReady().enqueue(s.componentDidUpdate.bind(s,a,u,c),s)},_updateRenderedComponent:function(t,e){var n=this._renderedComponent,r=n._currentElement,i=this._renderValidatedComponent(),o=0;if(y(r,i))v.receiveComponent(n,i,t,this._processChildContext(e));else{var a=v.getHostNode(n);v.unmountComponent(n,!1);var u=d.getType(i);this._renderedNodeType=u;var c=this._instantiateReactComponent(i,u!==d.EMPTY);this._renderedComponent=c;var s=v.mountComponent(c,t,this._hostParent,this._hostContainerInfo,this._processChildContext(e),o);this._replaceNodeWithMarkup(a,s,n)}},_replaceNodeWithMarkup:function(t,e,n){l.replaceNodeWithMarkup(t,e,n)},_renderValidatedComponentWithoutOwnerOrContext:function(){var t,e=this._instance;return t=e.render()},_renderValidatedComponent:function(){var t;if(this._compositeType!==_.StatelessFunctional){f.current=this;try{t=this._renderValidatedComponentWithoutOwnerOrContext()}finally{f.current=null}}else t=this._renderValidatedComponentWithoutOwnerOrContext();return null===t||t===!1||s.isValidElement(t)?void 0:u(\"109\",this.getName()||\"ReactCompositeComponent\"),t},attachRef:function(t,e){var n=this.getPublicInstance();null==n?u(\"110\"):void 0;var r=e.getPublicInstance(),i=n.refs===g?n.refs={}:n.refs;i[t]=r},detachRef:function(t){var e=this.getPublicInstance().refs;delete e[t]},getName:function(){var t=this._currentElement.type,e=this._instance&&this._instance.constructor;return t.displayName||e&&e.displayName||t.name||e&&e.name||null},getPublicInstance:function(){var t=this._instance;return this._compositeType===_.StatelessFunctional?null:t},_instantiateReactComponent:null};t.exports=x},function(t,e,n){\"use strict\";var r=n(4),i=n(358),o=n(163),a=n(24),u=n(11),c=n(371),s=n(387),l=n(167),f=n(395);n(1);i.inject();var p={findDOMNode:s,render:o.render,unmountComponentAtNode:o.unmountComponentAtNode,version:c,unstable_batchedUpdates:u.batchedUpdates,unstable_renderSubtreeIntoContainer:f};\"undefined\"!=typeof __REACT_DEVTOOLS_GLOBAL_HOOK__&&\"function\"==typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.inject&&__REACT_DEVTOOLS_GLOBAL_HOOK__.inject({ComponentTree:{getClosestInstanceFromNode:r.getClosestInstanceFromNode,getNodeFromInstance:function(t){return t._renderedComponent&&(t=l(t)),t?r.getNodeFromInstance(t):null}},Mount:o,Reconciler:a});t.exports=p},function(t,e,n){\"use strict\";function r(t){if(t){var e=t._currentElement._owner||null;if(e){var n=e.getName();if(n)return\" This DOM node was rendered by `\"+n+\"`.\"}}return\"\"}function i(t,e){e&&(G[t._tag]&&(null!=e.children||null!=e.dangerouslySetInnerHTML?v(\"137\",t._tag,t._currentElement._owner?\" Check the render method of \"+t._currentElement._owner.getName()+\".\":\"\"):void 0),null!=e.dangerouslySetInnerHTML&&(null!=e.children?v(\"60\"):void 0,\"object\"==typeof e.dangerouslySetInnerHTML&&V in e.dangerouslySetInnerHTML?void 0:v(\"61\")),null!=e.style&&\"object\"!=typeof e.style?v(\"62\",r(t)):void 0)}function o(t,e,n,r){if(!(r instanceof I)){var i=t._hostContainerInfo,o=i._node&&i._node.nodeType===H,u=o?i._node:i._ownerDocument;F(e,u),r.getReactMountReady().enqueue(a,{inst:t,registrationName:e,listener:n})}}function a(){var t=this;C.putListener(t.inst,t.registrationName,t.listener)}function u(){var t=this;S.postMountWrapper(t)}function c(){var t=this;A.postMountWrapper(t)}function s(){var t=this;P.postMountWrapper(t)}function l(){var t=this;t._rootNodeID?void 0:v(\"63\");var e=U(t);switch(e?void 0:v(\"64\"),t._tag){case\"iframe\":case\"object\":t._wrapperState.listeners=[k.trapBubbledEvent(\"topLoad\",\"load\",e)];break;case\"video\":case\"audio\":t._wrapperState.listeners=[];for(var n in q)q.hasOwnProperty(n)&&t._wrapperState.listeners.push(k.trapBubbledEvent(n,q[n],e));break;case\"source\":t._wrapperState.listeners=[k.trapBubbledEvent(\"topError\",\"error\",e)];break;case\"img\":t._wrapperState.listeners=[k.trapBubbledEvent(\"topError\",\"error\",e),k.trapBubbledEvent(\"topLoad\",\"load\",e)];break;case\"form\":t._wrapperState.listeners=[k.trapBubbledEvent(\"topReset\",\"reset\",e),k.trapBubbledEvent(\"topSubmit\",\"submit\",e)];break;case\"input\":case\"select\":case\"textarea\":t._wrapperState.listeners=[k.trapBubbledEvent(\"topInvalid\",\"invalid\",e)]}}function f(){N.postUpdateWrapper(this)}function p(t){Z.call(X,t)||($.test(t)?void 0:v(\"65\",t),X[t]=!0)}function h(t,e){return t.indexOf(\"-\")>=0||null!=e.is}function d(t){var e=t.type;p(e),this._currentElement=t,this._tag=e.toLowerCase(),this._namespaceURI=null,this._renderedChildren=null,this._previousStyle=null,this._previousStyleCopy=null,this._hostNode=null,this._hostParent=null,this._rootNodeID=0,this._domID=0,this._hostContainerInfo=null,this._wrapperState=null,this._topLevelWrapper=null,this._flags=0}var v=n(2),g=n(3),m=n(332),y=n(334),_=n(20),b=n(82),x=n(21),w=n(156),C=n(22),M=n(83),k=n(51),E=n(157),T=n(4),S=n(351),P=n(352),N=n(158),A=n(355),O=(n(9),n(364)),I=n(369),D=(n(8),n(54)),R=(n(0),n(94),n(80),n(96),n(1),E),L=C.deleteListener,U=T.getNodeFromInstance,F=k.listenTo,j=M.registrationNameModules,B={string:!0,number:!0},W=\"style\",V=\"__html\",z={children:null,dangerouslySetInnerHTML:null,suppressContentEditableWarning:null},H=11,q={topAbort:\"abort\",topCanPlay:\"canplay\",topCanPlayThrough:\"canplaythrough\",topDurationChange:\"durationchange\",topEmptied:\"emptied\",topEncrypted:\"encrypted\",topEnded:\"ended\",topError:\"error\",topLoadedData:\"loadeddata\",topLoadedMetadata:\"loadedmetadata\",topLoadStart:\"loadstart\",topPause:\"pause\",topPlay:\"play\",topPlaying:\"playing\",topProgress:\"progress\",topRateChange:\"ratechange\",topSeeked:\"seeked\",topSeeking:\"seeking\",topStalled:\"stalled\",topSuspend:\"suspend\",topTimeUpdate:\"timeupdate\",topVolumeChange:\"volumechange\",topWaiting:\"waiting\"},Y={area:!0,base:!0,br:!0,col:!0,embed:!0,hr:!0,img:!0,input:!0,keygen:!0,link:!0,meta:!0,param:!0,source:!0,track:!0,wbr:!0},K={listing:!0,pre:!0,textarea:!0},G=g({menuitem:!0},Y),$=/^[a-zA-Z][a-zA-Z:_\\.\\-\\d]*$/,X={},Z={}.hasOwnProperty,Q=1;d.displayName=\"ReactDOMComponent\",d.Mixin={mountComponent:function(t,e,n,r){this._rootNodeID=Q++,this._domID=n._idCounter++,this._hostParent=e,this._hostContainerInfo=n;var o=this._currentElement.props;switch(this._tag){case\"audio\":case\"form\":case\"iframe\":case\"img\":case\"link\":case\"object\":case\"source\":case\"video\":this._wrapperState={listeners:null},t.getReactMountReady().enqueue(l,this);break;case\"input\":S.mountWrapper(this,o,e),o=S.getHostProps(this,o),t.getReactMountReady().enqueue(l,this);break;case\"option\":P.mountWrapper(this,o,e),o=P.getHostProps(this,o);break;case\"select\":N.mountWrapper(this,o,e),o=N.getHostProps(this,o),t.getReactMountReady().enqueue(l,this);break;case\"textarea\":A.mountWrapper(this,o,e),o=A.getHostProps(this,o),t.getReactMountReady().enqueue(l,this)}i(this,o);var a,f;null!=e?(a=e._namespaceURI,f=e._tag):n._tag&&(a=n._namespaceURI,f=n._tag),(null==a||a===b.svg&&\"foreignobject\"===f)&&(a=b.html),a===b.html&&(\"svg\"===this._tag?a=b.svg:\"math\"===this._tag&&(a=b.mathml)),this._namespaceURI=a;var p;if(t.useCreateElement){var h,d=n._ownerDocument;if(a===b.html)if(\"script\"===this._tag){var v=d.createElement(\"div\"),g=this._currentElement.type;v.innerHTML=\"<\"+g+\"></\"+g+\">\",h=v.removeChild(v.firstChild)}else h=o.is?d.createElement(this._currentElement.type,o.is):d.createElement(this._currentElement.type);else h=d.createElementNS(a,this._currentElement.type);T.precacheNode(this,h),this._flags|=R.hasCachedChildNodes,this._hostParent||w.setAttributeForRoot(h),this._updateDOMProperties(null,o,t);var y=_(h);this._createInitialChildren(t,o,r,y),p=y}else{var x=this._createOpenTagMarkupAndPutListeners(t,o),C=this._createContentMarkup(t,o,r);p=!C&&Y[this._tag]?x+\"/>\":x+\">\"+C+\"</\"+this._currentElement.type+\">\"}switch(this._tag){case\"input\":t.getReactMountReady().enqueue(u,this),o.autoFocus&&t.getReactMountReady().enqueue(m.focusDOMComponent,this);break;case\"textarea\":t.getReactMountReady().enqueue(c,this),o.autoFocus&&t.getReactMountReady().enqueue(m.focusDOMComponent,this);break;case\"select\":o.autoFocus&&t.getReactMountReady().enqueue(m.focusDOMComponent,this);break;case\"button\":o.autoFocus&&t.getReactMountReady().enqueue(m.focusDOMComponent,this);break;case\"option\":t.getReactMountReady().enqueue(s,this)}return p},_createOpenTagMarkupAndPutListeners:function(t,e){var n=\"<\"+this._currentElement.type;for(var r in e)if(e.hasOwnProperty(r)){var i=e[r];if(null!=i)if(j.hasOwnProperty(r))i&&o(this,r,i,t);else{r===W&&(i&&(i=this._previousStyleCopy=g({},e.style)),i=y.createMarkupForStyles(i,this));var a=null;null!=this._tag&&h(this._tag,e)?z.hasOwnProperty(r)||(a=w.createMarkupForCustomAttribute(r,i)):a=w.createMarkupForProperty(r,i),a&&(n+=\" \"+a)}}return t.renderToStaticMarkup?n:(this._hostParent||(n+=\" \"+w.createMarkupForRoot()),n+=\" \"+w.createMarkupForID(this._domID))},_createContentMarkup:function(t,e,n){var r=\"\",i=e.dangerouslySetInnerHTML;if(null!=i)null!=i.__html&&(r=i.__html);else{var o=B[typeof e.children]?e.children:null,a=null!=o?null:e.children;if(null!=o)r=D(o);else if(null!=a){var u=this.mountChildren(a,t,n);r=u.join(\"\")}}return K[this._tag]&&\"\\n\"===r.charAt(0)?\"\\n\"+r:r},_createInitialChildren:function(t,e,n,r){var i=e.dangerouslySetInnerHTML;if(null!=i)null!=i.__html&&_.queueHTML(r,i.__html);else{var o=B[typeof e.children]?e.children:null,a=null!=o?null:e.children;if(null!=o)\"\"!==o&&_.queueText(r,o);else if(null!=a)for(var u=this.mountChildren(a,t,n),c=0;c<u.length;c++)_.queueChild(r,u[c])}},receiveComponent:function(t,e,n){var r=this._currentElement;this._currentElement=t,this.updateComponent(e,r,t,n)},updateComponent:function(t,e,n,r){var o=e.props,a=this._currentElement.props;switch(this._tag){case\"input\":o=S.getHostProps(this,o),a=S.getHostProps(this,a);break;case\"option\":o=P.getHostProps(this,o),a=P.getHostProps(this,a);break;case\"select\":o=N.getHostProps(this,o),a=N.getHostProps(this,a);break;case\"textarea\":o=A.getHostProps(this,o),a=A.getHostProps(this,a)}switch(i(this,a),this._updateDOMProperties(o,a,t),this._updateDOMChildren(o,a,t,r),this._tag){case\"input\":S.updateWrapper(this);break;case\"textarea\":A.updateWrapper(this);break;case\"select\":t.getReactMountReady().enqueue(f,this)}},_updateDOMProperties:function(t,e,n){var r,i,a;for(r in t)if(!e.hasOwnProperty(r)&&t.hasOwnProperty(r)&&null!=t[r])if(r===W){var u=this._previousStyleCopy;for(i in u)u.hasOwnProperty(i)&&(a=a||{},a[i]=\"\");this._previousStyleCopy=null}else j.hasOwnProperty(r)?t[r]&&L(this,r):h(this._tag,t)?z.hasOwnProperty(r)||w.deleteValueForAttribute(U(this),r):(x.properties[r]||x.isCustomAttribute(r))&&w.deleteValueForProperty(U(this),r);for(r in e){var c=e[r],s=r===W?this._previousStyleCopy:null!=t?t[r]:void 0;if(e.hasOwnProperty(r)&&c!==s&&(null!=c||null!=s))if(r===W)if(c?c=this._previousStyleCopy=g({},c):this._previousStyleCopy=null,s){for(i in s)!s.hasOwnProperty(i)||c&&c.hasOwnProperty(i)||(a=a||{},a[i]=\"\");for(i in c)c.hasOwnProperty(i)&&s[i]!==c[i]&&(a=a||{},a[i]=c[i])}else a=c;else if(j.hasOwnProperty(r))c?o(this,r,c,n):s&&L(this,r);else if(h(this._tag,e))z.hasOwnProperty(r)||w.setValueForAttribute(U(this),r,c);else if(x.properties[r]||x.isCustomAttribute(r)){var l=U(this);null!=c?w.setValueForProperty(l,r,c):w.deleteValueForProperty(l,r)}}a&&y.setValueForStyles(U(this),a,this)},_updateDOMChildren:function(t,e,n,r){var i=B[typeof t.children]?t.children:null,o=B[typeof e.children]?e.children:null,a=t.dangerouslySetInnerHTML&&t.dangerouslySetInnerHTML.__html,u=e.dangerouslySetInnerHTML&&e.dangerouslySetInnerHTML.__html,c=null!=i?null:t.children,s=null!=o?null:e.children,l=null!=i||null!=a,f=null!=o||null!=u;null!=c&&null==s?this.updateChildren(null,n,r):l&&!f&&this.updateTextContent(\"\"),null!=o?i!==o&&this.updateTextContent(\"\"+o):null!=u?a!==u&&this.updateMarkup(\"\"+u):null!=s&&this.updateChildren(s,n,r)},getHostNode:function(){return U(this)},unmountComponent:function(t){switch(this._tag){case\"audio\":case\"form\":case\"iframe\":case\"img\":case\"link\":case\"object\":case\"source\":case\"video\":var e=this._wrapperState.listeners;if(e)for(var n=0;n<e.length;n++)e[n].remove();break;case\"html\":case\"head\":case\"body\":v(\"66\",this._tag)}this.unmountChildren(t),T.uncacheNode(this),C.deleteAllListeners(this),this._rootNodeID=0,this._domID=0,this._wrapperState=null},getPublicInstance:function(){return U(this)}},g(d.prototype,d.Mixin,O.Mixin),t.exports=d},function(t,e,n){\"use strict\";function r(t,e){var n={_topLevelWrapper:t,_idCounter:1,_ownerDocument:e?e.nodeType===i?e:e.ownerDocument:null,_node:e,_tag:e?e.nodeName.toLowerCase():null,_namespaceURI:e?e.namespaceURI:null};return n}var i=(n(96),9);t.exports=r},function(t,e,n){\"use strict\";var r=n(3),i=n(20),o=n(4),a=function(t){this._currentElement=null,this._hostNode=null,this._hostParent=null,this._hostContainerInfo=null,this._domID=0};r(a.prototype,{mountComponent:function(t,e,n,r){var a=n._idCounter++;this._domID=a,this._hostParent=e,this._hostContainerInfo=n;var u=\" react-empty: \"+this._domID+\" \";if(t.useCreateElement){var c=n._ownerDocument,s=c.createComment(u);return o.precacheNode(this,s),i(s)}return t.renderToStaticMarkup?\"\":\"<!--\"+u+\"-->\"},receiveComponent:function(){},getHostNode:function(){return o.getNodeFromInstance(this)},unmountComponent:function(){o.uncacheNode(this)}}),t.exports=a},function(t,e,n){\"use strict\";var r={useCreateElement:!0,useFiber:!1};t.exports=r},function(t,e,n){\"use strict\";var r=n(81),i=n(4),o={dangerouslyProcessChildrenUpdates:function(t,e){var n=i.getNodeFromInstance(t);r.processUpdates(n,e)}};t.exports=o},function(t,e,n){\"use strict\";function r(){this._rootNodeID&&f.updateWrapper(this)}function i(t){var e=this._currentElement.props,n=c.executeOnChange(e,t);l.asap(r,this);var i=e.name;if(\"radio\"===e.type&&null!=i){for(var a=s.getNodeFromInstance(this),u=a;u.parentNode;)u=u.parentNode;for(var f=u.querySelectorAll(\"input[name=\"+JSON.stringify(\"\"+i)+'][type=\"radio\"]'),p=0;p<f.length;p++){var h=f[p];if(h!==a&&h.form===a.form){var d=s.getInstanceFromNode(h);d?void 0:o(\"90\"),l.asap(r,d)}}}return n}var o=n(2),a=n(3),u=n(156),c=n(85),s=n(4),l=n(11),f=(n(0),n(1),{getHostProps:function(t,e){var n=c.getValue(e),r=c.getChecked(e),i=a({type:void 0,step:void 0,min:void 0,max:void 0},e,{defaultChecked:void 0,defaultValue:void 0,value:null!=n?n:t._wrapperState.initialValue,checked:null!=r?r:t._wrapperState.initialChecked,onChange:t._wrapperState.onChange});return i},mountWrapper:function(t,e){var n=e.defaultValue;t._wrapperState={initialChecked:null!=e.checked?e.checked:e.defaultChecked,initialValue:null!=e.value?e.value:n,listeners:null,onChange:i.bind(t)}},updateWrapper:function(t){var e=t._currentElement.props,n=e.checked;null!=n&&u.setValueForProperty(s.getNodeFromInstance(t),\"checked\",n||!1);var r=s.getNodeFromInstance(t),i=c.getValue(e);if(null!=i){var o=\"\"+i;o!==r.value&&(r.value=o)}else null==e.value&&null!=e.defaultValue&&r.defaultValue!==\"\"+e.defaultValue&&(r.defaultValue=\"\"+e.defaultValue),null==e.checked&&null!=e.defaultChecked&&(r.defaultChecked=!!e.defaultChecked)},postMountWrapper:function(t){var e=t._currentElement.props,n=s.getNodeFromInstance(t);switch(e.type){case\"submit\":case\"reset\":break;case\"color\":case\"date\":case\"datetime\":case\"datetime-local\":case\"month\":case\"time\":case\"week\":n.value=\"\",n.value=n.defaultValue;break;default:n.value=n.value}var r=n.name;\"\"!==r&&(n.name=\"\"),n.defaultChecked=!n.defaultChecked,n.defaultChecked=!n.defaultChecked,\"\"!==r&&(n.name=r)}});t.exports=f},function(t,e,n){\"use strict\";function r(t){var e=\"\";return o.Children.forEach(t,function(t){null!=t&&(\"string\"==typeof t||\"number\"==typeof t?e+=t:c||(c=!0))}),e}var i=n(3),o=n(26),a=n(4),u=n(158),c=(n(1),!1),s={mountWrapper:function(t,e,n){var i=null;if(null!=n){var o=n;\"optgroup\"===o._tag&&(o=o._hostParent),null!=o&&\"select\"===o._tag&&(i=u.getSelectValueContext(o))}var a=null;if(null!=i){var c;if(c=null!=e.value?e.value+\"\":r(e.children),a=!1,Array.isArray(i)){for(var s=0;s<i.length;s++)if(\"\"+i[s]===c){a=!0;break}}else a=\"\"+i===c}t._wrapperState={selected:a}},postMountWrapper:function(t){var e=t._currentElement.props;if(null!=e.value){var n=a.getNodeFromInstance(t);n.setAttribute(\"value\",e.value)}},getHostProps:function(t,e){var n=i({selected:void 0,children:void 0},e);null!=t._wrapperState.selected&&(n.selected=t._wrapperState.selected);var o=r(e.children);return o&&(n.children=o),n}};t.exports=s},function(t,e,n){\"use strict\";function r(t,e,n,r){return t===n&&e===r}function i(t){var e=document.selection,n=e.createRange(),r=n.text.length,i=n.duplicate();i.moveToElementText(t),i.setEndPoint(\"EndToStart\",n);var o=i.text.length,a=o+r;return{start:o,end:a}}function o(t){var e=window.getSelection&&window.getSelection();if(!e||0===e.rangeCount)return null;var n=e.anchorNode,i=e.anchorOffset,o=e.focusNode,a=e.focusOffset,u=e.getRangeAt(0);try{u.startContainer.nodeType,u.endContainer.nodeType}catch(t){return null}var c=r(e.anchorNode,e.anchorOffset,e.focusNode,e.focusOffset),s=c?0:u.toString().length,l=u.cloneRange();l.selectNodeContents(t),l.setEnd(u.startContainer,u.startOffset);var f=r(l.startContainer,l.startOffset,l.endContainer,l.endOffset),p=f?0:l.toString().length,h=p+s,d=document.createRange();d.setStart(n,i),d.setEnd(o,a);var v=d.collapsed;return{start:v?h:p,end:v?p:h}}function a(t,e){var n,r,i=document.selection.createRange().duplicate();void 0===e.end?(n=e.start,r=n):e.start>e.end?(n=e.end,r=e.start):(n=e.start,r=e.end),i.moveToElementText(t),i.moveStart(\"character\",n),i.setEndPoint(\"EndToStart\",i),i.moveEnd(\"character\",r-n),i.select()}function u(t,e){if(window.getSelection){var n=window.getSelection(),r=t[l()].length,i=Math.min(e.start,r),o=void 0===e.end?i:Math.min(e.end,r);if(!n.extend&&i>o){var a=o;o=i,i=a}var u=s(t,i),c=s(t,o);if(u&&c){var f=document.createRange();f.setStart(u.node,u.offset),n.removeAllRanges(),i>o?(n.addRange(f),n.extend(c.node,c.offset)):(f.setEnd(c.node,c.offset),n.addRange(f))}}}var c=n(6),s=n(392),l=n(168),f=c.canUseDOM&&\"selection\"in document&&!(\"getSelection\"in window),p={getOffsets:f?i:o,setOffsets:f?a:u};t.exports=p},function(t,e,n){\"use strict\";var r=n(2),i=n(3),o=n(81),a=n(20),u=n(4),c=n(54),s=(n(0),n(96),function(t){this._currentElement=t,this._stringText=\"\"+t,this._hostNode=null,this._hostParent=null,this._domID=0,this._mountIndex=0,this._closingComment=null,this._commentNodes=null});i(s.prototype,{mountComponent:function(t,e,n,r){var i=n._idCounter++,o=\" react-text: \"+i+\" \",s=\" /react-text \";if(this._domID=i,this._hostParent=e,t.useCreateElement){var l=n._ownerDocument,f=l.createComment(o),p=l.createComment(s),h=a(l.createDocumentFragment());return a.queueChild(h,a(f)),this._stringText&&a.queueChild(h,a(l.createTextNode(this._stringText))),a.queueChild(h,a(p)),u.precacheNode(this,f),this._closingComment=p,h}var d=c(this._stringText);return t.renderToStaticMarkup?d:\"<!--\"+o+\"-->\"+d+\"<!--\"+s+\"-->\"},receiveComponent:function(t,e){if(t!==this._currentElement){this._currentElement=t;var n=\"\"+t;if(n!==this._stringText){this._stringText=n;var r=this.getHostNode();o.replaceDelimitedText(r[0],r[1],n)}}},getHostNode:function(){var t=this._commentNodes;if(t)return t;if(!this._closingComment)for(var e=u.getNodeFromInstance(this),n=e.nextSibling;;){if(null==n?r(\"67\",this._domID):void 0,8===n.nodeType&&\" /react-text \"===n.nodeValue){this._closingComment=n;break}n=n.nextSibling}return t=[this._hostNode,this._closingComment],this._commentNodes=t,t},unmountComponent:function(){this._closingComment=null,this._commentNodes=null,u.uncacheNode(this)}}),t.exports=s},function(t,e,n){\"use strict\";function r(){this._rootNodeID&&l.updateWrapper(this)}function i(t){var e=this._currentElement.props,n=u.executeOnChange(e,t);return s.asap(r,this),n}var o=n(2),a=n(3),u=n(85),c=n(4),s=n(11),l=(n(0),n(1),{getHostProps:function(t,e){null!=e.dangerouslySetInnerHTML?o(\"91\"):void 0;var n=a({},e,{value:void 0,defaultValue:void 0,children:\"\"+t._wrapperState.initialValue,onChange:t._wrapperState.onChange});return n},mountWrapper:function(t,e){var n=u.getValue(e),r=n;if(null==n){var a=e.defaultValue,c=e.children;null!=c&&(null!=a?o(\"92\"):void 0,Array.isArray(c)&&(c.length<=1?void 0:o(\"93\"),c=c[0]),a=\"\"+c),null==a&&(a=\"\"),r=a}t._wrapperState={initialValue:\"\"+r,listeners:null,onChange:i.bind(t)}},updateWrapper:function(t){var e=t._currentElement.props,n=c.getNodeFromInstance(t),r=u.getValue(e);if(null!=r){var i=\"\"+r;i!==n.value&&(n.value=i),null==e.defaultValue&&(n.defaultValue=i)}null!=e.defaultValue&&(n.defaultValue=e.defaultValue)},postMountWrapper:function(t){var e=c.getNodeFromInstance(t),n=e.textContent;\n",
       "n===t._wrapperState.initialValue&&(e.value=n)}});t.exports=l},function(t,e,n){\"use strict\";function r(t,e){\"_hostNode\"in t?void 0:c(\"33\"),\"_hostNode\"in e?void 0:c(\"33\");for(var n=0,r=t;r;r=r._hostParent)n++;for(var i=0,o=e;o;o=o._hostParent)i++;for(;n-i>0;)t=t._hostParent,n--;for(;i-n>0;)e=e._hostParent,i--;for(var a=n;a--;){if(t===e)return t;t=t._hostParent,e=e._hostParent}return null}function i(t,e){\"_hostNode\"in t?void 0:c(\"35\"),\"_hostNode\"in e?void 0:c(\"35\");for(;e;){if(e===t)return!0;e=e._hostParent}return!1}function o(t){return\"_hostNode\"in t?void 0:c(\"36\"),t._hostParent}function a(t,e,n){for(var r=[];t;)r.push(t),t=t._hostParent;var i;for(i=r.length;i-- >0;)e(r[i],\"captured\",n);for(i=0;i<r.length;i++)e(r[i],\"bubbled\",n)}function u(t,e,n,i,o){for(var a=t&&e?r(t,e):null,u=[];t&&t!==a;)u.push(t),t=t._hostParent;for(var c=[];e&&e!==a;)c.push(e),e=e._hostParent;var s;for(s=0;s<u.length;s++)n(u[s],\"bubbled\",i);for(s=c.length;s-- >0;)n(c[s],\"captured\",o)}var c=n(2);n(0);t.exports={isAncestor:i,getLowestCommonAncestor:r,getParentInstance:o,traverseTwoPhase:a,traverseEnterLeave:u}},function(t,e,n){\"use strict\";function r(){this.reinitializeTransaction()}var i=n(3),o=n(11),a=n(53),u=n(8),c={initialize:u,close:function(){p.isBatchingUpdates=!1}},s={initialize:u,close:o.flushBatchedUpdates.bind(o)},l=[s,c];i(r.prototype,a,{getTransactionWrappers:function(){return l}});var f=new r,p={isBatchingUpdates:!1,batchedUpdates:function(t,e,n,r,i,o){var a=p.isBatchingUpdates;return p.isBatchingUpdates=!0,a?t(e,n,r,i,o):f.perform(t,null,e,n,r,i,o)}};t.exports=p},function(t,e,n){\"use strict\";function r(){C||(C=!0,y.EventEmitter.injectReactEventListener(m),y.EventPluginHub.injectEventPluginOrder(u),y.EventPluginUtils.injectComponentTree(p),y.EventPluginUtils.injectTreeTraversal(d),y.EventPluginHub.injectEventPluginsByName({SimpleEventPlugin:w,EnterLeaveEventPlugin:c,ChangeEventPlugin:a,SelectEventPlugin:x,BeforeInputEventPlugin:o}),y.HostComponent.injectGenericComponentClass(f),y.HostComponent.injectTextComponentClass(v),y.DOMProperty.injectDOMPropertyConfig(i),y.DOMProperty.injectDOMPropertyConfig(s),y.DOMProperty.injectDOMPropertyConfig(b),y.EmptyComponent.injectEmptyComponentFactory(function(t){return new h(t)}),y.Updates.injectReconcileTransaction(_),y.Updates.injectBatchingStrategy(g),y.Component.injectEnvironment(l))}var i=n(331),o=n(333),a=n(335),u=n(337),c=n(338),s=n(341),l=n(343),f=n(346),p=n(4),h=n(348),d=n(356),v=n(354),g=n(357),m=n(361),y=n(362),_=n(367),b=n(372),x=n(373),w=n(374),C=!1;t.exports={inject:r}},function(t,e,n){\"use strict\";var r=\"function\"==typeof Symbol&&Symbol.for&&Symbol.for(\"react.element\")||60103;t.exports=r},function(t,e,n){\"use strict\";function r(t){i.enqueueEvents(t),i.processEventQueue(!1)}var i=n(22),o={handleTopLevel:function(t,e,n,o){var a=i.extractEvents(t,e,n,o);r(a)}};t.exports=o},function(t,e,n){\"use strict\";function r(t){for(;t._hostParent;)t=t._hostParent;var e=f.getNodeFromInstance(t),n=e.parentNode;return f.getClosestInstanceFromNode(n)}function i(t,e){this.topLevelType=t,this.nativeEvent=e,this.ancestors=[]}function o(t){var e=h(t.nativeEvent),n=f.getClosestInstanceFromNode(e),i=n;do t.ancestors.push(i),i=i&&r(i);while(i);for(var o=0;o<t.ancestors.length;o++)n=t.ancestors[o],v._handleTopLevel(t.topLevelType,n,t.nativeEvent,h(t.nativeEvent))}function a(t){var e=d(window);t(e)}var u=n(3),c=n(150),s=n(6),l=n(17),f=n(4),p=n(11),h=n(93),d=n(324);u(i.prototype,{destructor:function(){this.topLevelType=null,this.nativeEvent=null,this.ancestors.length=0}}),l.addPoolingTo(i,l.twoArgumentPooler);var v={_enabled:!0,_handleTopLevel:null,WINDOW_HANDLE:s.canUseDOM?window:null,setHandleTopLevel:function(t){v._handleTopLevel=t},setEnabled:function(t){v._enabled=!!t},isEnabled:function(){return v._enabled},trapBubbledEvent:function(t,e,n){return n?c.listen(n,e,v.dispatchEvent.bind(null,t)):null},trapCapturedEvent:function(t,e,n){return n?c.capture(n,e,v.dispatchEvent.bind(null,t)):null},monitorScrollValue:function(t){var e=a.bind(null,t);c.listen(window,\"scroll\",e)},dispatchEvent:function(t,e){if(v._enabled){var n=i.getPooled(t,e);try{p.batchedUpdates(o,n)}finally{i.release(n)}}}};t.exports=v},function(t,e,n){\"use strict\";var r=n(21),i=n(22),o=n(50),a=n(86),u=n(159),c=n(51),s=n(161),l=n(11),f={Component:a.injection,DOMProperty:r.injection,EmptyComponent:u.injection,EventPluginHub:i.injection,EventPluginUtils:o.injection,EventEmitter:c.injection,HostComponent:s.injection,Updates:l.injection};t.exports=f},function(t,e,n){\"use strict\";var r=n(385),i=/\\/?>/,o=/^<\\!\\-\\-/,a={CHECKSUM_ATTR_NAME:\"data-react-checksum\",addChecksumToMarkup:function(t){var e=r(t);return o.test(t)?t:t.replace(i,\" \"+a.CHECKSUM_ATTR_NAME+'=\"'+e+'\"$&')},canReuseMarkup:function(t,e){var n=e.getAttribute(a.CHECKSUM_ATTR_NAME);n=n&&parseInt(n,10);var i=r(t);return i===n}};t.exports=a},function(t,e,n){\"use strict\";function r(t,e,n){return{type:\"INSERT_MARKUP\",content:t,fromIndex:null,fromNode:null,toIndex:n,afterNode:e}}function i(t,e,n){return{type:\"MOVE_EXISTING\",content:null,fromIndex:t._mountIndex,fromNode:p.getHostNode(t),toIndex:n,afterNode:e}}function o(t,e){return{type:\"REMOVE_NODE\",content:null,fromIndex:t._mountIndex,fromNode:e,toIndex:null,afterNode:null}}function a(t){return{type:\"SET_MARKUP\",content:t,fromIndex:null,fromNode:null,toIndex:null,afterNode:null}}function u(t){return{type:\"TEXT_CONTENT\",content:t,fromIndex:null,fromNode:null,toIndex:null,afterNode:null}}function c(t,e){return e&&(t=t||[],t.push(e)),t}function s(t,e){f.processChildrenUpdates(t,e)}var l=n(2),f=n(86),p=(n(40),n(9),n(15),n(24)),h=n(342),d=(n(8),n(388)),v=(n(0),{Mixin:{_reconcilerInstantiateChildren:function(t,e,n){return h.instantiateChildren(t,e,n)},_reconcilerUpdateChildren:function(t,e,n,r,i,o){var a,u=0;return a=d(e,u),h.updateChildren(t,a,n,r,i,this,this._hostContainerInfo,o,u),a},mountChildren:function(t,e,n){var r=this._reconcilerInstantiateChildren(t,e,n);this._renderedChildren=r;var i=[],o=0;for(var a in r)if(r.hasOwnProperty(a)){var u=r[a],c=0,s=p.mountComponent(u,e,this,this._hostContainerInfo,n,c);u._mountIndex=o++,i.push(s)}return i},updateTextContent:function(t){var e=this._renderedChildren;h.unmountChildren(e,!1);for(var n in e)e.hasOwnProperty(n)&&l(\"118\");var r=[u(t)];s(this,r)},updateMarkup:function(t){var e=this._renderedChildren;h.unmountChildren(e,!1);for(var n in e)e.hasOwnProperty(n)&&l(\"118\");var r=[a(t)];s(this,r)},updateChildren:function(t,e,n){this._updateChildren(t,e,n)},_updateChildren:function(t,e,n){var r=this._renderedChildren,i={},o=[],a=this._reconcilerUpdateChildren(r,t,o,i,e,n);if(a||r){var u,l=null,f=0,h=0,d=0,v=null;for(u in a)if(a.hasOwnProperty(u)){var g=r&&r[u],m=a[u];g===m?(l=c(l,this.moveChild(g,v,f,h)),h=Math.max(g._mountIndex,h),g._mountIndex=f):(g&&(h=Math.max(g._mountIndex,h)),l=c(l,this._mountChildAtIndex(m,o[d],v,f,e,n)),d++),f++,v=p.getHostNode(m)}for(u in i)i.hasOwnProperty(u)&&(l=c(l,this._unmountChild(r[u],i[u])));l&&s(this,l),this._renderedChildren=a}},unmountChildren:function(t){var e=this._renderedChildren;h.unmountChildren(e,t),this._renderedChildren=null},moveChild:function(t,e,n,r){if(t._mountIndex<r)return i(t,e,n)},createChild:function(t,e,n){return r(n,e,t._mountIndex)},removeChild:function(t,e){return o(t,e)},_mountChildAtIndex:function(t,e,n,r,i,o){return t._mountIndex=r,this.createChild(t,n,e)},_unmountChild:function(t,e){var n=this.removeChild(t,e);return t._mountIndex=null,n}}});t.exports=v},function(t,e,n){\"use strict\";function r(t){return!(!t||\"function\"!=typeof t.attachRef||\"function\"!=typeof t.detachRef)}var i=n(2),o=(n(0),{addComponentAsRefTo:function(t,e,n){r(n)?void 0:i(\"119\"),n.attachRef(e,t)},removeComponentAsRefFrom:function(t,e,n){r(n)?void 0:i(\"120\");var o=n.getPublicInstance();o&&o.refs[e]===t.getPublicInstance()&&n.detachRef(e)}});t.exports=o},function(t,e,n){\"use strict\";var r=\"SECRET_DO_NOT_PASS_THIS_OR_YOU_WILL_BE_FIRED\";t.exports=r},function(t,e,n){\"use strict\";function r(t){this.reinitializeTransaction(),this.renderToStaticMarkup=!1,this.reactMountReady=o.getPooled(null),this.useCreateElement=t}var i=n(3),o=n(155),a=n(17),u=n(51),c=n(162),s=(n(9),n(53)),l=n(88),f={initialize:c.getSelectionInformation,close:c.restoreSelection},p={initialize:function(){var t=u.isEnabled();return u.setEnabled(!1),t},close:function(t){u.setEnabled(t)}},h={initialize:function(){this.reactMountReady.reset()},close:function(){this.reactMountReady.notifyAll()}},d=[f,p,h],v={getTransactionWrappers:function(){return d},getReactMountReady:function(){return this.reactMountReady},getUpdateQueue:function(){return l},checkpoint:function(){return this.reactMountReady.checkpoint()},rollback:function(t){this.reactMountReady.rollback(t)},destructor:function(){o.release(this.reactMountReady),this.reactMountReady=null}};i(r.prototype,s,v),a.addPoolingTo(r),t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n){\"function\"==typeof t?t(e.getPublicInstance()):o.addComponentAsRefTo(e,t,n)}function i(t,e,n){\"function\"==typeof t?t(null):o.removeComponentAsRefFrom(e,t,n)}var o=n(365),a={};a.attachRefs=function(t,e){if(null!==e&&\"object\"==typeof e){var n=e.ref;null!=n&&r(n,t,e._owner)}},a.shouldUpdateRefs=function(t,e){var n=null,r=null;null!==t&&\"object\"==typeof t&&(n=t.ref,r=t._owner);var i=null,o=null;return null!==e&&\"object\"==typeof e&&(i=e.ref,o=e._owner),n!==i||\"string\"==typeof i&&o!==r},a.detachRefs=function(t,e){if(null!==e&&\"object\"==typeof e){var n=e.ref;null!=n&&i(n,t,e._owner)}},t.exports=a},function(t,e,n){\"use strict\";function r(t){this.reinitializeTransaction(),this.renderToStaticMarkup=t,this.useCreateElement=!1,this.updateQueue=new u(this)}var i=n(3),o=n(17),a=n(53),u=(n(9),n(370)),c=[],s={enqueue:function(){}},l={getTransactionWrappers:function(){return c},getReactMountReady:function(){return s},getUpdateQueue:function(){return this.updateQueue},destructor:function(){},checkpoint:function(){},rollback:function(){}};i(r.prototype,a,l),o.addPoolingTo(r),t.exports=r},function(t,e,n){\"use strict\";function r(t,e){if(!(t instanceof e))throw new TypeError(\"Cannot call a class as a function\")}function i(t,e){}var o=n(88),a=(n(1),function(){function t(e){r(this,t),this.transaction=e}return t.prototype.isMounted=function(t){return!1},t.prototype.enqueueCallback=function(t,e,n){this.transaction.isInTransaction()&&o.enqueueCallback(t,e,n)},t.prototype.enqueueForceUpdate=function(t){this.transaction.isInTransaction()?o.enqueueForceUpdate(t):i(t,\"forceUpdate\")},t.prototype.enqueueReplaceState=function(t,e){this.transaction.isInTransaction()?o.enqueueReplaceState(t,e):i(t,\"replaceState\")},t.prototype.enqueueSetState=function(t,e){this.transaction.isInTransaction()?o.enqueueSetState(t,e):i(t,\"setState\")},t}());t.exports=a},function(t,e,n){\"use strict\";t.exports=\"15.4.2\"},function(t,e,n){\"use strict\";var r={xlink:\"http://www.w3.org/1999/xlink\",xml:\"http://www.w3.org/XML/1998/namespace\"},i={accentHeight:\"accent-height\",accumulate:0,additive:0,alignmentBaseline:\"alignment-baseline\",allowReorder:\"allowReorder\",alphabetic:0,amplitude:0,arabicForm:\"arabic-form\",ascent:0,attributeName:\"attributeName\",attributeType:\"attributeType\",autoReverse:\"autoReverse\",azimuth:0,baseFrequency:\"baseFrequency\",baseProfile:\"baseProfile\",baselineShift:\"baseline-shift\",bbox:0,begin:0,bias:0,by:0,calcMode:\"calcMode\",capHeight:\"cap-height\",clip:0,clipPath:\"clip-path\",clipRule:\"clip-rule\",clipPathUnits:\"clipPathUnits\",colorInterpolation:\"color-interpolation\",colorInterpolationFilters:\"color-interpolation-filters\",colorProfile:\"color-profile\",colorRendering:\"color-rendering\",contentScriptType:\"contentScriptType\",contentStyleType:\"contentStyleType\",cursor:0,cx:0,cy:0,d:0,decelerate:0,descent:0,diffuseConstant:\"diffuseConstant\",direction:0,display:0,divisor:0,dominantBaseline:\"dominant-baseline\",dur:0,dx:0,dy:0,edgeMode:\"edgeMode\",elevation:0,enableBackground:\"enable-background\",end:0,exponent:0,externalResourcesRequired:\"externalResourcesRequired\",fill:0,fillOpacity:\"fill-opacity\",fillRule:\"fill-rule\",filter:0,filterRes:\"filterRes\",filterUnits:\"filterUnits\",floodColor:\"flood-color\",floodOpacity:\"flood-opacity\",focusable:0,fontFamily:\"font-family\",fontSize:\"font-size\",fontSizeAdjust:\"font-size-adjust\",fontStretch:\"font-stretch\",fontStyle:\"font-style\",fontVariant:\"font-variant\",fontWeight:\"font-weight\",format:0,from:0,fx:0,fy:0,g1:0,g2:0,glyphName:\"glyph-name\",glyphOrientationHorizontal:\"glyph-orientation-horizontal\",glyphOrientationVertical:\"glyph-orientation-vertical\",glyphRef:\"glyphRef\",gradientTransform:\"gradientTransform\",gradientUnits:\"gradientUnits\",hanging:0,horizAdvX:\"horiz-adv-x\",horizOriginX:\"horiz-origin-x\",ideographic:0,imageRendering:\"image-rendering\",in:0,in2:0,intercept:0,k:0,k1:0,k2:0,k3:0,k4:0,kernelMatrix:\"kernelMatrix\",kernelUnitLength:\"kernelUnitLength\",kerning:0,keyPoints:\"keyPoints\",keySplines:\"keySplines\",keyTimes:\"keyTimes\",lengthAdjust:\"lengthAdjust\",letterSpacing:\"letter-spacing\",lightingColor:\"lighting-color\",limitingConeAngle:\"limitingConeAngle\",local:0,markerEnd:\"marker-end\",markerMid:\"marker-mid\",markerStart:\"marker-start\",markerHeight:\"markerHeight\",markerUnits:\"markerUnits\",markerWidth:\"markerWidth\",mask:0,maskContentUnits:\"maskContentUnits\",maskUnits:\"maskUnits\",mathematical:0,mode:0,numOctaves:\"numOctaves\",offset:0,opacity:0,operator:0,order:0,orient:0,orientation:0,origin:0,overflow:0,overlinePosition:\"overline-position\",overlineThickness:\"overline-thickness\",paintOrder:\"paint-order\",panose1:\"panose-1\",pathLength:\"pathLength\",patternContentUnits:\"patternContentUnits\",patternTransform:\"patternTransform\",patternUnits:\"patternUnits\",pointerEvents:\"pointer-events\",points:0,pointsAtX:\"pointsAtX\",pointsAtY:\"pointsAtY\",pointsAtZ:\"pointsAtZ\",preserveAlpha:\"preserveAlpha\",preserveAspectRatio:\"preserveAspectRatio\",primitiveUnits:\"primitiveUnits\",r:0,radius:0,refX:\"refX\",refY:\"refY\",renderingIntent:\"rendering-intent\",repeatCount:\"repeatCount\",repeatDur:\"repeatDur\",requiredExtensions:\"requiredExtensions\",requiredFeatures:\"requiredFeatures\",restart:0,result:0,rotate:0,rx:0,ry:0,scale:0,seed:0,shapeRendering:\"shape-rendering\",slope:0,spacing:0,specularConstant:\"specularConstant\",specularExponent:\"specularExponent\",speed:0,spreadMethod:\"spreadMethod\",startOffset:\"startOffset\",stdDeviation:\"stdDeviation\",stemh:0,stemv:0,stitchTiles:\"stitchTiles\",stopColor:\"stop-color\",stopOpacity:\"stop-opacity\",strikethroughPosition:\"strikethrough-position\",strikethroughThickness:\"strikethrough-thickness\",string:0,stroke:0,strokeDasharray:\"stroke-dasharray\",strokeDashoffset:\"stroke-dashoffset\",strokeLinecap:\"stroke-linecap\",strokeLinejoin:\"stroke-linejoin\",strokeMiterlimit:\"stroke-miterlimit\",strokeOpacity:\"stroke-opacity\",strokeWidth:\"stroke-width\",surfaceScale:\"surfaceScale\",systemLanguage:\"systemLanguage\",tableValues:\"tableValues\",targetX:\"targetX\",targetY:\"targetY\",textAnchor:\"text-anchor\",textDecoration:\"text-decoration\",textRendering:\"text-rendering\",textLength:\"textLength\",to:0,transform:0,u1:0,u2:0,underlinePosition:\"underline-position\",underlineThickness:\"underline-thickness\",unicode:0,unicodeBidi:\"unicode-bidi\",unicodeRange:\"unicode-range\",unitsPerEm:\"units-per-em\",vAlphabetic:\"v-alphabetic\",vHanging:\"v-hanging\",vIdeographic:\"v-ideographic\",vMathematical:\"v-mathematical\",values:0,vectorEffect:\"vector-effect\",version:0,vertAdvY:\"vert-adv-y\",vertOriginX:\"vert-origin-x\",vertOriginY:\"vert-origin-y\",viewBox:\"viewBox\",viewTarget:\"viewTarget\",visibility:0,widths:0,wordSpacing:\"word-spacing\",writingMode:\"writing-mode\",x:0,xHeight:\"x-height\",x1:0,x2:0,xChannelSelector:\"xChannelSelector\",xlinkActuate:\"xlink:actuate\",xlinkArcrole:\"xlink:arcrole\",xlinkHref:\"xlink:href\",xlinkRole:\"xlink:role\",xlinkShow:\"xlink:show\",xlinkTitle:\"xlink:title\",xlinkType:\"xlink:type\",xmlBase:\"xml:base\",xmlns:0,xmlnsXlink:\"xmlns:xlink\",xmlLang:\"xml:lang\",xmlSpace:\"xml:space\",y:0,y1:0,y2:0,yChannelSelector:\"yChannelSelector\",z:0,zoomAndPan:\"zoomAndPan\"},o={Properties:{},DOMAttributeNamespaces:{xlinkActuate:r.xlink,xlinkArcrole:r.xlink,xlinkHref:r.xlink,xlinkRole:r.xlink,xlinkShow:r.xlink,xlinkTitle:r.xlink,xlinkType:r.xlink,xmlBase:r.xml,xmlLang:r.xml,xmlSpace:r.xml},DOMAttributeNames:{}};Object.keys(i).forEach(function(t){o.Properties[t]=0,i[t]&&(o.DOMAttributeNames[t]=i[t])}),t.exports=o},function(t,e,n){\"use strict\";function r(t){if(\"selectionStart\"in t&&c.hasSelectionCapabilities(t))return{start:t.selectionStart,end:t.selectionEnd};if(window.getSelection){var e=window.getSelection();return{anchorNode:e.anchorNode,anchorOffset:e.anchorOffset,focusNode:e.focusNode,focusOffset:e.focusOffset}}if(document.selection){var n=document.selection.createRange();return{parentElement:n.parentElement(),text:n.text,top:n.boundingTop,left:n.boundingLeft}}}function i(t,e){if(y||null==v||v!==l())return null;var n=r(v);if(!m||!p(m,n)){m=n;var i=s.getPooled(d.select,g,t,e);return i.type=\"select\",i.target=v,o.accumulateTwoPhaseDispatches(i),i}return null}var o=n(23),a=n(6),u=n(4),c=n(162),s=n(14),l=n(152),f=n(170),p=n(80),h=a.canUseDOM&&\"documentMode\"in document&&document.documentMode<=11,d={select:{phasedRegistrationNames:{bubbled:\"onSelect\",captured:\"onSelectCapture\"},dependencies:[\"topBlur\",\"topContextMenu\",\"topFocus\",\"topKeyDown\",\"topKeyUp\",\"topMouseDown\",\"topMouseUp\",\"topSelectionChange\"]}},v=null,g=null,m=null,y=!1,_=!1,b={eventTypes:d,extractEvents:function(t,e,n,r){if(!_)return null;var o=e?u.getNodeFromInstance(e):window;switch(t){case\"topFocus\":(f(o)||\"true\"===o.contentEditable)&&(v=o,g=e,m=null);break;case\"topBlur\":v=null,g=null,m=null;break;case\"topMouseDown\":y=!0;break;case\"topContextMenu\":case\"topMouseUp\":return y=!1,i(n,r);case\"topSelectionChange\":if(h)break;case\"topKeyDown\":case\"topKeyUp\":return i(n,r)}return null},didPutListener:function(t,e,n){\"onSelect\"===e&&(_=!0)}};t.exports=b},function(t,e,n){\"use strict\";function r(t){return\".\"+t._rootNodeID}function i(t){return\"button\"===t||\"input\"===t||\"select\"===t||\"textarea\"===t}var o=n(2),a=n(150),u=n(23),c=n(4),s=n(375),l=n(376),f=n(14),p=n(379),h=n(381),d=n(52),v=n(378),g=n(382),m=n(383),y=n(25),_=n(384),b=n(8),x=n(91),w=(n(0),{}),C={};[\"abort\",\"animationEnd\",\"animationIteration\",\"animationStart\",\"blur\",\"canPlay\",\"canPlayThrough\",\"click\",\"contextMenu\",\"copy\",\"cut\",\"doubleClick\",\"drag\",\"dragEnd\",\"dragEnter\",\"dragExit\",\"dragLeave\",\"dragOver\",\"dragStart\",\"drop\",\"durationChange\",\"emptied\",\"encrypted\",\"ended\",\"error\",\"focus\",\"input\",\"invalid\",\"keyDown\",\"keyPress\",\"keyUp\",\"load\",\"loadedData\",\"loadedMetadata\",\"loadStart\",\"mouseDown\",\"mouseMove\",\"mouseOut\",\"mouseOver\",\"mouseUp\",\"paste\",\"pause\",\"play\",\"playing\",\"progress\",\"rateChange\",\"reset\",\"scroll\",\"seeked\",\"seeking\",\"stalled\",\"submit\",\"suspend\",\"timeUpdate\",\"touchCancel\",\"touchEnd\",\"touchMove\",\"touchStart\",\"transitionEnd\",\"volumeChange\",\"waiting\",\"wheel\"].forEach(function(t){var e=t[0].toUpperCase()+t.slice(1),n=\"on\"+e,r=\"top\"+e,i={phasedRegistrationNames:{bubbled:n,captured:n+\"Capture\"},dependencies:[r]};w[t]=i,C[r]=i});var M={},k={eventTypes:w,extractEvents:function(t,e,n,r){var i=C[t];if(!i)return null;var a;switch(t){case\"topAbort\":case\"topCanPlay\":case\"topCanPlayThrough\":case\"topDurationChange\":case\"topEmptied\":case\"topEncrypted\":case\"topEnded\":case\"topError\":case\"topInput\":case\"topInvalid\":case\"topLoad\":case\"topLoadedData\":case\"topLoadedMetadata\":case\"topLoadStart\":case\"topPause\":case\"topPlay\":case\"topPlaying\":case\"topProgress\":case\"topRateChange\":case\"topReset\":case\"topSeeked\":case\"topSeeking\":case\"topStalled\":case\"topSubmit\":case\"topSuspend\":case\"topTimeUpdate\":case\"topVolumeChange\":case\"topWaiting\":a=f;break;case\"topKeyPress\":if(0===x(n))return null;case\"topKeyDown\":case\"topKeyUp\":a=h;break;case\"topBlur\":case\"topFocus\":a=p;break;case\"topClick\":if(2===n.button)return null;case\"topDoubleClick\":case\"topMouseDown\":case\"topMouseMove\":case\"topMouseUp\":case\"topMouseOut\":case\"topMouseOver\":case\"topContextMenu\":a=d;break;case\"topDrag\":case\"topDragEnd\":case\"topDragEnter\":case\"topDragExit\":case\"topDragLeave\":case\"topDragOver\":case\"topDragStart\":case\"topDrop\":a=v;break;case\"topTouchCancel\":case\"topTouchEnd\":case\"topTouchMove\":case\"topTouchStart\":a=g;break;case\"topAnimationEnd\":case\"topAnimationIteration\":case\"topAnimationStart\":a=s;break;case\"topTransitionEnd\":a=m;break;case\"topScroll\":a=y;break;case\"topWheel\":a=_;break;case\"topCopy\":case\"topCut\":case\"topPaste\":a=l}a?void 0:o(\"86\",t);var c=a.getPooled(i,e,n,r);return u.accumulateTwoPhaseDispatches(c),c},didPutListener:function(t,e,n){if(\"onClick\"===e&&!i(t._tag)){var o=r(t),u=c.getNodeFromInstance(t);M[o]||(M[o]=a.listen(u,\"click\",b))}},willDeleteListener:function(t,e){if(\"onClick\"===e&&!i(t._tag)){var n=r(t);M[n].remove(),delete M[n]}}};t.exports=k},function(t,e,n){\"use strict\";function r(t,e,n,r){return i.call(this,t,e,n,r)}var i=n(14),o={animationName:null,elapsedTime:null,pseudoElement:null};i.augmentClass(r,o),t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n,r){return i.call(this,t,e,n,r)}var i=n(14),o={clipboardData:function(t){return\"clipboardData\"in t?t.clipboardData:window.clipboardData}};i.augmentClass(r,o),t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n,r){return i.call(this,t,e,n,r)}var i=n(14),o={data:null};i.augmentClass(r,o),t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n,r){return i.call(this,t,e,n,r)}var i=n(52),o={dataTransfer:null};i.augmentClass(r,o),t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n,r){return i.call(this,t,e,n,r)}var i=n(25),o={relatedTarget:null};i.augmentClass(r,o),t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n,r){return i.call(this,t,e,n,r)}var i=n(14),o={data:null};i.augmentClass(r,o),t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n,r){return i.call(this,t,e,n,r)}var i=n(25),o=n(91),a=n(389),u=n(92),c={key:a,location:null,ctrlKey:null,shiftKey:null,altKey:null,metaKey:null,repeat:null,locale:null,getModifierState:u,charCode:function(t){return\"keypress\"===t.type?o(t):0},keyCode:function(t){return\"keydown\"===t.type||\"keyup\"===t.type?t.keyCode:0},which:function(t){return\"keypress\"===t.type?o(t):\"keydown\"===t.type||\"keyup\"===t.type?t.keyCode:0}};i.augmentClass(r,c),t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n,r){return i.call(this,t,e,n,r)}var i=n(25),o=n(92),a={touches:null,targetTouches:null,changedTouches:null,altKey:null,metaKey:null,ctrlKey:null,shiftKey:null,getModifierState:o};i.augmentClass(r,a),t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n,r){return i.call(this,t,e,n,r)}var i=n(14),o={propertyName:null,elapsedTime:null,pseudoElement:null};i.augmentClass(r,o),t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n,r){return i.call(this,t,e,n,r)}var i=n(52),o={deltaX:function(t){return\"deltaX\"in t?t.deltaX:\"wheelDeltaX\"in t?-t.wheelDeltaX:0},deltaY:function(t){return\"deltaY\"in t?t.deltaY:\"wheelDeltaY\"in t?-t.wheelDeltaY:\"wheelDelta\"in t?-t.wheelDelta:0},deltaZ:null,deltaMode:null};i.augmentClass(r,o),t.exports=r},function(t,e,n){\"use strict\";function r(t){for(var e=1,n=0,r=0,o=t.length,a=o&-4;r<a;){for(var u=Math.min(r+4096,a);r<u;r+=4)n+=(e+=t.charCodeAt(r))+(e+=t.charCodeAt(r+1))+(e+=t.charCodeAt(r+2))+(e+=t.charCodeAt(r+3));e%=i,n%=i}for(;r<o;r++)n+=e+=t.charCodeAt(r);return e%=i,n%=i,e|n<<16}var i=65521;t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n){var r=null==e||\"boolean\"==typeof e||\"\"===e;if(r)return\"\";var i=isNaN(e);if(i||0===e||o.hasOwnProperty(t)&&o[t])return\"\"+e;if(\"string\"==typeof e){e=e.trim()}return e+\"px\"}var i=n(154),o=(n(1),i.isUnitlessNumber);t.exports=r},function(t,e,n){\"use strict\";function r(t){if(null==t)return null;if(1===t.nodeType)return t;var e=a.get(t);return e?(e=u(e),e?o.getNodeFromInstance(e):null):void(\"function\"==typeof t.render?i(\"44\"):i(\"45\",Object.keys(t)))}var i=n(2),o=(n(15),n(4)),a=n(40),u=n(167);n(0),n(1);t.exports=r},function(t,e,n){\"use strict\";(function(e){function r(t,e,n,r){if(t&&\"object\"==typeof t){var i=t,o=void 0===i[n];o&&null!=e&&(i[n]=e)}}function i(t,e){if(null==t)return t;var n={};return o(t,r,n),n}var o=(n(84),n(172));n(1);\"undefined\"!=typeof e&&e.env,1,t.exports=i}).call(e,n(153))},function(t,e,n){\"use strict\";function r(t){if(t.key){var e=o[t.key]||t.key;if(\"Unidentified\"!==e)return e}if(\"keypress\"===t.type){var n=i(t);return 13===n?\"Enter\":String.fromCharCode(n)}return\"keydown\"===t.type||\"keyup\"===t.type?a[t.keyCode]||\"Unidentified\":\"\"}var i=n(91),o={Esc:\"Escape\",Spacebar:\" \",Left:\"ArrowLeft\",Up:\"ArrowUp\",Right:\"ArrowRight\",Down:\"ArrowDown\",Del:\"Delete\",Win:\"OS\",Menu:\"ContextMenu\",Apps:\"ContextMenu\",Scroll:\"ScrollLock\",MozPrintableKey:\"Unidentified\"},a={8:\"Backspace\",9:\"Tab\",12:\"Clear\",13:\"Enter\",16:\"Shift\",17:\"Control\",18:\"Alt\",19:\"Pause\",20:\"CapsLock\",27:\"Escape\",32:\" \",33:\"PageUp\",34:\"PageDown\",35:\"End\",36:\"Home\",37:\"ArrowLeft\",38:\"ArrowUp\",39:\"ArrowRight\",40:\"ArrowDown\",45:\"Insert\",46:\"Delete\",112:\"F1\",113:\"F2\",114:\"F3\",115:\"F4\",116:\"F5\",117:\"F6\",118:\"F7\",119:\"F8\",120:\"F9\",121:\"F10\",122:\"F11\",123:\"F12\",144:\"NumLock\",145:\"ScrollLock\",224:\"Meta\"};t.exports=r},function(t,e,n){\"use strict\";function r(t){var e=t&&(i&&t[i]||t[o]);if(\"function\"==typeof e)return e}var i=\"function\"==typeof Symbol&&Symbol.iterator,o=\"@@iterator\";t.exports=r},function(t,e,n){\"use strict\";function r(){return i++}var i=1;t.exports=r},function(t,e,n){\"use strict\";function r(t){for(;t&&t.firstChild;)t=t.firstChild;return t}function i(t){for(;t;){if(t.nextSibling)return t.nextSibling;t=t.parentNode}}function o(t,e){for(var n=r(t),o=0,a=0;n;){if(3===n.nodeType){if(a=o+n.textContent.length,o<=e&&a>=e)return{node:n,offset:e-o};o=a}n=r(i(n))}}t.exports=o},function(t,e,n){\"use strict\";function r(t,e){var n={};return n[t.toLowerCase()]=e.toLowerCase(),n[\"Webkit\"+t]=\"webkit\"+e,n[\"Moz\"+t]=\"moz\"+e,n[\"ms\"+t]=\"MS\"+e,n[\"O\"+t]=\"o\"+e.toLowerCase(),n}function i(t){if(u[t])return u[t];if(!a[t])return t;var e=a[t];for(var n in e)if(e.hasOwnProperty(n)&&n in c)return u[t]=e[n];return\"\"}var o=n(6),a={animationend:r(\"Animation\",\"AnimationEnd\"),animationiteration:r(\"Animation\",\"AnimationIteration\"),animationstart:r(\"Animation\",\"AnimationStart\"),transitionend:r(\"Transition\",\"TransitionEnd\")},u={},c={};o.canUseDOM&&(c=document.createElement(\"div\").style,\"AnimationEvent\"in window||(delete a.animationend.animation,delete a.animationiteration.animation,delete a.animationstart.animation),\"TransitionEvent\"in window||delete a.transitionend.transition),t.exports=i},function(t,e,n){\"use strict\";function r(t){return'\"'+i(t)+'\"'}var i=n(54);t.exports=r},function(t,e,n){\"use strict\";var r=n(163);t.exports=r.renderSubtreeIntoContainer},function(t,e,n){\"use strict\";function r(t,e){var n=l.extractSingleTouch(e);return n?n[t.page]:t.page in e?e[t.page]:e[t.client]+f[t.envScroll]}function i(t,e){var n=r(b.x,e),i=r(b.y,e);return Math.pow(Math.pow(n-t.x,2)+Math.pow(i-t.y,2),.5)}function o(t){return{tapMoveThreshold:g,ignoreMouseThreshold:m,eventTypes:C,extractEvents:function(e,n,o,a){if(!h(e)&&!d(e))return null;if(v(e))_=M();else if(t(_,M()))return null;var u=null,l=i(y,o);return d(e)&&l<g&&(u=s.getPooled(C.touchTap,n,o,a)),h(e)?(y.x=r(b.x,o),y.y=r(b.y,o)):d(e)&&(y.x=0,y.y=0),c.accumulateTwoPhaseDispatches(u),u}}}var a=n(339),u=n(50),c=n(23),s=n(25),l=n(397),f=n(89),p=n(329),h=(a.topLevelTypes,u.isStartish),d=u.isEndish,v=function(t){var e=[\"topTouchCancel\",\"topTouchEnd\",\"topTouchStart\",\"topTouchMove\"];return e.indexOf(t)>=0},g=10,m=750,y={x:null,y:null},_=null,b={x:{page:\"pageX\",client:\"clientX\",envScroll:\"currentPageScrollLeft\"},y:{page:\"pageY\",client:\"clientY\",envScroll:\"currentPageScrollTop\"}},x=[\"topTouchStart\",\"topTouchCancel\",\"topTouchEnd\",\"topTouchMove\"],w=[\"topMouseDown\",\"topMouseMove\",\"topMouseUp\"].concat(x),C={touchTap:{phasedRegistrationNames:{bubbled:p({onTouchTap:null}),captured:p({onTouchTapCapture:null})},dependencies:w}},M=function(){return Date.now?Date.now:function(){return+new Date}}();t.exports=o},function(t,e){var n={extractSingleTouch:function(t){var e=t.touches,n=t.changedTouches,r=e&&e.length>0,i=n&&n.length>0;return!r&&i?n[0]:r?e[0]:t}};t.exports=n},function(t,e){t.exports=function(t,e){if(t&&e-t<750)return!0}},function(t,e,n){\"use strict\";function r(t){var e=/[=:]/g,n={\"=\":\"=0\",\":\":\"=2\"},r=(\"\"+t).replace(e,function(t){return n[t]});return\"$\"+r}function i(t){var e=/(=0|=2)/g,n={\"=0\":\"=\",\"=2\":\":\"},r=\".\"===t[0]&&\"$\"===t[1]?t.substring(2):t.substring(1);return(\"\"+r).replace(e,function(t){return n[t]})}var o={escape:r,unescape:i};t.exports=o},function(t,e,n){\"use strict\";var r=n(28),i=(n(0),function(t){var e=this;if(e.instancePool.length){var n=e.instancePool.pop();return e.call(n,t),n}return new e(t)}),o=function(t,e){var n=this;if(n.instancePool.length){var r=n.instancePool.pop();return n.call(r,t,e),r}return new n(t,e)},a=function(t,e,n){var r=this;if(r.instancePool.length){var i=r.instancePool.pop();return r.call(i,t,e,n),i}return new r(t,e,n)},u=function(t,e,n,r){var i=this;if(i.instancePool.length){var o=i.instancePool.pop();return i.call(o,t,e,n,r),o}return new i(t,e,n,r)},c=function(t){var e=this;t instanceof e?void 0:r(\"25\"),t.destructor(),e.instancePool.length<e.poolSize&&e.instancePool.push(t)},s=10,l=i,f=function(t,e){var n=t;return n.instancePool=[],n.getPooled=e||l,n.poolSize||(n.poolSize=s),n.release=c,n},p={addPoolingTo:f,oneArgumentPooler:i,twoArgumentPooler:o,threeArgumentPooler:a,fourArgumentPooler:u};t.exports=p},function(t,e,n){\"use strict\";function r(t){return(\"\"+t).replace(b,\"$&/\")}function i(t,e){this.func=t,this.context=e,this.count=0}function o(t,e,n){var r=t.func,i=t.context;r.call(i,e,t.count++)}function a(t,e,n){if(null==t)return t;var r=i.getPooled(e,n);m(t,o,r),i.release(r)}function u(t,e,n,r){this.result=t,this.keyPrefix=e,this.func=n,this.context=r,this.count=0}function c(t,e,n){var i=t.result,o=t.keyPrefix,a=t.func,u=t.context,c=a.call(u,e,t.count++);Array.isArray(c)?s(c,i,n,g.thatReturnsArgument):null!=c&&(v.isValidElement(c)&&(c=v.cloneAndReplaceKey(c,o+(!c.key||e&&e.key===c.key?\"\":r(c.key)+\"/\")+n)),i.push(c))}function s(t,e,n,i,o){var a=\"\";null!=n&&(a=r(n)+\"/\");var s=u.getPooled(e,a,i,o);m(t,c,s),u.release(s)}function l(t,e,n){if(null==t)return t;var r=[];return s(t,r,null,e,n),r}function f(t,e,n){return null}function p(t,e){return m(t,f,null)}function h(t){var e=[];return s(t,e,null,g.thatReturnsArgument),e}var d=n(400),v=n(27),g=n(8),m=n(409),y=d.twoArgumentPooler,_=d.fourArgumentPooler,b=/\\/+/g;i.prototype.destructor=function(){this.func=null,this.context=null,this.count=0},d.addPoolingTo(i,y),u.prototype.destructor=function(){this.result=null,this.keyPrefix=null,this.func=null,this.context=null,this.count=0},d.addPoolingTo(u,_);var x={forEach:a,map:l,mapIntoWithKeyPrefixInternal:s,count:p,toArray:h};t.exports=x},function(t,e,n){\"use strict\";function r(t){return t}function i(t,e){var n=b.hasOwnProperty(e)?b[e]:null;w.hasOwnProperty(e)&&(\"OVERRIDE_BASE\"!==n?p(\"73\",e):void 0),t&&(\"DEFINE_MANY\"!==n&&\"DEFINE_MANY_MERGED\"!==n?p(\"74\",e):void 0)}function o(t,e){if(e){\"function\"==typeof e?p(\"75\"):void 0,v.isValidElement(e)?p(\"76\"):void 0;var n=t.prototype,r=n.__reactAutoBindPairs;e.hasOwnProperty(y)&&x.mixins(t,e.mixins);for(var o in e)if(e.hasOwnProperty(o)&&o!==y){var a=e[o],u=n.hasOwnProperty(o);if(i(u,o),x.hasOwnProperty(o))x[o](t,a);else{var l=b.hasOwnProperty(o),f=\"function\"==typeof a,h=f&&!l&&!u&&e.autobind!==!1;if(h)r.push(o,a),n[o]=a;else if(u){var d=b[o];!l||\"DEFINE_MANY_MERGED\"!==d&&\"DEFINE_MANY\"!==d?p(\"77\",d,o):void 0,\"DEFINE_MANY_MERGED\"===d?n[o]=c(n[o],a):\"DEFINE_MANY\"===d&&(n[o]=s(n[o],a))}else n[o]=a}}}else;}function a(t,e){if(e)for(var n in e){var r=e[n];if(e.hasOwnProperty(n)){var i=n in x;i?p(\"78\",n):void 0;var o=n in t;o?p(\"79\",n):void 0,t[n]=r}}}function u(t,e){t&&e&&\"object\"==typeof t&&\"object\"==typeof e?void 0:p(\"80\");for(var n in e)e.hasOwnProperty(n)&&(void 0!==t[n]?p(\"81\",n):void 0,t[n]=e[n]);return t}function c(t,e){return function(){var n=t.apply(this,arguments),r=e.apply(this,arguments);if(null==n)return r;if(null==r)return n;var i={};return u(i,n),u(i,r),i}}function s(t,e){return function(){t.apply(this,arguments),e.apply(this,arguments)}}function l(t,e){var n=e.bind(t);return n;\n",
       "}function f(t){for(var e=t.__reactAutoBindPairs,n=0;n<e.length;n+=2){var r=e[n],i=e[n+1];t[r]=l(t,i)}}var p=n(28),h=n(3),d=n(97),v=n(27),g=(n(175),n(98)),m=n(38),y=(n(0),n(1),\"mixins\"),_=[],b={mixins:\"DEFINE_MANY\",statics:\"DEFINE_MANY\",propTypes:\"DEFINE_MANY\",contextTypes:\"DEFINE_MANY\",childContextTypes:\"DEFINE_MANY\",getDefaultProps:\"DEFINE_MANY_MERGED\",getInitialState:\"DEFINE_MANY_MERGED\",getChildContext:\"DEFINE_MANY_MERGED\",render:\"DEFINE_ONCE\",componentWillMount:\"DEFINE_MANY\",componentDidMount:\"DEFINE_MANY\",componentWillReceiveProps:\"DEFINE_MANY\",shouldComponentUpdate:\"DEFINE_ONCE\",componentWillUpdate:\"DEFINE_MANY\",componentDidUpdate:\"DEFINE_MANY\",componentWillUnmount:\"DEFINE_MANY\",updateComponent:\"OVERRIDE_BASE\"},x={displayName:function(t,e){t.displayName=e},mixins:function(t,e){if(e)for(var n=0;n<e.length;n++)o(t,e[n])},childContextTypes:function(t,e){t.childContextTypes=h({},t.childContextTypes,e)},contextTypes:function(t,e){t.contextTypes=h({},t.contextTypes,e)},getDefaultProps:function(t,e){t.getDefaultProps?t.getDefaultProps=c(t.getDefaultProps,e):t.getDefaultProps=e},propTypes:function(t,e){t.propTypes=h({},t.propTypes,e)},statics:function(t,e){a(t,e)},autobind:function(){}},w={replaceState:function(t,e){this.updater.enqueueReplaceState(this,t),e&&this.updater.enqueueCallback(this,e,\"replaceState\")},isMounted:function(){return this.updater.isMounted(this)}},C=function(){};h(C.prototype,d.prototype,w);var M={createClass:function(t){var e=r(function(t,n,r){this.__reactAutoBindPairs.length&&f(this),this.props=t,this.context=n,this.refs=m,this.updater=r||g,this.state=null;var i=this.getInitialState?this.getInitialState():null;\"object\"!=typeof i||Array.isArray(i)?p(\"82\",e.displayName||\"ReactCompositeComponent\"):void 0,this.state=i});e.prototype=new C,e.prototype.constructor=e,e.prototype.__reactAutoBindPairs=[],_.forEach(o.bind(null,e)),o(e,t),e.getDefaultProps&&(e.defaultProps=e.getDefaultProps()),e.prototype.render?void 0:p(\"83\");for(var n in b)e.prototype[n]||(e.prototype[n]=null);return e},injection:{injectMixin:function(t){_.push(t)}}};t.exports=M},function(t,e,n){\"use strict\";var r=n(27),i=r.createFactory,o={a:i(\"a\"),abbr:i(\"abbr\"),address:i(\"address\"),area:i(\"area\"),article:i(\"article\"),aside:i(\"aside\"),audio:i(\"audio\"),b:i(\"b\"),base:i(\"base\"),bdi:i(\"bdi\"),bdo:i(\"bdo\"),big:i(\"big\"),blockquote:i(\"blockquote\"),body:i(\"body\"),br:i(\"br\"),button:i(\"button\"),canvas:i(\"canvas\"),caption:i(\"caption\"),cite:i(\"cite\"),code:i(\"code\"),col:i(\"col\"),colgroup:i(\"colgroup\"),data:i(\"data\"),datalist:i(\"datalist\"),dd:i(\"dd\"),del:i(\"del\"),details:i(\"details\"),dfn:i(\"dfn\"),dialog:i(\"dialog\"),div:i(\"div\"),dl:i(\"dl\"),dt:i(\"dt\"),em:i(\"em\"),embed:i(\"embed\"),fieldset:i(\"fieldset\"),figcaption:i(\"figcaption\"),figure:i(\"figure\"),footer:i(\"footer\"),form:i(\"form\"),h1:i(\"h1\"),h2:i(\"h2\"),h3:i(\"h3\"),h4:i(\"h4\"),h5:i(\"h5\"),h6:i(\"h6\"),head:i(\"head\"),header:i(\"header\"),hgroup:i(\"hgroup\"),hr:i(\"hr\"),html:i(\"html\"),i:i(\"i\"),iframe:i(\"iframe\"),img:i(\"img\"),input:i(\"input\"),ins:i(\"ins\"),kbd:i(\"kbd\"),keygen:i(\"keygen\"),label:i(\"label\"),legend:i(\"legend\"),li:i(\"li\"),link:i(\"link\"),main:i(\"main\"),map:i(\"map\"),mark:i(\"mark\"),menu:i(\"menu\"),menuitem:i(\"menuitem\"),meta:i(\"meta\"),meter:i(\"meter\"),nav:i(\"nav\"),noscript:i(\"noscript\"),object:i(\"object\"),ol:i(\"ol\"),optgroup:i(\"optgroup\"),option:i(\"option\"),output:i(\"output\"),p:i(\"p\"),param:i(\"param\"),picture:i(\"picture\"),pre:i(\"pre\"),progress:i(\"progress\"),q:i(\"q\"),rp:i(\"rp\"),rt:i(\"rt\"),ruby:i(\"ruby\"),s:i(\"s\"),samp:i(\"samp\"),script:i(\"script\"),section:i(\"section\"),select:i(\"select\"),small:i(\"small\"),source:i(\"source\"),span:i(\"span\"),strong:i(\"strong\"),style:i(\"style\"),sub:i(\"sub\"),summary:i(\"summary\"),sup:i(\"sup\"),table:i(\"table\"),tbody:i(\"tbody\"),td:i(\"td\"),textarea:i(\"textarea\"),tfoot:i(\"tfoot\"),th:i(\"th\"),thead:i(\"thead\"),time:i(\"time\"),title:i(\"title\"),tr:i(\"tr\"),track:i(\"track\"),u:i(\"u\"),ul:i(\"ul\"),var:i(\"var\"),video:i(\"video\"),wbr:i(\"wbr\"),circle:i(\"circle\"),clipPath:i(\"clipPath\"),defs:i(\"defs\"),ellipse:i(\"ellipse\"),g:i(\"g\"),image:i(\"image\"),line:i(\"line\"),linearGradient:i(\"linearGradient\"),mask:i(\"mask\"),path:i(\"path\"),pattern:i(\"pattern\"),polygon:i(\"polygon\"),polyline:i(\"polyline\"),radialGradient:i(\"radialGradient\"),rect:i(\"rect\"),stop:i(\"stop\"),svg:i(\"svg\"),text:i(\"text\"),tspan:i(\"tspan\")};t.exports=o},function(t,e,n){\"use strict\";function r(t,e){return t===e?0!==t||1/t===1/e:t!==t&&e!==e}function i(t){this.message=t,this.stack=\"\"}function o(t){function e(e,n,r,o,a,u,c){o=o||E,u=u||r;if(null==n[r]){var s=w[a];return e?new i(null===n[r]?\"The \"+s+\" `\"+u+\"` is marked as required \"+(\"in `\"+o+\"`, but its value is `null`.\"):\"The \"+s+\" `\"+u+\"` is marked as required in \"+(\"`\"+o+\"`, but its value is `undefined`.\")):null}return t(n,r,o,a,u)}var n=e.bind(null,!1);return n.isRequired=e.bind(null,!0),n}function a(t){function e(e,n,r,o,a,u){var c=e[n],s=y(c);if(s!==t){var l=w[o],f=_(c);return new i(\"Invalid \"+l+\" `\"+a+\"` of type \"+(\"`\"+f+\"` supplied to `\"+r+\"`, expected \")+(\"`\"+t+\"`.\"))}return null}return o(e)}function u(){return o(M.thatReturns(null))}function c(t){function e(e,n,r,o,a){if(\"function\"!=typeof t)return new i(\"Property `\"+a+\"` of component `\"+r+\"` has invalid PropType notation inside arrayOf.\");var u=e[n];if(!Array.isArray(u)){var c=w[o],s=y(u);return new i(\"Invalid \"+c+\" `\"+a+\"` of type \"+(\"`\"+s+\"` supplied to `\"+r+\"`, expected an array.\"))}for(var l=0;l<u.length;l++){var f=t(u,l,r,o,a+\"[\"+l+\"]\",C);if(f instanceof Error)return f}return null}return o(e)}function s(){function t(t,e,n,r,o){var a=t[e];if(!x.isValidElement(a)){var u=w[r],c=y(a);return new i(\"Invalid \"+u+\" `\"+o+\"` of type \"+(\"`\"+c+\"` supplied to `\"+n+\"`, expected a single ReactElement.\"))}return null}return o(t)}function l(t){function e(e,n,r,o,a){if(!(e[n]instanceof t)){var u=w[o],c=t.name||E,s=b(e[n]);return new i(\"Invalid \"+u+\" `\"+a+\"` of type \"+(\"`\"+s+\"` supplied to `\"+r+\"`, expected \")+(\"instance of `\"+c+\"`.\"))}return null}return o(e)}function f(t){function e(e,n,o,a,u){for(var c=e[n],s=0;s<t.length;s++)if(r(c,t[s]))return null;var l=w[a],f=JSON.stringify(t);return new i(\"Invalid \"+l+\" `\"+u+\"` of value `\"+c+\"` \"+(\"supplied to `\"+o+\"`, expected one of \"+f+\".\"))}return Array.isArray(t)?o(e):M.thatReturnsNull}function p(t){function e(e,n,r,o,a){if(\"function\"!=typeof t)return new i(\"Property `\"+a+\"` of component `\"+r+\"` has invalid PropType notation inside objectOf.\");var u=e[n],c=y(u);if(\"object\"!==c){var s=w[o];return new i(\"Invalid \"+s+\" `\"+a+\"` of type \"+(\"`\"+c+\"` supplied to `\"+r+\"`, expected an object.\"))}for(var l in u)if(u.hasOwnProperty(l)){var f=t(u,l,r,o,a+\".\"+l,C);if(f instanceof Error)return f}return null}return o(e)}function h(t){function e(e,n,r,o,a){for(var u=0;u<t.length;u++){var c=t[u];if(null==c(e,n,r,o,a,C))return null}var s=w[o];return new i(\"Invalid \"+s+\" `\"+a+\"` supplied to \"+(\"`\"+r+\"`.\"))}return Array.isArray(t)?o(e):M.thatReturnsNull}function d(){function t(t,e,n,r,o){if(!g(t[e])){var a=w[r];return new i(\"Invalid \"+a+\" `\"+o+\"` supplied to \"+(\"`\"+n+\"`, expected a ReactNode.\"))}return null}return o(t)}function v(t){function e(e,n,r,o,a){var u=e[n],c=y(u);if(\"object\"!==c){var s=w[o];return new i(\"Invalid \"+s+\" `\"+a+\"` of type `\"+c+\"` \"+(\"supplied to `\"+r+\"`, expected `object`.\"))}for(var l in t){var f=t[l];if(f){var p=f(u,l,r,o,a+\".\"+l,C);if(p)return p}}return null}return o(e)}function g(t){switch(typeof t){case\"number\":case\"string\":case\"undefined\":return!0;case\"boolean\":return!t;case\"object\":if(Array.isArray(t))return t.every(g);if(null===t||x.isValidElement(t))return!0;var e=k(t);if(!e)return!1;var n,r=e.call(t);if(e!==t.entries){for(;!(n=r.next()).done;)if(!g(n.value))return!1}else for(;!(n=r.next()).done;){var i=n.value;if(i&&!g(i[1]))return!1}return!0;default:return!1}}function m(t,e){return\"symbol\"===t||(\"Symbol\"===e[\"@@toStringTag\"]||\"function\"==typeof Symbol&&e instanceof Symbol)}function y(t){var e=typeof t;return Array.isArray(t)?\"array\":t instanceof RegExp?\"object\":m(e,t)?\"symbol\":e}function _(t){var e=y(t);if(\"object\"===e){if(t instanceof Date)return\"date\";if(t instanceof RegExp)return\"regexp\"}return e}function b(t){return t.constructor&&t.constructor.name?t.constructor.name:E}var x=n(27),w=n(175),C=n(405),M=n(8),k=n(177),E=(n(1),\"<<anonymous>>\"),T={array:a(\"array\"),bool:a(\"boolean\"),func:a(\"function\"),number:a(\"number\"),object:a(\"object\"),string:a(\"string\"),symbol:a(\"symbol\"),any:u(),arrayOf:c,element:s(),instanceOf:l,node:d(),objectOf:p,oneOf:f,oneOfType:h,shape:v};i.prototype=Error.prototype,t.exports=T},function(t,e,n){\"use strict\";var r=\"SECRET_DO_NOT_PASS_THIS_OR_YOU_WILL_BE_FIRED\";t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n){this.props=t,this.context=e,this.refs=c,this.updater=n||u}function i(){}var o=n(3),a=n(97),u=n(98),c=n(38);i.prototype=a.prototype,r.prototype=new i,r.prototype.constructor=r,o(r.prototype,a.prototype),r.prototype.isPureReactComponent=!0,t.exports=r},function(t,e,n){\"use strict\";t.exports=\"15.4.2\"},function(t,e,n){\"use strict\";function r(t){return o.isValidElement(t)?void 0:i(\"143\"),t}var i=n(28),o=n(27);n(0);t.exports=r},function(t,e,n){\"use strict\";function r(t,e){return t&&\"object\"==typeof t&&null!=t.key?s.escape(t.key):e.toString(36)}function i(t,e,n,o){var p=typeof t;if(\"undefined\"!==p&&\"boolean\"!==p||(t=null),null===t||\"string\"===p||\"number\"===p||\"object\"===p&&t.$$typeof===u)return n(o,t,\"\"===e?l+r(t,0):e),1;var h,d,v=0,g=\"\"===e?l:e+f;if(Array.isArray(t))for(var m=0;m<t.length;m++)h=t[m],d=g+r(h,m),v+=i(h,d,n,o);else{var y=c(t);if(y){var _,b=y.call(t);if(y!==t.entries)for(var x=0;!(_=b.next()).done;)h=_.value,d=g+r(h,x++),v+=i(h,d,n,o);else for(;!(_=b.next()).done;){var w=_.value;w&&(h=w[1],d=g+s.escape(w[0])+f+r(h,0),v+=i(h,d,n,o))}}else if(\"object\"===p){var C=\"\",M=String(t);a(\"31\",\"[object Object]\"===M?\"object with keys {\"+Object.keys(t).join(\", \")+\"}\":M,C)}}return v}function o(t,e,n){return null==t?0:i(t,\"\",e,n)}var a=n(28),u=(n(15),n(174)),c=n(177),s=(n(0),n(399)),l=(n(1),\".\"),f=\":\";t.exports=o},function(t,e,n){\"use strict\";function r(t){return t&&t.__esModule?t:{default:t}}var i=n(41),o=r(i),a=n(182),u=r(a),c=n(183),s=r(c),l=n(181),f=r(l),p=n(180),h=r(p),d=n(179),v=r(d);(0,s.default)(),window.SHAP={SimpleListVisualizer:f.default,AdditiveForceVisualizer:h.default,AdditiveForceArrayVisualizer:v.default,React:o.default,ReactDom:u.default}}]);</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import shap\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 238443,
     "status": "ok",
     "timestamp": 1668342897632,
     "user": {
      "displayName": "Darrell Lai",
      "userId": "03944376215088217788"
     },
     "user_tz": -480
    },
    "id": "qCIDBgLF8FWl",
    "outputId": "ef90cd27-95df-49fd-c98d-3e23fd1353ab"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 501it [03:58,  2.02it/s]\n"
     ]
    }
   ],
   "source": [
    "explainer = shap.Explainer(model_tuned, X_train_full, feature_names=X.columns)\n",
    "shap_values500 = explainer(X_train_full[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "executionInfo": {
     "elapsed": 1722,
     "status": "ok",
     "timestamp": 1668342903979,
     "user": {
      "displayName": "Darrell Lai",
      "userId": "03944376215088217788"
     },
     "user_tz": -480
    },
    "id": "phX4qJIB95X2",
    "outputId": "20bb2666-a5d6-44b3-c600-08b9989090cd"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x396 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = shap.plots.beeswarm(shap_values,show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "executionInfo": {
     "elapsed": 1751,
     "status": "ok",
     "timestamp": 1668343638770,
     "user": {
      "displayName": "Darrell Lai",
      "userId": "03944376215088217788"
     },
     "user_tz": -480
    },
    "id": "__PbDrrH_Gxz",
    "outputId": "39f4c266-d905-40d6-e0e4-7e882387488b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x453.6 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "shap.summary_plot(shap_values,X_test[:500],feature_names=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "executionInfo": {
     "elapsed": 1857849,
     "status": "ok",
     "timestamp": 1668346430474,
     "user": {
      "displayName": "Darrell Lai",
      "userId": "03944376215088217788"
     },
     "user_tz": -480
    },
    "id": "Rdy5OiN5AdeF",
    "outputId": "19160fd3-9e2a-4ffe-fecc-604b53eff08b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 4248it [30:56,  2.28it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x453.6 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "shap_values_test_full = explainer(X_test)\n",
    "shap.summary_plot(shap_values_test_full,X_test,feature_names=X.columns)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7.1 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "5741cc7d8792b3f01c8dd29250f9a5b3ae1fb75a0d772c815f8863fe4900639a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
